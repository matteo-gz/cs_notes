video: https://www.youtube.com/playlist?list=PLMDSb3PWPnvivPLXHM9SlZLljrO9unIAW

CMU 15-418＼618 Parallel Computer Architecture and Programming 2016 SP
## 01 Why Parallelism Why Efficiency

## 02 A Modern Multi Core Processor

**多核处理器工作原理**

* 多核处理器是指在一枚处理器中集成多个完整的计算引擎（内核），每个内核都可以独立执行指令。
* 多核处理器的工作流程可以简化为三个基本单元：
    * 指令解码单元：负责将指令从内存中读取到处理器，并解码成可执行的指令流。
    * 执行单元：负责执行指令，并产生结果。
    * 上下文切换单元：负责管理不同内核之间的切换。

**SIMD技术**

* SIMD（Single Instruction Multiple Data）技术是一种并行处理技术，它通过扩展执行单元来实现同时处理多个数据。
* SIMD技术可以提高多核处理器的性能，但也存在一些局限性，例如：
    * 对程序的依赖性较高，如果程序中存在条件分支等依赖关系，可能无法很好地利用SIMD的特点实现并行。
    * 对硬件的支持要求较高，需要处理器支持相应的指令集。

**多核处理器的并行计算**

* 多核处理器可以通过数据并行和任务并行来实现并行计算。
* 数据并行：将一个任务的数据分割为多个部分，并分别分配给多个内核来执行。
* 任务并行：将一个任务分割为多个独立的子任务，并分别分配给多个内核来执行。
## 03 Parallel Programing Abstractions  

**并行编程中的抽象概念和实现机制**

* 并行编程语言提供的高层抽象概念，可以帮助编程人员更容易地编写并行程序。
* 并行程序的实现机制，通常涉及硬件资源的调度和管理。

**ISPC中的工作组抽象**

* ISPC中函数调用会同时启动多个“工作组”来执行函数体。
* 工作组是并行编程中的一个常见抽象概念，可以用于将计算任务分配给多个处理器核心。
* ISPC中工作组的ID和数量可以用于分配计算任务。

**ISPC中的向量计算实现**

* ISPC实际上是通过向量指令来实现工作组并行执行的。
* 向量指令可以同时处理多个数据，可以提高并行计算的效率。
* ISPC编译器会生成能够同时并行执行所有工作组实例指令的二进制文件。

## 04 Parallel Programing Basics

**并行程序设计的思考框架**

* 并行程序设计的核心是将大问题分解为独立的小任务，并将这些任务分配给多个工作线程或程序实例来执行。

* 具体的思考框架可以分为以下几个步骤：
    * 将大问题分解为独立的小任务。
    * 将任务分配给工作线程/程序实例进行执行。
    * 协调所有工作线程的执行，确保数据依赖和顺序都得到满足。
    * 将工作线程映射到实际的计算资源如CPU核等上执行。

**图像处理例子**

* 将图像处理任务分解为调亮度和计算平均亮度两个步骤。
* 调亮度这一步可以完全并行，但计算平均亮度这一步是串行的。
* 这两个步骤的并行度取决于它们的独立性。

**并行程序的性能**

* 一个任务的最高速度提升上限取决于它的串行部分占总工作量的比例。
## 05 GPU Architecture and CUDA Programming

**GPU架构**

* GPU是专门用于并行计算的硬件设备。
* GPU由大量的流处理器（SP）组成，每个SP可以同时执行多个指令。
* GPU还具有大量的共享内存和局部内存，可以用于加速数据访问。

**计算机绘图原理**

* 计算机绘图是通过操作顶点、三角形、片段来生成图形。
* 顶点是图形的基本元素，包含位置、颜色、纹理等信息。
* 三角形是图形的基本结构，由三个顶点连接而成。
* 片段是三角形被光栅化后生成的像素。

**现代GPU的发展历程**

* 早期的GPU主要用于游戏渲染。
* 随着GPU计算能力的提升，逐渐开始用于通用计算。
* CUDA、OpenCL等编程框架的出现，使得GPU可以编程运行通用计算程序。

**CUDA编程模型**

* CUDA编程模型是基于数据并行计算的编程模型。
* CUDA程序由主机程序和核函数组成。
* 主机程序负责创建核函数并将数据传递给核函数。
* 核函数在GPU上执行，并可以并行运行。

**OpenGL渲染管道模型**

* OpenGL渲染管道模型是基于流水线的编程模型。
* OpenGL程序由顶点着色器、片段着色器、几何着色器等组成。
* 顶点着色器负责对顶点进行处理。
* 片段着色器负责对片段进行处理。
* 几何着色器负责生成新的三角形。

**CUDA kernel函数语法**

* CUDA kernel函数是一个特殊的函数，可以并行运行。
* CUDA kernel函数的语法与C/C++函数类似，但有一些特殊的语法。

**OpenCL标准**

* OpenCL是另一种通用计算编程框架。
* OpenCL与CUDA类似，都是基于数据并行计算的编程模型。
* CUDA和OpenCL都支持多种硬件平台，包括GPU、CPU、FPGA等。

## 06 Performance Optimization Part I

**并行任务分配**

* 并行任务分配是指将并行任务映射到处理器资源上的过程。
* 任务分配方式可以分为静态分配和动态分配。

**静态分配**

* 静态分配是指在任务调度之前就将任务分配给处理器。
* 适用于工作负载的成本可以预知的情况。
* 优点是简单、高效。
* 缺点是不能适应工作负载变化。

**动态分配**

* 动态分配是指在任务调度过程中动态将任务分配给处理器。
* 适用于工作负载的成本无法预知的情况。
* 优点是灵活、适应性强。
* 缺点是复杂、可能存在同步开销。

**动态分配的优化**

* 动态分配的同步开销是性能瓶颈。
* 优化方法包括：
    * 加大每个任务的粒度：可以减少同步次数。
    * 随机化输入数据：可以均衡任务负载。

**任务粒度选择**

* 任务粒度是指每个任务的工作量。
* 需要平衡同步开销和工作负载平衡两方面。
  
## 07 Performance Optimization Part II

**并行计算性能优化**

* 并行计算性能优化是指提高并行程序执行效率的过程。
* 主要的优化方向包括：
    * 提高计算效率：例如使用高效的算法和数据结构。
    * 减少通信开销：例如使用高效的消息传递机制。
    * 降低同步开销：例如使用异步通信或流水线技术。

**通信同步开销**

* 通信同步是指在并行程序中，多个进程或线程之间进行数据交换时，需要等待所有参与方都准备就绪的过程。
* 通信同步的开销包括：
    * 等待时间：等待其他参与方准备就绪的时间。
    * 通信开销：数据传输的开销。

**消息传递**

* 消息传递是并行计算中常用的通信方式。
* 消息传递可以分为同步和异步两种模式。

**同步消息传递**

* 同步消息传递是指发送方在发送消息后，必须等待接收方确认收到消息后才能继续执行。
* 同步消息传递的优点是：
    * 数据传输可靠，不会丢失数据。
    * 开发简单，易于编程。
* 同步消息传递的缺点是：
    * 会增加等待时间，降低性能。

**异步消息传递**

* 异步消息传递是指发送方在发送消息后，可以继续执行，无需等待接收方确认收到消息。
* 异步消息传递的优点是：
    * 可以提高性能，减少等待时间。
* 异步消息传递的缺点是：
    * 数据传输不可靠，可能丢失数据。
    * 开发复杂，编程困难。

**延迟与吞吐量**

* 延迟是指从发送消息到接收消息之间的时间。
* 吞吐量是指单位时间内发送或接收的消息数。

**流水线**

* 流水线是指将一个任务分解为多个子任务，然后将这些子任务依次执行的过程。
* 流水线可以提高系统吞吐量，而不增加延迟。

**并行计算性能优化建议**

* 避免不必要的同步。
* 使用异步消息传递来减少等待时间。
* 使用流水线技术来提高吞吐量。
## 08 Parallel Programming Case Studies

**并行编程案例**

* 在并行编程中，常见的应用场景包括科学计算、大数据处理、机器学习等。
* 并行编程案例的分析和优化，可以帮助我们更好地理解并行编程的原理和方法。

**海洋浪流模拟**

* 海洋浪流模拟是常见的科学计算应用之一。
* 该应用的计算过程可以分为以下几个步骤：
    * 计算海浪的初始条件。
    * 计算海浪的传播。
    * 计算海浪的相互作用。
* 并行化该应用可以提高计算速度。

**内存优化**

* 内存优化是并行编程的关键之一。
* 内存优化可以提高缓存利用率，从而提高性能。

* 内存优化的方法包括：
    * 优化内存访问模式：避免随机访问，尽量使用顺序访问。
    * 调整工作集大小：使工作集大小符合缓存大小。

**Barnes-Hut算法**

* Barnes-Hut算法是一种常用的天体物理学模拟算法。
* 该算法可以将复杂的星系模型分解为多个简单的子模型，然后分别进行计算。

* 并行化Barnes-Hut算法可以提高计算速度。

**任务分配与平衡**

* 在并行编程中，任务分配与平衡是重要的问题。
* 任务分配与平衡可以提高并行计算的效率。

* 任务分配与平衡的方法包括：
    * 静态任务分配：在程序运行前就将任务分配给处理器。
    * 动态任务分配：在程序运行过程中根据需要动态分配任务。

## 09 Workload Driven Performance Evaluation

**工作负载驱动的性能评估**

* 工作负载驱动的性能评估是指根据工作负载的规模和特点，选择合适的性能评估方法。

* 常见的工作负载规模包括：
    * 问题尺寸尺度：保持问题规模不变，增加处理器数量。
    * 时间尺度：保持计算时间不变，利用更多处理资源解决更大规模的问题任务。
    * 内存尺度：利用更多处理器扩大内存容量，处理更大规模的数据集。

* 在不同工作负载规模下，算法的性能表现可能不同。

**海洋模拟程序的性能评估**

* 海洋模拟程序是常见的科学计算应用之一。
* 在问题尺度驱动下，随着处理器数量增加，计算/通信比例下降。
* 在时间尺度驱动下，问题规模随处理器数增加的幅度慢于问题尺度驱动。
* 在内存尺度驱动下，可以处理多个不同规模数据集。

## 10 Snooping Based Cache Coherence

**缓存一致性问题**

在多核处理器系统中，每个处理器都有自己的私有缓存，这意味着每个处理器可能拥有相同内存地址的数据的不同副本。如果一个处理器对某个数据进行写操作，而其他处理器仍然使用旧的值，就会产生缓存一致性问题。

**一致性内存系统**

一致性内存系统是指所有处理器中的缓存数据都保持一致的系统。在一致性内存系统中，如果一个处理器写了某个地址的值，其他处理器后续读这地址时应该返回写值。

**解决方案**

缓存一致性问题可以通过以下方式解决：

* 使用共享缓存：所有处理器共享一个缓存，这样所有处理器都拥有相同的内存数据。
* 使用缓存一致性协议：在缓存一致性协议中，每个处理器都维护一个状态机来跟踪其缓存中数据的状态。当发生缓存一致性事件时，处理器会根据状态机进行相应的操作。

**缓存一致性协议**

缓存一致性协议是解决缓存一致性问题的一种常用方法。常见的缓存一致性协议包括：

* 缓存同读协议：当一个处理器读取某个地址的数据时，它会向其他处理器发送请求，以确认其他处理器是否也拥有该数据。
* 目录协议：在目录协议中，每个处理器都有一个目录，用于跟踪共享数据的所有拷贝。当发生缓存一致性事件时，处理器会向目录进行更新。

## 11 Directory Based Cache Coherence

#### 基本思想

目录式缓存一致性是多处理器系统中实现缓存一致性的一种方法。其基本思想是为每段内存使用一个目录结构来跟踪其拷贝的位置。

#### 基本协议

目录式缓存一致性的基本协议如下：

* 读操作：如果数据在缓存中，直接返回缓存中的数据；如果数据不在缓存中，从主存中读取数据，并将数据更新到请求处理器的缓存中。
* 写操作：将数据写入主存，并将所有缓存中的数据标记为无效。

#### 优化方法

目录式缓存一致性存在目录过大的问题。为了解决这个问题，可以使用以下优化方法：

* 使用混合方案处理本地和全局拷贝：对于本地拷贝，可以直接使用标记来表示其状态。对于全局拷贝，仍然使用目录来跟踪。
* 使用指针表示部分拷贝：如果某段数据被多个处理器共享，但只有部分处理器对其进行写操作，那么可以使用指针来表示这些拷贝的位置。
* 使用链表表示所有拷贝：如果数据的拷贝数量很大，可以使用链表来表示所有拷贝的位置。

#### 性能提升

目录式缓存一致性的协议流程比较复杂，可以通过以下方法来提升性能：

* 并行处理共享转换：在执行共享转换时，允许不同处理器并行执行，而不是顺序执行，从而缩短整个协议执行时间。

#### 实现

Intel多核CPU的缓存一致性实现使用层次式总线和目录 agent。在每个处理器上都有一个目录 agent，负责管理该处理器上的缓存数据。当发生缓存一致性事件时，目录 agent会向其他处理器发送请求或通知。

## 12 Basic Snooping Based Multiprocessor Implementation

**缓存一致性协议**

缓存一致性协议是多处理器系统中保证不同处理器间缓存数据一致性的一种方法。在缓存一致性协议中，每个缓存行都具有以下状态：

* 无效：缓存行中的数据不存在。
* 共享：缓存行中的数据与其他处理器共享。
* 独占：缓存行中的数据仅在当前处理器中存在。

**并发问题**

在多处理器系统中，可能出现以下并发问题：

* 死锁：多个处理器相互等待对方释放资源，导致系统无法继续运行。
* 活锁：多个处理器不断尝试获取资源，但始终无法获取，导致系统资源无法有效利用。
* 饥饿：某个处理器长时间无法获取资源，导致该处理器无法执行。

**总线**

总线是一种常用的多处理器系统中的通信链路。总线工作原理如下：

* 总线由多个端口组成，每个端口连接一个处理器或其他设备。
* 处理器通过发送总线请求来使用总线。
* 总线仲裁器负责对总线请求进行仲裁，以确保总线的正常使用。

**缓存初始化读取数据**

在采用原子总线的情况下，缓存初始化读取数据的整个流程如下：

1. 处理器获取总线权限。
2. 在总线上发送读请求地址。
3. 总线仲裁器将读请求转发给所有处理器。
4. 所有处理器检查请求地址对应的缓存行。
5. 如果处理器的缓存行中没有对应的数据，则从主存中读取数据。
6. 处理器向总线仲裁器发送读响应数据。
7. 总线仲裁器将读响应数据转发给所有处理器。

## 13 Memory Consistency + Exam 1 Review

#### 概述

内存一致性模型是指不同处理器或线程访问共享内存时，对内存读写操作的顺序约束。

#### 缓存一致性协议

缓存一致性协议是内存一致性模型的一种实现方式，它确保不同缓存对同一地址的读写操作保持一致性。

#### 内存一致性模型

内存一致性模型可以分为以下几种：

* **顺序一致性模型**：保证程序中读写指令的顺序执行。
* **宽松一致模型**：允许不同地址间读写顺序的重新排列。

###### 顺序一致性模型

顺序一致性模型是内存一致性模型的一种严格的模型，它保证程序中读写指令的顺序执行。

在顺序一致性模型下，如果一个线程写入了一个变量，那么其他线程读取该变量时，一定会看到写入后的值。

###### 宽松一致模型

宽松一致性模型是内存一致性模型的一种松散的模型，允许不同地址间读写顺序的重新排列。

在宽松一致性模型下，如果一个线程写入了一个变量，那么其他线程读取该变量时，可能看到写入前的值。

#### 面试题

从一条写指令发出到完成的整个过程可以分为以下几个步骤：

1. 指令发出：处理器将指令发送给内存控制器。
2. 数据写入：内存控制器将数据写入主存。
3. 缓存更新：内存控制器将写入的数据刷新到缓存。
4. 指令完成：处理器接收到内存控制器的完成信号。

## 14 Scaling a Website

#### 概述

网站扩容是指在保证网站性能和可用性的前提下，提高网站的吞吐量和减少 latency 的过程。

#### 网站扩容方法

网站扩容的方法可以分为以下几个步骤：

1. 使用多线程或进程池来分配计算任务。
2. 将计算负载分布到多台机器上。
3. 采用负载均衡来分发请求。
4. 使用数据库分片或读写分离来扩展数据库容量。
5. 采用微服务架构来减少 latency。

#### 挑战

网站扩容需要考虑以下几个挑战：

* 保持会话状态
* 数据库性能
* 成本
## 15 Interconnection Networks

#### 概述

集成电路网络拓扑结构是指集成电路中各个节点之间的连接方式。

#### 网络术语

* **节点**：集成电路中的逻辑单元或模块。
* **链路**：连接两个节点的通路。
* **交换机**：用于转发数据的设备。

#### 常见网络拓扑结构

* **总线**：所有节点共享一条链路。
* **交叉机**：每个节点连接到交叉机。
* **环形网络**：节点通过环形链路连接。
* **网状网络**：节点通过多条链路连接。

#### 现代集成电路网络拓扑结构

* **环形网络**：Intel CPU 中常用。
* **多环网络**：解决网状网络平均通信成本不对称性的问题。
* **树形网络**：适用于分治算法。

## 16 Implementing Synchronization

#### 概述

同步机制是多线程程序中保证线程安全的重要手段。

#### 锁的三个步骤

* **获取锁**：线程在访问共享资源之前，必须先获取锁。
* **等待锁**：如果锁被其他线程持有，则当前线程将进入等待状态。
* **释放锁**：当线程完成对共享资源的访问后，必须释放锁。

#### 忙等待算法

忙等待算法是线程等待锁的一种简单实现。线程在等待锁时，会一直循环检查锁是否已经被释放。

**缺点**：忙等待算法会导致线程占用 CPU 资源，但没有实际进展。

#### 错误的锁算法

以下是一个简单但不正确的锁算法：

```python
def lock(lock):
    if lock.locked:
        print("锁被占用，等待中...")
        while lock.locked:
            pass
    lock.locked = True

def unlock(lock):
    lock.locked = False
```

**错误**：在 `lock.locked` 为 True 时，没有判断线程是否是当前持有锁的线程。因此，其他线程可能会误以为锁已经被释放，从而导致竞态条件。

#### 测试-设置指令

测试-设置指令是一种原子操作，用于测试和设置一个变量的值。在多处理器环境下，测试-设置指令可以保证两个线程同时执行该指令时，只有一个线程能成功设置变量的值。

#### 自旋锁

自旋锁是基于测试-设置指令实现的一种锁。自旋锁的实现如下：

```python
def lock(lock):
    while lock.locked:
        pass
    lock.locked = True

def unlock(lock):
    lock.locked = False
```

**原理**：在 `lock.locked` 为 True 时，线程将一直循环测试该变量，直到变量值为 False。当线程成功获取锁后，将将变量值设置为 True。

#### 性能问题

由于自旋锁会导致线程一直循环测试变量值，因此可能会导致性能问题。

## 17 Fine Grained Sync and Lock Free Programming

#### 概述

在并发编程中，同步机制是保证线程安全的重要手段。传统的同步机制通常使用全局锁或互斥量来保护共享资源，这种方式的优点是简单易用，但缺点是会导致过度同步，降低并发性能。

细粒度的同步和无锁编程是并发编程中的一个重要方向，它通过降低锁粒度或避免使用锁来提高并发性能。

#### 全局锁

全局锁是指对共享资源使用一个全局锁进行保护。这种方式的优点是简单易用，但缺点是只允许一个线程操作共享资源，会导致并发性能下降。

#### 细粒度的同步

细粒度的同步是指对共享资源使用多个更小粒度的锁进行保护。这种方式的优点是允许多个线程同时操作共享资源的不同部分，提高了并发性能。但缺点是会增加编程复杂度和性能开支。

#### 无锁编程

无锁编程是指在没有使用锁的情况下实现线程安全。这种方式的优点是可以最大限度地提高并发性能。但缺点是实现难度较大，需要对并发编程有深入的理解。

#### Hazard pointers

Hazard pointers 是一种无锁编程技术，它允许部分操作不加锁，降低锁粒度，优化性能。


## 18 Transactional Memory

#### 概述

事务内存机制是并发编程中的一项重要技术，它可以解决使用锁来实现原子操作存在的性能和可扩展性问题。

#### 使用锁的缺点

使用锁来实现原子操作存在以下缺点：

* 会导致过度同步，降低并发性能。
* 会影响锁粒度，导致竞争条件。
* 会增加编程复杂度。

#### 事务的概念

事务是指一组原子操作，要么全部成功，要么全部失败。事务具有原子性、一致性、隔离性和持久性。

* **原子性**：事务中的所有操作要么全部执行成功，要么全部执行失败，没有中间状态。
* **一致性**：事务结束后，数据库的状态必须是一致的，即事务之前的状态和事务之后的状态必须是一致的。
* **隔离性**：事务的执行不能被其他事务干扰，即一个事务的执行不能看到其他事务正在执行的状态。
* **持久性**：事务一旦提交，其结果将持久化到数据库中，即使在系统崩溃的情况下也不会丢失。

#### 事务内存的实现

事务内存可以通过以下方式来实现：

* **数据版本管理**：将数据库中的数据版本化，每个事务都使用不同的版本号来访问数据。
* **冲突检测**：在事务执行过程中，检测并解决事务冲突。

#### 事务的优点

使用事务内存机制可以获得以下优点：

* 提高并发性能
* 降低锁粒度
* 简化编程


## 19 Heterogeneous Parallelism and Hardware Specialization

#### 概述

异构并行系统是指由不同类型的处理器组成的系统，例如 CPU、GPU、FPGA 等。硬件专业化是指为特定任务设计特定的硬件。

#### 单核 CPU 性能利用率低的问题

单核 CPU 的性能利用率很低，因为许多工作负载无法完全并行化。因此，需要采用异构并行系统来提高性能。

#### 选择 CPU 时应考虑的因素

在选择 CPU 时，应考虑以下因素：

* 工作负载的并行度
* 序列化部分和并行部分的平衡
* 成本

#### 现代 CPU 的异构结构

现代 CPU 通常采用异构结构，例如集成图形处理器（GPU）。GPU 专门用于图形处理，具有大量的并行处理能力。

#### 异构系统在手机 SoC 和超级计算机中的应用

手机 SoC 和超级计算机都采用异构设计，以提高性能和节能。

#### Amdahl 定律和性能图

Amdahl 定律指出，系统的总体性能受限于最慢的部分。性能图可以帮助我们分析不同系统的性能。



## 20 Domain Specific Parallel Programming Systems


#### 概述

领域特定并行编程系统（Domain-Specific Parallel Programming Systems）是指针对特定领域的并行编程系统，它通过限制程序的范围，从而可以在这些限定范围内实现更高效的编译优化。

#### 挑战

传统的通用并行编程语言，如 OpenMP、MPI，需要软件开发人员手动进行并行化，这对于复杂的领域特定应用程序来说非常困难。

#### 解决方案

领域特定并行编程系统通过提供领域特定的语法和抽象，可以帮助软件开发人员更轻松地编写并行程序。

#### 例子

* List语言：用于科学计算中对网格结构进行计算，如流体动力学模拟。它隐含定义了网格结构，提供拓扑操作来访问数据，限定了只能访问临近元素，从而编译器可以推导出并行化和数据依赖关系。
* Halide语言：用于图像处理。

#### 使用List语言编译程序运行在CPU和GPU上的不同方法

* 在CPU集群上，需要考虑如何划分网格进行分布，以及不同分区之间的同步问题。
* 在GPU上，可以将边循环并行化，每个线程执行一个边，需要考虑同一个顶点被多个边更新的同步问题。


## 21 Domain Specific Programming on Graphs

#### 概述

域特定图处理系统（Domain-Specific Graph Processing Systems）是指针对图处理应用程序的编程系统，它通过提供图处理特定的语法和抽象，可以帮助软件开发人员更轻松地编写图算法。

#### 设计考虑

在设计域特定图处理系统时，需要考虑以下因素：

* 基本操作：系统应该提供哪些基本操作来支持图算法？
* 优化：系统应该提供哪些优化来提高性能？
* 易用性：系统应该易于使用，降低开发人员的负担。

#### 例子

* Ligra系统：使用vertex map和edge map操作来实现图算法。
* GraphLab系统：定义了图数据结构及vertex programs来描述每个节点的操作。它支持在集群和单机上并行运行程序。

#### GraphLab实现PageRank算法

GraphLab实现PageRank算法使用了Gather、Apply等操作来描述每个节点的计算逻辑。程序通过迭代运行来求解PageRank。


## 22 Spark


#### 概述

Spark 是用于大数据处理的开源框架，它提供了比 MapReduce 更高效的计算模型和运行机制。

#### MapReduce 编程模型

MapReduce 是 Hadoop 框架的基础，它是一种用于分布式计算的编程模型。MapReduce 程序由两个阶段组成：Map 和 Reduce。

* Map 阶段将输入数据映射到中间结果，每个键对应一个值。
* Reduce 阶段将中间结果根据键进行聚合，计算出最终结果。

#### Spark 编程模型

Spark 编程模型基于内存计算，它可以将中间结果保存在内存中，避免多次读写磁盘，从而提高性能。

Spark 提供了丰富的 API，可以用来编写各种数据处理应用程序，包括批处理、流式处理、机器学习等。

#### MapReduce 和 Spark 的比较

MapReduce 和 Spark 都是用于大数据处理的框架，但它们在以下几个方面存在差异：

* 计算模型：MapReduce 基于磁盘计算，Spark 基于内存计算。
* 编程模型：MapReduce 提供较为简单的编程模型，Spark 提供了更丰富的 API。
* 性能：Spark 的性能比 MapReduce 更高。

#### 迭代计算

MapReduce 的迭代计算效率较低，因为每次迭代都要将中间结果保存到磁盘，然后再次读取到内存中。

Spark 通过 RDD 的 checkpoint 机制来解决迭代计算效率低的问题。RDD 的 checkpoint 机制将 RDD 中的数据保存到磁盘，这样在下次迭代时，就可以直接从磁盘中读取数据，无需重新计算。



## 23 Addressing the Memory Wall


#### 概述

计算机内存系统是计算机系统中的重要组成部分，负责存储程序和数据。内存系统的性能直接影响计算机系统的整体性能。

#### 内存访问成本

内存访问成本主要包括延迟和功耗。内存访问延迟是指从 CPU 发出内存访问请求到数据返回的时间。内存访问功耗是指内存访问过程中消耗的电能。

#### DRAM 内存数组

DRAM 是目前计算机系统中使用最广泛的内存类型。DRAM 内存数组由行、列和缓冲区组成。

* 行：DRAM 内存数组中的最小存储单元是行。
* 列：DRAM 内存数组中的行由列组成。
* 缓冲区：DRAM 内存控制器会将最近访问过的数据缓存在缓冲区中，以提高内存访问性能。

#### 软硬件协作优化

软硬件协作可以有效地提高内存访问性能。

* 利用地域性 caching：CPU 会将经常访问的数据缓存在 CPU 的缓存中，以减少对内存的访问次数。
* 跨越多行合并读写：DRAM 内存控制器可以合并多个内存访问请求，以减少内存访问延迟。

#### 存储器控制器

存储器控制器负责管理内存与 CPU 之间的数据传输。存储器控制器可以组织多个 DRAM 芯片，形成更宽带宽的内存通道。

#### GPU 等多核系统

GPU 等多核系统中，每个核心都有自己的内存控制器。内存控制器可以独立地访问内存，以提高内存访问性能。

## 24 The Future of High Performance Computing

#### 概述

高性能计算（High-Performance Computing，HPC）是指利用大型计算机系统来解决复杂、计算量大的问题。

* 介绍了国际科技政策办公室关于 HPC 的战略研究，并讨论了美国政府在此方面的重点投入。
* 比较了目前两种主流的 HPC 架构：超级计算机和互联网数据中心。介绍了它们在计算模型、硬件设计等方面的区别。
* 详细介绍了超级计算机的工作原理、编程模型等技术细节。包括使用 MPI、OpenMP、CUDA 来编程多核 CPU 和 GPU。
* 介绍了 MapReduce 和 Spark 等数据并行计算框架，以及它们在大数据场景下的应用。
* 分析了两种架构各自的优劣势，并预测它们未来会在一定程度上融合，如将数据分析技术融入模拟计算等。
* 讨论了 HPC 软硬件的可靠性、伸缩性等挑战。

## 25 Trends in Deep Networks

#### 概述

深度卷积神经网络（Deep Convolutional Neural Networks）是一种用于图像识别、自然语言处理等任务的深度学习模型。CNN 通过卷积层和池化层来提取图像中的特征，然后通过全连接层进行分类。

#### 内容
* 神经网络的基本工作原理：线性变换加非线性激活。
* 卷积层和池化层的概念和作用。
* 一些经典 CNN 网络的结构。
* CNN 在不同层次提取的特征。

## 26 Parallel Deep Network Training

#### 概述

深度学习网络训练通常需要大量的计算资源和时间。并行计算是提高深度学习网络训练效率的有效手段。
#### 内容
* 反向传播算法
* 并行计算的需求
* 单机多核并行计算
* 分布式并行计算
* 实现细节


## 27 Parallelizing the Graphics Pipeline

#### 概述

图形渲染管线是将三维模型渲染为二维图像的过程。该过程通常需要大量的计算资源，并行计算是提高图形渲染效率的有效手段。

#### 内容

* 图形渲染管线的基本概念
* 深度测试和遮蔽的算法实现
* 固定函数硬件优化带宽
* 深度/颜色值压缩算法


## 28 Course Wrap up and Project Presentations

#### 概述
* 课程考试反馈
* 项目报告要求
* 项目报告准备建议
* 项目报告流程

#### 内容
1. 课程考试反馈：老师询问学生对考试的反馈，并说明试卷难易程度。
2. 项目报告要求：老师提醒学生项目报告将在 5 月 9 日进行，分六到七分钟个人报告。报告将决定部分奖品，但不影响分数。
3. 项目报告准备建议：老师给出项目报告准备的一些建议，包括报告要清晰为主，选择重点，提供论据证明工作完成得好等。
4. 项目报告标题：老师分享一些学生过去项目报告的例子，指出好的报告标题可以概括报告内容。
5. 项目报告流程：老师具体解释如何设置问题、目标、难点，展示结果和分析等报告流程。


## CMU 15-418＼618 Student Presentations

#### 概述
* 会议流程和奖品安排
* 四个项目组的报告

#### 会议内容

1. 主持人介绍会议流程和奖品安排。会议采取 8 分钟报告 + 5 分钟问答的形式，各组报告之间会选出获奖项目。
2. 第一个项目组报告了他们开发的分布式并行计算框架 Gregor。他们介绍了优化步骤，并与 Silk 框架进行性能对比。
3. 第二个项目组报告了针对 Raspberry Pi 内置视频核心 GPU 开发的并行计算库 Kiny。他们介绍了 GPU 架构，并展示了如何使用操作和函数简化编程。
4. 第三个项目组报告了他们在药品设计领域的一个 Virtual Screening 软件的 GPU 优化。他们介绍了算法细节和不同优化方案的效果。
5. 第四个项目组报告了针对返回定向攻击算法开发的并行搜索生成器。他们展示了实时攻击演示。
