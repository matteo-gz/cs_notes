video : https://www.youtube.com/playlist?list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0

Neural Networks and Deep Learning (Course 1 of the Deep Learning Specialization)

# 1. Welcome (Deep Learning Specialization C1W1L01)

## 前言

深度学习已经改变了传统的网络搜索和广告业务。深度学习还可以开发新的产品和行业,帮助人们更好地生活。

## 应用领域

深度学习在以下领域表现出色:

- 医疗保健,尤其是阅读X光图片
- 个性化教育
- 精细农业
- 自动驾驶车込

## 这门课程的目的

学习深度学习工具,将其应用到实际项目中开发惊人产品。完成五门Coursera专项课后,你可以自信地在简历上加上深度学习技能。

## 第1门基础理论课程

了解神经网络和深度学习的基础知识。可以构建分类猫图片的神经网络。四周的学习内容包括:

- 如何构建神经网络
- 如何训练网络学习数据 
- 设计网络架构

## 第2门实用技术课程 

学习获得性能的实用技巧:

- 超参数调优
- 正则化
- 诊断技巧
- 优化算法如Momentum, RMSprop等

## 第3门项目结构课程

深度学习项目的最佳实践已经更新:

- 数据preprocess
- holdout验证集
- 训练样本与测试样本分布不同的问题
- 端到端深度学习

## 第4门卷积神经网络课程

学习CNN应用于图像分类。

## 第5门序列模型课程 

学习RNN、LSTM等序列模型用于自然语言处理。

# 2. What is a Neural Network? (C1W1L02)

##### 单个神经元
使用一个神经元可以建立一个简单的神经网络来预测房屋价格。输入是房屋面积,输出是房屋价格。神经元执行线性函数计算价格,取最大值为0得到S形曲线。

##### 神经网络
通过堆叠多个单个神经元可以构建更大的神经网络。例如,预测房屋价格不仅从面积,还考虑卧室数、家庭人数、邮政编码(房屋位置)等特征。每个特征对应一个神经元,所有特征共同输入后神经网络可以学习出函数映射特征到价格。

##### 神经网络工作原理
神经网络由输入层、隐藏层和输出层组成。输入层对应特征数据,输出层对应目标变量。隐藏层中的每个节点都会接受所有输入特征,神经网络通过大量训练样本自动学习隐藏层中的权重,映射输入到输出。

##### 神经网络应用
神经网络在监督学习任务中表现最好,比如通过输入特征预测输出目标。它可以学习出复杂非线性函数,从多维输入空间到输出空间的映射关系。常见应用包括图像分类、语言处理等。
# 3. Supervised Learning with a Neural Network (C1W1L03)

监督学习是目前神经网络取得经济价值的主要方式。在监督学习中,你有一些输入X,目标是学习一个函数将其映射到一些输出Y。

例如,住房价格预测中的输入包含房屋特性,输出预测价格。神经网络在以下应用都显示出很好的效果:

- 在线广告排名预测用户点击广告的可能性,大幅提升盈利。

- 物体识别识别图片中的物体类目。 

- 语音识别将音频转写为文本。

- 机器翻译将一种语言转为另一种语言。

- 自动驾驶通过多种输入预测障碍物位置。

神经网络的价值来自于智能选择X和Y,并将监督学习模块嵌入更大系统中。

不同任务使用不同网络结构:

- 实操数据常用标准网络  
- 图像识别用卷积神经网络
- 序列数据如音频用循环神经网络
- 复杂任务可能使用混合网络

结构化数据如数据库每项特征含义明确;非结构化数据如音频图像难以直接理解,但神经网络提升了非结构化数据学习能力。

神经网络成功应用于结构化和非结构化数据,创造巨大商业价值。
# 4. Why is deep learning taking off? (C1W1L04)

深度学习技术已经在几十年前就被提出,但为何最近几年才真正流行起来?这主要取决于以下几个方面:

1. 数据规模。随着数字化进程的不断深入,为许多任务我们不再只拥有有限的数据,而是拥有大量的数据。这就需要一个算法来更好地利用这些数据。

2. 计算能力。近年来GPU等高性能计算设备的出现,使我们能够训练更大更深的神经网络模型。

3. 算法进步。例如将激活函数从sigmoid函数改为ReLU函数,可以让模型训练更快。这些算法进步促进了计算能力的提升。

4. 数据影响模型效果的关系。小量数据下,传统算法与深度学习算法效果差异不大。但数据量越大,深度学习算法效果会明显优于传统算法。

5. 循环迭代提高模型效果。计算能力的提升使实验循环更快,有利于神经网络模型不断演进。

总之,数据集规模的不断扩大,计算能力的激增,以及深度学习算法不断优化,共同推动了深度学习在近年迅速发展。未来这些驱动力还将持续推动深度学习技术实用水平的提高。
# 5. About This Course (C1W1L05)

# 6. Course Resources (C1W1L06)

若有任何问题或需要与同学或讲师讨论,最好的地方是论坛讨论区。讲师会定期回复论坛,同学也可以在这里获取答案或回答同学的问题。

从课程首页左侧菜单可以进入论坛讨论区。

如有需要直接联系讲师,也可以邮件此邮箱。讲师将读每封邮件,努力解答常见问题,但可能无法对每封邮件及时回复。

若公司有需对百名以上员工进行深度学习培训,也可以通过此邮箱寻求协助。

如果大学教师或管理人员有意在本校开设深度学习课程,同样可以通过此邮箱联系。

希望以上资源能帮助完成本课程。如有同学在论坛交流,也希望能见面。
# 7. Binary Classification (C1W2L01)

## 二分类问题

采用图像分类作为示例,输入为图像像素值形成的特征向量X,输出为类别标签Y,取值为0或1,表示是否为猫图。

## 数字图像表示

数字图像通常用三个矩阵分别记录红、绿、蓝三个颜色通道的像素强度值。将三个矩阵展开成一维特征向量X。

## 训练数据表示

每个训练样本为一对(X,Y)。整个训练样本集表示为矩阵X和向量Y。X为特征维数×样本数矩阵,Y为1×样本数矩阵。

## 符号表示

- n:特征维数
- M:样本数 
- Xi:第i个样本特征向量
- Yi:第i个样本标签
- X:特征矩阵
- Y:标签向量

二分类任务的目标是学习一个分类器,对新样本X进行预测,输出类别标签Ŷ。
# 8. Logistic Regression (C1W2L02)

 logistic回归是一种学习算法,用于解决输出标签y都是0或1的二分类问题。给定输入特征向量x(可能对应于要识别为猫图片或不是猫图片的图片),它可以输出预测y^表示x图像的类别概率。

在logistic回归中,参数包括权重向量w(与x维数相同)和偏置项b(一个实数)。采用sigmoid函数将线性组合w^T x + b映射到0-1区间,从而得到预测y^作为y=1的概率。

sigmoid函数定义为σ(z)=1/(1+e^-z) ,它是一个S形曲线,随z从负无穷到正无穷 smoothly变化从0到1。其中z表示w^T x + b。

当z较大时,e^-z很接近0,σ(z)很接近1;当z较小时,e^-z很大,σ(z)很接近0。这样σ(z)就可以很好地表示0-1概率。

训练 logistic回归需要定义损失函数,然后根据损失函数最小化w和b,使预测y^尽可能接近真实标签y。

除了通常使用的w和b表示权重向量和偏置外,有些文献也使用θ来统一表示,其中θ0对应的是b,θ1到θn对应w的各分量。但本课程中我们直接使用w和b这种表示方式。
# 9. Logistic Regression Cost Function (C1W2L03)

在上一个视频中,你看到了logistic回归模型。为了训练模型的参数W和B,需要定义一个成本函数。

 logistic回归中的预测输出Y hat定义为:

Y hat = σ(W^T X + B) 

σ代表sigmoid函数。 

一个训练样本集包含M个训练示例。我们希望找到W和B,使得模型在训练样本上的预测Y hat尽可能接近ground truth标签Y。

每个训练示例用下标i表示,其预测输出为:

Y hat^i = σ(W^T X^i + B)

下标i代表数据与第i个训练示例有关。

我们需要定义一个损失函数来衡量预测输出Y hat与真实标签Y的差异。直接使用平方误差可能不行,因为它会导致梯度下降的优化问题非凸。

Logistic回归使用以下损失函数:

L = -y log y hat - (1-y) log(1-y hat)

intuition:
如果y=1,希望y hat尽可能接近1。如果y=0,希望y hat尽可能接近0。

成本函数J衡量整个训练样本集上的损失,定义为:

J = -1/m ∑L

其中L代表单个训练示例的损失,m代表训练样本数量。

训练的目标是找到W和B,使得J最小。下一视频将看到Logistic回归可以视为一个简单的神经网络。
# 10. Gradient Descent (C1W2L04)

梯度下降算法可以用来训练逻辑回归模型的参数W和B。具体来说:

- 逻辑回归模型预测输出为yhat=sigmoid(W^Tx + B)
- 成本函数J(W,B)衡量参数W和B在整个训练数据集上的效果
- 我们希望找到一个W和B最小化J(W,B) 
- 梯度下降算法初始化W和B,然后不断更新它们来减小J(W,B)

梯度下降的每一步包括:

1. 计算J(W,B)对W和B的导数,即∂J/∂W 和 ∂J/∂B
2. 使用W:=W-α×∂J/∂W和B:=B-α×∂J/∂B公式更新W和B  
(α是学习率,控制更新步长)

重复这个过程,参数W和B就会越来越接近最小化J(W,B)的最优值。

在代码实现时,我们使用DW代表∂J/∂W,DB代表∂J/∂B。

对很多人来说,导数概念可能比较陌生。但只需要知道它描述函数在某点的斜率,就能理解梯度下降算法是如何利用此性质优化参数的。实际上,即使不太了解导数的数学含义,也可以用梯度下降有效训练模型。
# 11. Derivatives (C1W2L05)

导数提供了函数在某个点附近的斜率信息。通过计算导数,我们可以推导出函数在该点的增长率。

对于线性函数f(a)=3a,我们找出一些点如a=2时,f(a)=6。然后将a向右移动很小量,如0.001,则a变为2.001,f(a)变为6.003。由此我们看出,随着a向右移动0.001,f(a)向上移动0.003,即三倍于a的变化量。所以我们可以得出此函数在a=2时的导数为3,记为Df/Da=3。

同理当a=5时,f(a)=15,若a向右移动0.001,f(a)会增加0.003,所以此函数任意点的导数都是3。

更正式地,导数定义为函数在无限小量Δa移动时函数的增量与Δa之比。但为了直观理解,我们用有限小量0.001来展示。 

一些重要特点:

- 导数代表函数在某点的切线斜率,即Slope。

- 对于直线函数,导数在任意点都相同。 

- 导数的计算为高度变化/宽度变化。

下一课将看更复杂的非线性函数,其导数在不同点可能不同。
# 12. More Derivative Examples (C1W2L06)

## 基本概念

- 导数表示函数在某一点的切线斜率,称为该点的导数。

- 对一个函数,其导数可以在不同点取不同值。

- 如f(x)=x^2,当x=2时,f'(x)=4;当x=5时,f'(x)=10。

## 计算导数

- 若知道某函数的表达式,可以查阅微积分教科书获得该函数的导数公式。

- 如f(x)=x^2,教科书告诉我们f'(x)=2x。

- 也可以通过计算极限的方法直接求导。

## 例子

### 1. f(x)=x^2

- 当x=2时,f(x)=4,将x稍微增加到2.001时,f(x)约等于4.004。

- 根据f'(x)=2x,当x=2时,f'(x)=2×2=4,与实际切线斜率吻合。

### 2. f(x)=a^3 

- 当x=2时,f(x)=8;将x增加到2.001时,f(x)约等于8.012。

- 根据f'(x)=3a^2,当x=2时,f'(x)=3×2^2=12,预测f(x)将增加12倍,与实际吻合。

### 3. f(x)=logx

- 当x=2时,f(x)约为0.693;将x增加到2.001时,f(x)约为0.693+0.005。

- 根据f'(x)=1/x,当x=2时,f'(x)=1/2=0.5,预测f(x)将增加0.5倍,也与实际吻合。

# 13. Computation Graph (C1W2L07)

一个神经网络的计算都可以通过前向传播步骤和后向传播步骤来组织。前向传播步骤计算网络的输出,后向传播步骤计算梯度来计算导数。

计算图解释了为什么需要这种组织结构。我们通过一个例子来说明计算图:

假设我们要计算函数J,它依赖于3个变量a,B,C。函数定义为:J = 3a + B*C

计算J有3个步骤:

1. 计算B*C,结果存储在变量u中。 

2. 计算a + u,结果存储在变量V中。

3. 计算3V,即最终的J值。

我们可以用有向图来表示这3个步骤:

- 图中有3个节点a,B,C作为输入

- 节点u表示B*C的计算,输入节点是B,C

- 节点V表示a + u的计算,输入节点是a,u  

- 节点J表示3V的计算,输入节点是V

例如,如果a=5,B=2,C=3,则:

- u = B*C = 2*3 = 6
- V = a + u = 5 + 6 = 11 
- J = 3V = 3*11 = 33

计算图可以对特定的输出变量J进行组织。通过左到右的传播可以计算J的值。后面的视频将介绍如何通过右到左的传播来计算导数。
# 14. Derivatives With Computation Graphs (C1W2L08)

在上一视频中,我们用计算图来计算函数J。现在,我们用计算图来计算J的导数。

我们给出一个计算图,想计算J对B的导数。我们知道,如果改变B的值,那么J的值也会改变。J定义为u×C,现在B的值为11,如果把B增大到11.001,那么u会增大到11.001×C,然后J会增大到原来的3倍。所以J对B的导数等于3。

同样,我们可以计算J对a的导数。如果增加a的值,那么B的值也会增加,通过B来增加J的值。计算J对a的导数应用链式法则:J对a的导数等于J对B的导数乘以B对a的导数。我们知道J对B的导数是3,B对a的导数是1。所以J对a的导数也等于3。

我们可以继续 backward 计算图中其他变量的导数,比如u,B,C等变量的导数。

在实现反向传播时,我们通常把最后的输出变量称为d_hat,即J这里。我们计算各中间变量的导数时,也使用类似的概念,比如计算J对u的导数写成d_u等。

所以通过计算图,我们可以从右到左高效地计算所有导数,这就构成了反向传播算法的基础。
# 15. Logistic Regression Gradient Descent (C1W2L09)

## 梯度下降实现逻辑回归

逻辑回归的预测值$y_{hat}$定义为:

$$
y_{hat} = \sigma(z)
$$

其中$z$是:

$$
z = w_1x_1 + w_2x_2 + ... + w_nx_n + b
$$

单例训练loss定义为:

$$ 
L(a,y) = -ylog(a)-(1-y)log(1-a)
$$

其中$a$是预测值$y_{hat}$

### 计算损失关于a的导数

$$
\frac{\partial L}{\partial a} = -\frac{y}{a}+\frac{1-y}{1-a}
$$

### 向后传播

计算$a$关于$z$的导数:

$$
\frac{\partial a}{\partial z}=a(1-a)
$$

使用链式法则得:

$$
\frac{\partial L}{\partial z} = \frac{\partial L}{\partial a}\frac{\partial a}{\partial z}=a-y
$$

### 计算参数更新

$$
\begin{align}
\frac{\partial L}{\partial w_1}=x_1\frac{\partial L}{\partial z}\\
\frac{\partial L}{\partial w_2}=x_2\frac{\partial L}{\partial z}\\
\frac{\partial L}{\partial b}=\frac{\partial L}{\partial z}
\end{align}
$$

参数更新过程:

$$
\begin{align}
w_1&=w_1-\alpha \frac{\partial L}{\partial w_1}\\  
w_2&=w_2-\alpha \frac{\partial L}{\partial w_2}\\
b&=b-\alpha \frac{\partial L}{\partial b}
\end{align}
$$

对整个训练集训练需要对每个样本重复此过程。
# 16. Gradient Descent on m Examples (C1W2L10)

 logistic回归使用梯度下降算法进行优化时,需要考虑所有的训练实例。

## 定义代价函数

代价函数J表示所有训练实例平均损失的和:

J = (1/m) * Σ(i=1 to m) L(ai,yi)  

其中:

- m为训练实例数量
- L(ai,yi)表示实例i预测值ai与真实值yi之间的损失
- ai表示实例i的预测值,通过zi=wTx+b计算得到,其中w为权重向量,b为偏置,x为实例特征  

## 计算每个实例的梯度

前面视频已经介绍过如何对单个训练实例i计算损失L(ai,yi)对zi,w,b的梯度。

## 对所有实例求和

由于代价函数J是所有实例损失的平均值,所以J对w,b求导也是每个实例求导值的平均。

具体来说,如果对单个实例i,损失L(ai,yi)对w1的求导为dW1^i,则:

∂J/∂w1 = (1/m) * Σ(i=1 to m) dW1^i

## 实现梯度下降

按照这个思路,可以实现一个完整的梯度下降算法,实现单次迭代的具体步骤为:

1. 初始化J,dw1,dw2,db等累加变量
2. 对每个训练实例i
   - 计算zi,ai等中间变量 
   - 计算损失函数对zi的导数dzi
   - 计算dw1,dw2,db等权重梯度的累加项
   - 将其累加到dw1,dw2,db等变量中
3. 对dw1,dw2,db等累加变量进行缩放(除以实例总数m)
4. 根据梯度下降方程进行w,b的更新
# 17. Vectorization (C1W2L11)

向量化是去除python代码中的显式for循环,以提升代码运行效率。在深度学习中,常需要处理大量数据,训练速度直接影响研究效率。

逻辑回归计算Z=W^T*X+B,向量化实现是使用np.dot(W,X),直接计算矩阵乘法。非向量化实现需要for循环累加每个元素,效率低下。

示例中创建了两个一百万维随机数组A和B,测试向量化和非向量化版本时间差异。向量化版本使用np.dot(A,B),耗时1.5ms;非向量化版本for循环累加,耗时400ms,较向量化版本慢300多倍。

CPU和GPU都支持SIMD指令集,可以并行计算,利用内置函数比手写for循环效率高。pytorch等深度学习框架底层都实现了向量化。

规则是:尽量避免显式for循环,利用numpy等库支持的广播机制,实现批量计算指令,提升运行效率。这对CPU和GPU都有帮助,GPU执行SIMD指令更快。
# 18. More Vectorization Examples

在上一个视频中,通过使用内置函数来避免明确的for循环,展示了如何显著加速代码。现在通过更多例子来掌握向量化的规则。

如果要计算矩阵A与向量B的积来获得向量u,非向量化版本会初始化u为零向量,并使用双重for循环计算每个元素。向量化版本直接使用np.dot(a,b)计算。

如果想对向量V中的每个元素应用指数运算得到向量u,非向量化版本会初始化u为零向量,并使用for循环一个个计算每个元素。但Numpy提供内置函数np.exp直接完成任务,无需for循环。

还有计算对数、绝对值、最大值等元素级操作都有对应的内置函数,如np.log、np.abs、np.max。

为了消除logistic回归梯度下降算法中的两个for循环,可以将Weight向量DW初始化为零向量,并使用向量运算替代内层for循环。

通过学习和应用这些例子,可以进一步优化代码,甚至全文消除for循环,一次处理整个训练数据集。
# 19. Vectorizing Logistic Regression

在前面的视频中,我们已经讨论了如何通过向量化来加速代码运行。在本视频中,我们将讨论如何将logistic回归实现向量化,以便同时处理整个训练数据集,而不需要使用任何显式循环。

首先,我们看看logistic回归的前向传播步骤。如果有M个训练示例,则计算第一个示例的预测需要计算Z1和a1。同理,计算第二个示例需要计算Z2和a2,以此类推,一共需要M次计算。 

实际上,我们可以用一条代码就同时计算Z1到ZM,即 capital Z。capital Z定义为把小写的Z1到ZM水平堆叠起来。具体实现是:

capital Z = NP.dot(W.T, X) + B

这里W.T X计算W^T * X1, W^T * X2等项,B自动扩充为向量。

同样,我们也可以一条代码计算a1到aM,即 capital A。容A定义为把小写的a1到aM水平堆叠起来。

以上实现完成了Logistic回归的前向传播,同时处理所有M个训练示例,而不需要任何循环。

下面我们将看看如何通过向量化实现后向传播计算梯度。
# 20. Vectorizing Logistic Regression's Gradient Computation (C1W2L14)

Logistic回归的梯度计算可以使用向量化来实现。

在上一视频中,我们通过向量化计算了全部训练样本的预测值A。现在我们来讨论如何同样使用向量化来计算梯度。

我们定义一个向量DZ,它包含所有的小DZ,即DZ1,DZ2等,这是一个1×M矩阵。根据A和Y的定义,我们可以使用一个语句A - Y来计算出DZ。

之前我们对DW和DB进行初始化,之后需要一个循环来分别更新每个训练样本对应的梯度。这里我们通过向量化来消除这个循环。

对DB来说,它实际上是将所有小DZ求和再除以样本数。所以我们可以使用one/m×np.sum(DZ)来实现。

对于DW,根据其定义,它等于1/M×X×DZ^T。所以我们可以使用一条语句1/M×X×DZ^T来实现DW的计算。

将所有部分连接起来,我们可以在没有循环的情况下,通过几条向量运算语句完成Logistic回归一个迭代的前向传播、预测、backward传播和梯度计算。

最后,如果需要多个迭代,我们仍需要一个外循环来控制迭代次数。但这一迭代内部剔除了所有循环,实现了完全向量化。

这利用了广播机制来使计算更高效。下一视频我们将进一步介绍广播机制。
# 21. Broadcasting in Python (C1W2L15)

## 支持广播的操作

Python支持对数组进行element-wise操作时使用广播。当对数、矩阵进行加减乘除运算时,如果维度不匹配,Python会自动广播较小的数组,使其与较大数组匹配。

主要情况包括:

1. M×N 矩阵 对 1×N 向量进行加减乘除运算时,会将1×N向量复制M次,形成M×N矩阵进行操作。

2. M×1 矢量 对 1×1 数进行加减乘除运算时,会将1×1数复制M次,形成M×1矢量进行操作。 

3. M×N 矩阵 对 M×1矢量进行加减乘除运算时,会将M×1矢量复制N次,形成M×N矩阵进行操作。

## 广播的示例

举例来说明广播规则:

- 2×3矩阵对1×3向量进行加法,会将1×3向量复制2次,形成2×3矩阵进行相加。

- 4×1矢量对数100进行加法,会将100复制4次,形成4×1矢量进行相加。

- 3×2矩阵对3×1矢量进行除法,会将3×1矢量复制2次,形成3×2矩阵进行element-wise除法。

## 使用广播计算百分比

给定食物营养素数值的3×4矩阵,利用广播计算每个食物的百分比:

1. axis=0 sum下矩阵每一列,计算各食物总卡路里。

2. 将总卡路里形成1×4矢量。

3. 将原矩阵除以总卡路里矢量,即实现了广播,得到各营养素在总量中的百分比。

这实现了用一行代码聚合计算多个样本,而无需使用循环。
# 22. A Note on Python/Numpy Vectors (C1W2L16)

Python和Numpy的广播特性带来了代码的灵活性,但同时也可能引入难以发现的bug。

比如,如果把列向量与行向量相加,结果可能是一个矩阵,而不是抛出异常。这是因为Python将自动广播向量来匹配维度。

另一用例,如果使用`np.random.randn(5)`生成一个变量`a`,则`a`的形状是`(5,)`,这被称为秩一数组。秩一数组的行为不一致,既不是行向量也不是列向量。

为了避免这些隐蔽的bugs,以下几点建议:

1. 不要使用秩一数组。可以使用形状为`(5,1)`的列向量或 `(1,5)` 的行向量。

2. 添加断言语句检查维度,例如`assert a.shape == (5,1)`

3. 可以使用`reshape`函数将秩一数组转换为矩阵,例如`a = a.reshape((5,1))` 

4. 在需要向量时,选择形状清楚的列向量或行向量,而不是秩一数组

5. print变量来检查其形状和广播行为

采取这些建议可以简化代码,消除由于广播和形状带来的非直观行为所导致的难题bug。
# 23. Quick Tour of Jupyter/iPython Notebooks (C1W2L17)

## Jupyter notebook

在Coursera上可以访问Jupyter notebook。代码块用浅灰色标识,每次只需在星号标记的码头区域编写代码。

## 执行代码

使用Shift+Enter键或单击“运行单元格”按钮运行单元格中的代码。运行时会在服务器上执行。 

## 格式化文本

如果显式为Markdown格式,可以运行“转换回格式化文本”单元来重新渲染。

## 核心死亡

如果核心死亡,可以使用“重启核心”按钮重启。

## 依赖设置

请运行所有授权展示的单元,以导入需要的包和设置变量。

## 提交作业 

完成后单击顶部的“提交作业”按钮提交答案。

## Jupyter优点

交互式环境适合快速学习和试验算法。
# 24. Explanation of Logistic Regression's Cost Function (C1W2L18)

Logistic回归模型预测输出Yhat表示给定特征X时标签Y的概率P(Y=1|X)。 

P(Y=1|X)定义为Sigmoid(WX+B),P(Y=0|X)定义为1-Sigmoid(WX+B)。

可以整合成一个等式:

P(Y|X) = Sigmoid(WX+B) ^ Y * [1- Sigmoid(WX+B)] ^ (1-Y)

取对数可得Logistic回归的成本函数J(W,B) = -1/mΣ[Yilog(Sigmoid(WX+B)) + (1-Yi)log(1- Sigmoid(WX+B))]

其中:

- Sigmoid(z) = 1/(1+e^-z) 是Logistic函数
- m是训练样本数量
- Yi是第i个样本的实际标签值
- WX+B是Logistic模型的预测

最小化这个成本函数相当于通过最大似然估计学习模型的参数W和B,从而使训练数据的概率最大。
# 25. Neural Network Overview (C1W3L01)

## 神经网络与logistic回归的关系

神经网络是通过堆叠多个logistic回归单元来实现的。每个单元都有Z和A两个计算步骤,相当于logistic回归中的两个步骤。

## 神经网络的层数标记

利用方括号来标记不同层对应的量,如Z1、A1是第一层,Z2、A2是第二层。训练样本用圆括号标记,如Xi。

## 神经网络前向计算

输入X经W1、B1计算Z1,通过sigmoid计算A1;A1经W2、B2计算Z2,通过sigmoid计算A2作为输出。

## 神经网络后向计算

计算损失后,利用红色箭头标记的顺序从右到左计算梯度,如dA2/dZ2,以计算dW2、dB2等参数更新。

## 总结

神经网络通过重复logistic回归单元来建模,使用层次索引来区分量,前向后向传播来训练参数。
# Neural Network Representations (C1W3L02)

## 26. 神经网络表示

神经网络包含输入层、隐藏层和输出层。

- 输入层表示特征X。在标注中用X或a0表示。

- 隐藏层用来学习输入特征的非线性组合。在标注中用a1表示。

- 输出层生成预测值Yhat。在标注中用a2表示。

隐藏层的节点值在训练数据中是未观测的,所以叫隐藏层。

隐藏层和输出层对应着参数W和B:

- 隐藏层的参数用W1和B1表示。

- 输出层的参数用W2和B2表示。

这是一个含有单隐藏层的神经网络,所以我们称它为两层神经网络。但是实际上它包含输入层(标为0层)、隐藏层(标为1层)和输出层(标为2层),所以是三层结构。

总体来说,神经网络通过输入层的值a0,经过隐藏层和输出层的计算,生成预测值a2(也就是Yhat)。
# 27. Computing Neural Network Output (C1W3L03)

神经网络如何计算输出值。一个单隐层神经网络的工作原理如下:

隐含层每个节点都包含两个计算步骤:

1. 计算Z值:Z = W^T * X + b

W代表节点对应的权重向量,X代表输入特征,b代表偏置项。

2. 计算激活值:a = σ(Z)

σ代表sigmoid激活函数。

输出层节点也包含这两个计算步骤,但参数W和b的维度不同。

为了向量化计算,可以将每个层的W stacking成矩阵W,b stacking成向量b。则隐含层计算可以表示为:

Z1 = W1 * X + b1
a1 = σ(Z1)  

输出层计算可以表示为:

Z2 = W2 * a1 + b2
Ŷ = σ(Z2)

其中:
- W1为隐含层参数矩阵,W2为输出层参数矩阵
- b1为隐含层偏置向量,b2为输出层偏置量
- X为输入特征,a1为隐含层激活,Ŷ为预测输出

通过矩阵计算实现了任意单输入样本的前向计算。对多个训练样本也可以通过扩充X和Y的维度实现向量化计算。
# 28. Vectorizing Across Multiple Examples (C1W3L04)

在上一视频中,你看到了在单个训练实例上计算新网络预测的方法。在本视频中,你会看到如何在多个训练实例上共享计算,结果与逻辑回归中的做法类似。通过在不同的列中堆叠不同的训练实例,你可以使用从上一视频得到的公式,只做少量修改,就能使神经网络同时计算所有实例的输出。

我们之前得到了4个计算Z1、a1、Z2和a2的等式。它们可以用于给定单个输入特征向量X生成单个训练实例的预测值y^。如果有M个训练实例,就需要重复这个过程计算每个实例的预测值。

为了表示激活函数,我们使用a[2](i)表示第2层的第i个训练实例的激活值。

如果未向量化实现,需要进行M个循环迭代,计算:

z1i = W1*Xi + B1 
a1i = sigmoid(z1i)
z2i = W2*a1i + B2
a2i = sigmoid(z2i)

为了向量化这个过程,我们定义 capital X矩阵将训练实例堆叠在不同列中。然后计算:

Z1 = W1*X + B1  
A1 = sigmoid(Z1)
Z2 = W2*A1 + B2
A2 = sigmoid(Z2)

将小写向量堆叠形成大写矩阵的思路和逻辑回归中的做法相同。

矩阵Z和A在水平方向索引不同的训练实例,在垂直方向索引不同的神经单元。这 providing提供了正确实现向量化计算的方法。

在下一个视频中,我将进一步解释为什么这种向量化实现是正确的,其原理与逻辑回归中的向量化是一致的。
# 29. Explanation For Vectorized Implementation (C1W3L05)

在之前的视频中,我们看到如何使用训练数据集的实例X,通过将它们水平堆叠成矩阵X,从而推导出对多个实例进行网格化的神经网络前向传播实现。

让我们给出更多理由来证明,我们写下的方程是对多个实例进行向量化的正确实现。

假设有三个训练实例,那么:

- 对第一个实例,前向传播计算为:X1 + b1
- 对第二个实例,前向传播计算为:X2 + b1 
- 对第三个实例,前向传播计算为:X3 + b1

这里我们忽略b以便简化解释。

W1是一个矩阵,那么对第一个实例:W1×X1是一个列向量;对第二个实例:W1×X2是一个列向量;对第三个实例:W1×X3是一个列向量。

如果我们将训练数据集X形成的矩阵,通过将每个实例水平堆叠得到:

- 第一个列对应第一个实例的列向量
- 第二个列对应第二个实例的列向量 
- 第三个列对应第三个实例的列向量

这样一来,W1×X就等价于将每个实例的列向量叠加在一起,也即Z1矩阵。

使用相似的逻辑可以证明,我们给出的其他步骤中的方程也是正确的向量化表达。

总之,向量化实现就是通过水平堆叠实例,将实例级运算扩展到整个数据集上。这种方法可以同时对所有实例进行前向传播运算,实现更高效的实现。
# 30. Activation Functions (C1W3L06)

在构建神经网络时,我们可以选择使用什么类型的激活函数。目前常用的激活函数有:

## Sigmoid函数
Sigmoid函数输出范围在0到1之间。主要用于输出层的二分类问题。

## Tanh函数 
Tanh函数输出范围在-1到1之间。对隐藏层来说性能比Sigmoid函数好。

## ReLU函数
ReLU函数输出为max(0,z)。对隐藏层来说性能优于Tanh和Sigmoid函数。微分不连续但在实际应用中影响很小。

## LeakyReLU函数
类似ReLU但在z<0时slope为一个很小的常数,如0.01。在理论上比ReLU好,但在实际应用中效果差异不大。

一般选择:

- 输出层使用Sigmoid函数(二分类问题)
- 隐藏层使用ReLU函数

在实际应用中,我们可以尝试使用不同的激活函数组合来观察效果。ReLU函数是一个不错的默认选择。此外,我们也不需要激活函数的原因将在后面的视频中讨论。
# 31. Why Non-linear Activation Functions (C1W3L07)

若使用线性激活函数或没有激活函数,那么无论神经网络有多少层,它都只能计算线性函数。因为两个线性函数的组合仍然是一个线性函数。所以必须加入非线性激活函数,才能计算更复杂的函数。

如果a1等于z1,a2等于z2,那么这个模型就只输出输入特征x的线性函数。通过替换a1,a2的定义,可以简化为W'x+B',即一个线性函数。

使用线性激活函数后的隐藏层实际上是没用的,因为它只能计算线性函数。除非加入非线性激活函数,否则无法计算更有趣的函数,即使网络更深层也是如此。

除回归问题外,线性激活函数几乎不使用。回归问题中,y可以取任意实数,所以输出层可以使用线性激活函数。但隐藏层仍应使用非线性激活函数,如Relu、Tanh等。

即使在回归问题中,如果y只取非负值,也可以考虑使用Relu激活函数,这样yhat也只取非负值。

最后,为了计算梯度下降,需要了解如何计算不同激活函数的梯度。
# 32. Derivatives Of Activation Functions (C1W3L08)

## Sigmoid函数
Sigmoid函数的导数公式为:
G'(Z) = G(Z) × (1 - G(Z))
其中G(Z)是Sigmoid函数的值

## Tanh函数
Tanh函数的导数公式为: 
G'(Z) = 1 - G(Z)2
其中G(Z)是Tanh函数的值

## ReLU函数
ReLU函数的导数公式为:
G'(Z) = 0, wenn Z <= 0
G'(Z) = 1, wenn Z > 0

## LeakyReLU函数  
Leaky ReLU函数的导数公式为:
G'(Z) = 0.01, wenn Z <= 0
G'(Z) = 1, wenn Z > 0

对常用的激活函数,我们都可以通过计算其导数来实现反向传播中的梯度计算。其中Sigmoid 和Tanh函数的导数公式都可以利用激活函数本身的定义来简化计算。ReLU和Leaky ReLU函数在Z=0点的导数是未定义的,但在实现中选择将其定义为0或1都可以。
# 33. Gradient Descent For Neural Networks (C1W3L09)

创建一个含有单隐藏层的神经网络,参数分别为:

- W1: 维度为 N1 × n0 的矩阵,N1 为隐藏单元数,n0 为输入特征数
- B1: 维度为 N1 × 1 的列向量  
- W2: 维度为 n2 × N1 的矩阵,n2 为输出单元数
- B2: 维度为 n2 × 1 的列向量

前向传播计算过程:

- z1 = W1x + B1
- a1 = 激活函数(z1) 
- z2 = W2a1 + B2
- a2 = 激活函数(z2)

这里假设使用sigmoid函数作为激活函数。

损失函数取平均交叉熵:

Cost = (1/m) ∑L

其中L为每个预测y^与真实标签y之间的损失。

反向传播计算梯度:

- δ2 = a2 - y
- dW2 = (1/m) δ2 a1^T  
- db2 = (1/m) np.sum(δ2, axis=1, keepdims=True)
- δ1 = W2^T δ2 .* G′(z1) 
- dW1 = (1/m) δ1 x^T
- db1 = (1/m) np.sum(δ1, axis=1, keepdims=True)

每个批次进行一步梯度下降更新参数:

- W1 -= α * dW1 
- B1 -= α * db1
- W2 -= α * dW2
- B2 -= α * db2

反复执行更新参数和计算梯度,将模型训练至损失函数收敛。
# 34. Backpropagation Intuition (C1W3L10)

在前一个视频中,你看到了反向传播的公式。在这个视频中,我们来通过计算图来理解这些公式是如何推导出来的。

这个视频完全可选。无论你选择看或者不看,都能实现反向传播。

回顾 logistic 回归时,我们有前向传播算出 Z,然后 A,继而得到损失函数。计算梯度时,我们有反向传播计算 dA,然后计算 GZ,DW和DB。

损失函数定义为:L(a, y) = -yloga - (1-y)log(1-a)

对这个损失函数对a求导,可以得到dA的公式:

dA = y/a - (1-y)/(1-a)

进一步计算,可以得到DZ的公式:

DZ = A - y

这是因为链式法则:DZ = DA × G'(Z),这里G(Z)就是sigmoid作用后的Z。

也就是说,DZ等于DA乘以σ'(Z),σ'代表sigmoid的导数。

回顾一下 logistic 回归,我们有X1,X2,...Xn,然后通过一个sigmoid单元计算出预测值Yhat。

这里激活函数就是sigmoid函数。

继续计算可以得到DW和DB的公式。

neural网络的计算也类似,只不过是一步一步进行:

1. 算出Z1 
2. 通过σ(Z1)算出A1
3. 算出Z2
4. 通过σ(Z2)算出A2 
5. 得到损失函数

反向传播则去算A2、Z2、W2和B2,再算A1、Z1,以及W1和B1。

得到反向传播的6个核心公式。

公式向量化后,对多个样例一起计算,会有1/m的因子。

这样就完成了反向传播算法的推导。推导这个算法需要矩阵计算和求导能力。
# 35. Random Initialization (C1W3L11)

## 重要性随机初始化权重

Logistic回归中把权重初始化为零是可以的,但对神经网络来说会产生问题。如果把所有的参数都初始化为零,然后应用梯度下降,它不会起作用。

## 为什么全部初始化为零不行

如果网络中的W矩阵和偏置向量B都初始化为零,那么所有隐藏单元都会计算出完全相同的功能。 

在反向传播中,每个隐藏单元的导数都会相同。所以网络中所有的隐藏单元实际上都是对称的,计算完全相同的功能。

这就没有必要再加入额外的隐藏单元了,因为它们不会学习到不同的表示。

## 随机初始化解决对称问题

解决这个对称问题的方法是将权重参数随机初始化。

可以使用随机数生成W矩阵,通常这些随机数需要乘以一个很小的常数,如0.01。这可以使参数初始化成很小的随机值。

对偏置向量B初始化为零是可以的,因为只要W矩阵随机初始化,隐藏单元就不会对称了。

这样每个隐藏单元开始时就会学习到不同的功能了。梯度下降也不会使它们再次对称。

## 为什么常数需要较小

如果权重初始化得太大,预测值Z就可能取到很大或很小的值。这可能使激活函数导数近似于0,导致学习极为缓慢。

所以我们选择一个较小的常数如0.01来初始化W,可以避免这个问题。对于更深更广的网络,这个常数可能需要再小一点,如0.001。
# 36. Deep L-Layer Neural Network (C1W4L01)

## 深度学习与浅层学习

深度学习使用多个隐含层来学习更复杂的函数,而浅层模型如逻辑回归难以学习。但是对具体问题,难以预测需要的网络深度。

## 神经网络表示

使用L表示层数,nL表示第L层的节点数。输入为第0层,隐藏层从1到L-1,输出为第L层。

如一个4层网络,输入层n0为3,第一个隐藏层n1为5,第二层n2为5,第三层n3为3,输出层n4为1。

## 前向传播概述

每个层L使用aL表示激活,ZL表示前一层到此层的线性变换,WL表示此变换的参数。
输入X等价于第0层输出a0,输出于最后一层aL,即预测值Yhat。

## 符号定义

使用不同符号来表示网络结构、层数、节点数、激活、参数等,以方便描述前向传播和计算过程。关键符号已列在视频或文档中。

# 37. Forward Propagation in a Deep Network (C1W4L02)

前向传播在深度神经网络中的计算过程如下:

给定单个训练示例X,第一层的激活计算公式是:

Z1 = W1 * X + b1
A1 = G(Z1)

其中,W1和b1是第一层的参数,G是第一层使用的激活函数。

第二层的激活计算公式是: 

Z2 = W2 * A1 + b2
A2 = G(Z2) 

W2和b2是第二层的参数,G是第二层使用的激活函数。

以此类推,最后一层输出层的激活计算公式是:

Z4 = W4 * A3 + b4 
A4 = G(Z4)

通用公式为:

ZL = WL * AL-1 + bL
AL = G(ZL)

对整个训练数据集进行向量化计算时,公式形式相同,但使用矩阵和向量代替标量:

Z1 = W1 * X0 + b1
A1 = G(Z1)

Z2 = W2 * A1 + b2 
A2 = G(Z2)

...

Yhat = A4 = G(Z4)

其中需要使用从1到L的循环来分层计算每个层的激活。这是向量化前向传播的唯一可能的实现方法。
# 38. Getting Matrix Dimensions Right (C1W4L03)

当实现深度神经网络时,我经常使用的调试工具之一就是在纸上绘制各种矩阵和变量的维度,这可以帮助我检查代码是否正确。

本视频将通过一个例子来说明如何检查这些维度。假设网络层数L为5,不包括输入层一共有5个隐藏层与1个输出层。

第一隐藏层的神经元数n1为3。依此类推,n2为5,n3为4,n4为2,n5为1。输入层的特征数n0为2。

前馈传播的第一步是计算第一隐藏层的激活Z1,其公式为Z1=W1×X+B1。

W1的维度必须是n1×n0,即3×2矩阵。更一般来说,层L的参数矩阵WL的维度应该是nL×nL-1。

偏置项B1的维度应为n1×1,即3×1向量。更一般来说,层L的偏置项BL应为nL×1向量。

向量化实现前馈传播时,Z1、X等量的维度会有变化。例如,Z1从n1×1调整为n1×M,其中M是训练集的大小;X从n0×1变为n0×M。

通过检查各种矩阵和向量的维度关系,可以帮助排除实现神经网络时的一类可能错误。
# 39. Why Deep Representations? (C1W4L04)

深度表示网络之所以工作好的原因:

1. 早期层学习简单功能,后期层学习复杂功能。比如物体检测网络,早期层可以学习像素边缘,中期层学习对象部件,后期层学习整体对象。

2. 深度神经网络可以采用分层表示,早期层学习低级特征,后期层通过组合低级特征学习高级特征。这种学习路径对图片、语音等数据都适用。

3. 根据电路理论,有些函数用深度但隐藏单元少的网络计算更简单。比如N个输入变量的异或函数,用深度logN的网络计算代价更低。

4. 人脑开始从视觉输入学习简单特征如边缘,然后学习更复杂的对象。深度学习借鉴了这一点。

5. 深度学习这个词本身就很有吸引力,有利于神经网络技术的推广。尽管深度不一定总比浅度好,但对很多问题,非常深的网络效果会好些。

6. 实践也证明,对某些任务来说,多层神经网络效果比较好。但始终应该先试简单模型,深度作为一个可以调节的超参数。
# 40. Building Blocks of a Deep Neural Network (C1W4L05)

在之前的视频中,您已经学习了前向传播和反向传播的基本组成部分,这些组成部分是实现深度神经网络所必需的。我们来看看如何将这些组成部分组合在一起,构建包含几层的深度网络。

对于网络中的某一层L,它将拥有一些参数WL和BL。在前向传播中,它将使用上一层的激活AL-1作为输入,输出AL。具体来说,它计算ZL=WL×AL-1+BL,然后AL=G(ZL)。此外,还需要缓存ZL,这对后向传播很重要。

在后向传播中,输入daL,输出daL-1。具体来说,它利用caL,WL和BL以计算daL-1。同时,它还计算dL-1WL和dL-1BL,这些导数将被用于梯度下降以学习参数。

将这些组成部分组合在一起,可以实现整个网络的前向和后向传播。具体来说,先使用输入特征a0进行前向传播,计算每一层的激活,同时缓存Z值。然后,使用反向传播顺序计算导数,最终得到所有层的参数更新量。重复这一迭代训练过程,即实现了神经网络的训练。

在实现上,cash不仅包含Z,还包含W和B,这对后向传播传参很方便。总之,每个层次都包含前向和后向传播步骤,cash负责信息的传递,这就是实现深度神经网络的基本结构。
# 41. Forward and Backward Propagation (C1W4L06)

前向传播实现:
- 输入为a(L-1),输出为aL和cache中的zL
- zL = WLa(L-1) + BL
- aL = 激活函数G(zL)  
- 实现forward函数,依次计算各层a

反向传播实现:
- 输入为daL,输出为da(L-1),dWL,DBL
- dzL = daL * G’(zL)
- dWL = (1/m)dzLa(L-1)T  
- DBL = (1/m)ΣdzL
- da(L-1) = WLTdzL

向量化版本:
- dzL = daL .* G’(zL)
- dWL = (1/m)dzL(a(L-1))T  
- DBL = (1/m)ΣdzL
- da(L-1) = WLTdzL

- 初始化backward为softmaxloss输出daL
- 依次调用backward函数计算所有层梯度

实现前向和后向传播算法后,即完成深度神经网络训练。
# 42. Parameters vs Hyperparameters (C1W4L07)

## 什么是超参数

模型的参数包括W和B。除此之外,学习算法还需要其他设置,如学习率α。因为需要设置α,它才可以确定参数的变化。其他如迭代次数、隐藏层数、隐藏单元数、激活函数也都是学习算法需要知道的数值设置。这些参数控制最终的参数W和B,所以称为超参数。

## 超参数的例子

常见的超参数包括学习率α、迭代次数、隐藏层数L、隐藏单元数、激活函数等。未来的课程还会介绍动量项、小批量大小等超参数。

## 调优超参数

应用深度学习是一个经验过程。对新任务来说,很难知道超参数的最佳值。通常需要尝试各种值,观察结果,然后再调整。例如学习率可能适用于0.01,但效果不好则调大到0.05试试。

同一个任务的最佳超参数值也可能随时间而变。每隔一段时间重新试试不同值是否会有更好的效果。

未来可能会给出一些方法系统地探索超参数空间,但目前还需要通过试错来选择值。这也是深度学习研究的一个课题。
# 43. What does this have to do with the brain? (C1W4L08)

- 在实现神经网络时的前向传播和反向传播以及梯度下降与人脑做了类比
- 这类比比较过于简单,难以解释这些算法背后的核心机制
- 单个逻辑回归单元与压缩激活函数与单个人脑神经元有很简单的类比关系
- 但是人脑神经元实际上要复杂得多,我们对它的理解还很有限
- 例如人脑学习的具体机制至今仍然是一个谜
- 至今还不清楚人脑是否采用类似反向传播和梯度下降的学习算法
- 与人脑的类比对于解释早期的人工神经网络还比较有帮助
- 但是随着深度学习的发展,这个类比已开始不再适用
- 很难将深度学习直接与人脑对应起来
