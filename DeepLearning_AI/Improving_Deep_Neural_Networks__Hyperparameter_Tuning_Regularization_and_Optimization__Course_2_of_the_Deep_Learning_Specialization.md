# Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization

 (Course 2 of the Deep Learning Specialization)

> <https://www.youtube.com/playlist?list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc>

## 1. Train/Dev/Test Sets (C2W1L01)

### 分割数据集

在机器学习中,通常会将数据集分割成三部分:

- 训练数据集(training set):用于训练模型
- 验证数据集(dev set或development set):用于调整模型超参数,选择模型等
- 测试数据集(test set):用于评估最终模型的性能

### 不同数据规模的分割比例

对于较小的数据集(如数千个样本), tradition上采用70/30或60/20/20的比例分割。

但对于大数据量(如百万级样本),验证集和测试集的比例可以更小,如1%或者0.25%。这是因为验证集和测试集的规模只需要满足评估模型效果的需求,不需要很大部分数据。

### 分布一致的重要性

尤其应确保验证集和测试集来自同一分布。如果训练数据来源不同于实际应用场景,则验证集和测试集最好也来自实际应用的数据。这有利于选出在实际场景下效果好的模型。

### 无测试集的情况

如果不需要得到最终模型无偏预测性能评估,也可以没有单独的测试集。此时可以将验证集视为测试集来迭代模型选择。

### 总结

正确划分训练、验证、测试集有助于提升深度学习模型迭代效率,选择优良模型。其中验证集和测试集规模的设置,以及它们与训练数据分布一致性,都是影响模型效果的重要细节。

## 2. Bias/Variance (C2W1L02)

机器学习模型在训练数据集上的误差可以用来判断模型是否存在偏差问题或者方差问题。

偏差过大表示模型复杂度不够,无法 sehr 好地拟合训练数据,这称为偏差问题。方差过大表示模型过于复杂,过于依赖训练数据,在测试集上泛化能力差,这称为方差问题。

我们可以通过训练数据集误差和测试集(开发集)误差来判断模型是否存在偏差或者方差问题:

- 如果训练数据集误差大而测试集误差也大,那么模型存在偏差问题。

- 如果训练数据集误差小而测试集误差大,那么模型存在方差问题。

- 如果训练数据集和测试集误差都小,那么模型既没有偏差也没有方差问题。

- 如果训练数据集和测试集误差都大,那么模型同时存在偏差和方差问题。

这种判断需要假设人类水平的误差为零或者非常小。如果人类水平误差实际上较高,那么相应的偏差和方差的判断标准需要调整。

除误差判断外,我们还可以通过二维特征空间中的决策边界来直观地观察模型是否存在偏差或者方差问题。但是在高维输入空间中无法直接观察决策边界,需要依靠误差来判断。

总体来说,通过比较训练数据集误差和测试集误差,可以有效 diagnosed 模型是否存在偏差或者方差问题,以便采取相应的改进措施。

## 3. Basic Recipe for Machine Learning (C2W1L03)

机器学习模型的基本训练流程包括:

1. 训练初始模型后,先判断模型是否存在偏差问题。如果训练精度差但验证集精度也差,则模型存在偏差。

2. 如果存在偏差,应增加模型复杂度,如添加更多隐藏单元或层数,训练更长时间,优化学习算法等。直到模型能较好地拟合训练数据。

3. 判断模型是否存在方差问题。如果训练精度好但验证集精度差,则存在方差问题。

4. 如果存在方差,应获取更多数据进行训练或使用正则化技术来防止过拟合。

5. 根据 judged 的偏差方差情况,选择适当的方法进行优化,例如对偏差问题不应仅增加数据量。

6. 重复执行上述流程,直到模型精度满意,即偏差和方差问题均得到很好解决为止。

此外,深度学习中训练更大的模型或获取更多数据能很好地降低偏差,同时不会显著增加方差。这是深度学习在监督学习上的一个优势。正则化技术也能在一定程度上减少偏差和方差。

总体来说,通过比较训练和验证集误差可以有效诊断模型问题,选择正确的优化方法进行迭代训练,是机器学习的基本流程。

## 4. Regularization (C2W1L04)

如果你怀疑自己的网络过拟合数据,即高方差问题,正则化是第一个应该尝试的方法。

正则化的另一种方法是增加训练数据,但是获取更多数据可能比较困难和昂贵。添加正则化通常能有效防止过拟合或者减小网络中的方差。

最常见的正则化方法是L2正则化。它通过增加一个惩罚项来最小化目标函数:

λ/2m‖W‖^2

这里λ是正则化参数,W是网络的参数矩阵,‖W‖^2代表矩阵W每个元素的平方和,也就是弗洛贝尼乌斯范数。

对于 logistic 回归,L2 正则化同样通过添加惩罚项λ/2m‖W‖^2来最小化目标函数。

使用梯度下降训练网络时,计算对W的梯度GDW需要考虑正则化项。具体来说,GDW被修改为:

GDW + λ/mW

这样网络参数在每次更新后都会减小一点,这就是它被称为权重衰减的原因。

正则化参数λ通常通过 developments 集进行调优。它可以平衡训练集误差和参数范数的大小,从而防止过拟合。

所以总体来说,正则化通过增加参数范数的惩罚项,在每次更新中让参数值越来越小,从而防止网络过度复杂来匹配训练数据的噪声,从而提高泛化能力。

## 5. Why Regularization Reduces Overfitting (C2W1L05)

正则化可以帮助减少过拟合的原因有以下几点:

1. 如果将正则化参数λ设置得很大,网络参数W将强烈倾向于朝零向量靠近。这相当于将许多隐含单元的影响“减弱”或“清零”,从而简化了网络模型。

2. 简化后的网络更像线性回归模型,而线性模型的复杂程度不够高,无法过度拟合数据集。

3. 如果λ很大,参数W将变得非常小。这使得激活函数的输入Z保持在近似线性区域,从而每一层和整个网络都表现出近似线性的特征。这样网络只能实现简单的线性函数,难以过度拟合。

4. 在实际实现中,λ的增大不会真正使W等于零,而是会将每个隐含单元的影响“减弱”。这样网络就像容量更小的模型,过拟合的可能性较低。

5. 正则化项的增加使目标函数增加一个惩罚项,迫使网络在每次迭代中parameter值不断缩小,从而避免过分拟合训练数据中的噪声。

实现正则化时,需要计算新的带正则化项的目标函数J,否则迭代过程中J可能不会单调下降。这是正确评估正则化效果的一个重要提示。

## 6. Dropout Regularization (C2W1L06)

除L2正则化外,dropout也是一种很强大的正则化技术。它的工作原理是:

对每一层网络,对每个节点,随机丢弃一定概率的节点。比如对每个节点,有50%的概率将其保留,50%的概率将其丢弃。

丢弃节点时,会删除该节点所有的进入和 outgoing连接。这样网络结构就被大大简化了。

在训练每个例子时,会使用不同的网络结构。这可以理解为对每个例子训练一个子网络。这有助于正则化整个网络。

实现dropout的常见方法是倒置采样(inverted dropout)。具体步骤是:

1. 对每一层生成随机矩阵D,其中每个元素有keep_prob概率为1,1-keep_prob概率为0。keep_prob通常取0.5或0.8。

2. 对该层节点的激活A进行元素乘法D,将部分元素置0,实现随机丢弃节点。

3. 训练完成后,将该层节点乘以1/keep_prob。这保证了节点的值期望不变,解决转测试时的尺度问题。

4. 测试时不使用dropout,直接使用整个网络实现预测。

Dropout这种随机丢弃部分节点的技术,可以看作每次对不同的子网络训练,起到正则化作用,能有效防止过拟合。

## 7. Understanding Dropout (C2W1L07)

### 原理

Dropout本质上是在每个训练迭代中,随机抽掉部分节点来工作。相当于每次使用一个更小的神经网络。这样可以起到正则化的效果,防止过拟合。

除此之外,Dropout可以让每个单位不依赖任何一个特征。因为每个特征在随机迭代中都可能被抽掉。这会强制单位将权重更均匀地分配到每个输入上。 从而收缩权重范数,实现正则化。

### 实现

在实现Dropout时,会生成一个随机矩阵,元素为0或1。随后将激活值与该矩阵元素乘积,相当于随机抽掉部分激活值。之后需要对剩余激活值进行归一化,以防止减弱原始输入。

可以为不同层设定不同的保留概率(keep_prob)。比如最大的权重矩阵对应层,保留概率设置得较低,以增强正则效果。输入层通常保留概率设为1或0.9,不想随机给特征增加噪声。

### 调参

是否使用Dropout需要根据是否产生过拟合来决定。如出现过拟合,则考虑使用Dropout。

保留概率keep_prob是一个重要参数。对不同层可以设置不同值,较大权重矩阵的层keep_prob设置低一些。

应用Dropout后,成本函数J对每次迭代不再一个确定值。这样无法直接监控成本下降趋势,需要事前验证优化是否成功,然后再打开Dropout。

## 8. Other Regularization Methods (C2W1L08)

其他正则化方法有:

1. 数据提升

    对类别识别来说,可以通过水平或垂直翻转图片来扩充训练数据。也可以对图片随机裁剪或缩放来获取新的训练实例。

    对数字识别来说,可以对数字应用随机旋转或畸变来扩充训练数据。

    数据提升可以用作正则化技术,效果类似正则化。

2. 早停止

    在训练过程中, plot 出训练集误差和验证集误差随迭代次数的变化。

    通常验证集误差首先下降,然后开始上升。此时停止训练,选择验证集误差最小时的模型参数。

    早停止相当于选择一个中等规模的W,防止过拟合。

3. L2正则化

    直接添加L2范数项到代价函数中,使得W规模变小,防止过拟合。

4. 比较

    早停止 couples 了优化代价函数和防止过拟合这两个任务,不如将它们分开来完成。

    L2正则化可以将两个任务分开,但需要试很多λ值。

    早停止的优点在于一次训练过程中即可尝试不同W规模,无需试多λ值。

5. 总结

    数据提升和早停止、L2正则化都是减少方差和防止过拟合的方法。需要根据计算成本选择合适的方法。

## 9. Normalizing Inputs (C2W1L09)

1. 对输入特征进行归一化包括:
   - 求出每个特征的均值μ,对所有训练和测试数据的这个特征都减去μ。
   - 计算每个特征的方差σ^2,对所有训练和测试数据的这个特征都除以σ。

2. 这样做的目的是:
   - 不同特征的范围可能有很大差异,如一个在1-1000,一个在0-1。这样梯度下降就难以优化代价函数。
   - 归一化后,各特征范围相近,约在-1到1之间,代价函数 J 的形状更圆。
   - 圆形的 J 更易于使用梯度下降进行优化,学习率可以取较大值,收敛速度更快。

3. 在归一化时需要:
   - 用全部训练数据计算μ和σ^2。
   - 将测试数据也用相同的μ和σ^2进行归一化,而不是单独在测试集上估计。
   - 这样训练和测试数据通过同样的变换,归为同一个空间下。

4. 一般情况下归一化都可以提升训练速度。即使特征范围相近,归一化也未必有害。

## 10. Vanishing/Exploding Gradients (C2W1L10)

1. 深度学习网络在训练过程中可能会出现梯度消失或梯度爆炸问题。

2. 梯度消失(Vanishing Gradients)意味着网络很深层的梯度值会变得极其小,导致学习迟缓。

3. 梯度爆炸(Exploding Gradients)意味着深层梯度值会变得极其大,可能导致训练失败。

4. 使用线性激活函数,可以用矩阵乘法推导出,深层输出值的大小取决于权重矩阵W的大小。

5. 当W大于1时,深层输出会呈指数级增加,梯度会爆炸;当W小于1时,深层输出会呈指数级减小,梯度会消失。

6. 对于很深的网络,如果W选择不当,梯度就可能消失或爆炸,影响训练。

7. 经过仔细初始化权重W,如使Wapproximately1,可以很大程度上解决这个问题,但不完全消除。

## 11. Weight Initialization in a Deep Network (C2W1L11)

1. 深度学习网络在训练时,如果权重初始化不当,可能导致梯度爆炸或梯度消失问题。

2. 对单个神经元进行初始化,可以将每个权重W的方差设置为1/n,其中n是输入特征数,使Z不会太大或太小。

3. 对神经网络层进行初始化,可以将该层权重矩阵W设置为标准正态随机数,乘以√(2/n),其中n是上一层特征数。

4. 对ReLU激活函数,上一条中的2需要改为1;对Tanh激活函数,需要改为1/n。

5. 以上初始化方法可以使每个层的W大小大致在1附近,从而减轻梯度消失或爆炸问题,并使网络能够更好地学习。

6. 方差项2/n也可以作为超参数进行调整,但一般效果不如其他超参数。

7. 以上方法提供了深度网络权重的初值设置,有利于训练过程的稳定进行。

## 12. Numerical Approximations of Gradients (C2W1L12)

1. 可以通过数值近似来计算梯度。

2. 将θ nudged到右侧和左侧,分别得到f(θ+ε)和f(θ-ε),可计算宽为2ε,高为f(θ+ε)-f(θ-ε)的梯度近似三角形。

3. 这样计算出来的梯度近似误差与仅考虑单侧差的方法相比小很多,它符合梯度的正式定义。

4. 数值误差与ε的平方成反比,采用双侧差可以很好地近似导数,误差为O(ε^2);单侧差误差为O(ε)较大。

5. 这种双侧差方法在梯度检查中会实现两倍的运行时间,但经验上仍然优于单侧差,因为其误差更小。

6. 通过这种方法,可以验证函数G是否正确实现了函数f的导数。下一步将学习如何进行梯度检查验证反向传播的正确性。

## 13. Gradient Checking (C2W1L13)

1. 梯度检查可以帮助找到机器学习模型如反向传播算法的错误。

2. 首先需要将所有参数如权重和偏差融合成一个 giant parameter vector θ。

3. 同时也将所有参数的导数如dW1、dB1等融合成同样维度的向量Dθ。

4. 若成本函数J变成单独依赖θ,则可以构建一个循环来数值近似估计每个参数θi的导数。

5. 对每个θi,计算J值在θi增加ε和减少ε点的值,并取其差值除以2ε来近似Dθi。

6. 重复上述过程计算所有参数的近似导数值,形成向量Dθapprox。

7. 计算Dθapprox和真实导数向量Dθ之间的欧几里得距离,如果结果小于一定阈值,则说明实现是正确的。

8. 如果距离过大,需要检查单个θi的参数对数值和导数的计算,找出bug来源。

9. 通过梯度检查可以有效检测反向传播算法中的错误,帮助调试和验证模型实现。

## 14. Gradient Checking Implementation Notes (C2W1L14)

1. 使用梯度下降算法时,不建议使用梯度检查来调试,因为计算D θaprox_i对每个i都很耗时。仅在调试时使用梯度检查。

2. 如果梯度检查失败,检查Dθapprox和Dθ的每个组件,以寻找错误原因。如发现Dθ和Dθapprox在对应Bl的组件上差距大,可能是计算∂L/∂B的地方有问题。

3. 使用正则化时,记得包含正则化项。J(θ)应该是包含正则化项的整体损失函数。

4. 梯度检查不适用于dropout,因为dropout每次随机丢弃不同的节点。可以将dropout概率设置为1,关闭dropout进行检查。

5. 情况很少,但算法实现可能在W、B近0时正确,但它们值增大后会给出不准确的梯度。可以训练一段时间后再检查。

## 15. Mini Batch Gradient Descent (C2W2L01)

1. 当数据集很大时,直接使用梯度下降计算整个数据集的梯度需要时间很长。

2. 样本数据可以分批次处理,每批次包含部分样本,这样每次只处理一小批次样本,这样可以不经常处理整个数据集,但依然可以实现训练。这种方法称为mini-batch梯度下降。

3. 将全部样本随机分成多个大小相同的小批次,每个小批次叫作mini-batch。重复此过程多次称为一个epoch。

4. 对每个mini-batch使用和普通梯度下降相同的算法,例如前向传播,计算成本函数,反向传播计算梯度,将参数更新一小步。

5. 重复对所有mini-batch进行上述过程,即完成一个epoch。采用mini-batch方式可以在较短时间内完成多次参数更新。

6. mini-batch大小可以调整性能。一般1000个样本左右的mini-batch效果好。太小不足以利用硬件,太大还是比较耗时。

## 16. Understanding Mini-Batch Gradient Dexcent (C2W2L02)

1. 使用小批量梯度下降可在未完成处理全量训练集前开始进行训练,不必等待完成一次迭代。

2. 每次使用小批量数据计算代价函数J时,J可能不会每次下降,会有细微波动。因为不同小批量数据质量不同,可能导致计算结果上下波动。

3. 但在多次迭代后,J整体趋势应下降。如果上升可能学习率设置过大。

4. 小批量大小选择训练数据大小M和1之间。M代表全量梯度下降,1代表随机梯度下降。

5. 全量梯度下降每次迭代耗时长,随机梯度下降噪声大,计算效率低。

6. 实际采用中间值,如64-512。 batchsize应为2的幂次方便计算。

7. 小批量大小也是超参数,应根据实验选取效率最高值。

8. 随机梯度下降下降速度慢,收敛性不好。小批量下降收敛效果较好,但可能在局部极小点震荡。

## 17. Exponentially Weighted Averages (C2W2L03)

1. 指数加权移动平均(EWMA)是一种计算移动平均值的方法。

2. EWMA通过衰减前一天得分来计算当天平均值,给近期天气更高权重。

3. 公式为Vt=β*Vt-1+(1-β)*Tt,其中β代表权重参数,接近1代表考虑更长期,值小代表考虑更短期。

4. 取β=0.9时约为10天平均。β=0.98为50天平均。β=0.5为2天平均。

5. β大时曲线更平滑但滞后更大,β小时曲线更颠簸但响应更快。

6. 实际β选择0.9左右,平衡响应速度和平滑程度。

7. EWMA核心是采用指数衰减来计算移动平均,从而考虑近期数据更重要。

8. 其结果取决于β值的设置,β也是这个算法的一个重要超参数。

## 18. Understanding Exponentially Weighted Averages (C2W2L04)

1. 指数加权移动平均公式为:Vt=β*Vt-1+(1-β)*Tt,其中β代表权重参数。

2. 当β取0.9时,约等同于10天平均。β取0.98时,约等同于50天平均。

3. 公式展开可知,Vt实际上是一个权重递减的θt值的加权和,近期数据权重大,权重以指数方式递减。

4. 权重递减函数为0.1*0.9^t,随t增加,权重按0.9的指数下降。

5. 实际实现时,只需保持一个V值,每次迭代更新V:=β*V+(1-β)*T_t,很高效。

6. β值选择影响计算均值的时间窗口范围,β大曲线更平滑但响应较慢;β小曲线较颠簸但响应更快。

7. 一般β取0.9,平衡响应速度和平滑程度,约等同10天均值。

8. 相比直接计算均值,EWMA只需很少内存空间,且计算高效,所以广泛用于机器学习等场景。

## 19. Bias Correction of Exponentially Weighted Averages (C2W2L05)

当实现指数加权平均公式时,如果不进行偏差校正,计算结果将不是理论上的曲线。

对于β为0.98的情况,理论上应该是绿线,但直接实现公式计算得到的是紫线。紫线起始值较低,初期估计不准。

这是因为初始化V0为0时,V1仅为0.02θ1。这样V1值偏低。

随后的Vt也会继续偏低。

为了解决这个问题,可以将Vt除以1-β的t次方。

当t为2时,1-β^2为0.0296。这样Vt除以0.0296后,Vt就变成θ1和θ2的加权平均,初期估计就更准了。

随着t增大,β^t趋于0,偏差校正影响越小。但在初期,偏差校正可以帮助获得更好的估计。

综上,实现指数加权平均时,需要进行偏差校正,尤其是在初期,以提高估计精度。但后期影响小,可以不进行校正。

## 20. Gradient Descent With Momentum (C2W2L06)

标准的梯度下降算法,会在成本函数等值线两侧来回震荡,学习速度慢。

momentum算法会计算梯度的加权移动平均值,用于更新参数。

具体地,在每次迭代中:

1. 计算当前mini-batch的梯度DW,DB

2. 计算梯度的移动平均值:

   VDW = β*VDW + (1-β)*DW

   VDB = β*VDB + (1-β)*DB

3. 使用移动平均值更新参数:

   W <- W - α*VDW

   B <- B - α*VDB

这里β控制平均权重,通常取0.9。

这种方法能够在垂直方向 damp 减小震荡,在水平方向保持学习速度,实现更直接高效的优化路径。

Momentum算法比直接使用梯度下降效果明显好,但也有机会继续改进提高学习速度。

## 21. RMSProp (C2W2L07)

RMSprop算法可以加速梯度下降。它通过记录参数的梯度平方平均值,来为不同参数设定不同的学习率。

在梯度下降中,垂直方向的学习率应该较小,以减弱震荡;而水平方向的学习率可以保持较快,以加快学习进度。

RMSprop记录每个参数的过去几步梯度的平方平均值。设S_W为W参数梯度的平方平均值,S_B为B参数梯度的平方平均值。

当更新W参数时,学习率会除以sqrt(S_W);当更新B参数时,学习率会除以sqrt(S_B)。由于常规情况下,B参数的梯度值变化幅度大于W,所以S_B大于S_W,学习率在B方向上会更小。

这样可以实现在垂直方向放缓学习速度,减弱震荡;在水平方向保持较快学习速度的效果。这让算法能使用更大的全局学习率,从而加速学习过程。

在实现时,需要加入一个很小的ε数字,避免分母为0导致结果无限大的情况发生。β是用来计算移动平均的decay参数。

RMSprop算法是在Coursera课程中首次提出的,随后在深度学习中得到广泛应用。将RMSprop与动量一起使用可以得到效果更好的优化算法。

## 22. Adam Optimization Algorithm (C2W2L08)

Adam优化算法是将动量算法和RMSprop算法结合在一起的算法。

初始化v_w,s_DW,v_b,s_DB等变量均为0。

计算每个批次的梯度dW,dB。使用beta1参数计算动量梯度的移动平均v_W,v_B。使用beta2参数计算梯度平方的移动平均s_DW,s_DB。

进行修正来减轻初始化阶段的影响。将v_W,v_B,s_DW,s_DB分别除以1-beta1^T和1-beta2^T。

将参数w根据学习率alpha,动量梯度v_W修正后的值,以及RMSprop的s_DW修正后值进行更新。将参数b根据相同的方法但用dB,v_B,s_DB进行更新。

Adam算法结合了动量算法加速收敛和RMSprop算法控制不同参数的学习率的优点。它通常使用默认超参数值就可以很好进行训练。

Adam的名称来源于它是一种自适应矩估计(Adaptive Moment Estimation)优化算法。beta1计算移动平均估计一阶矩(第一动量),beta2计算移动平均估计二阶矩(第二动量)。

## 23. Learning Rate Decay (C2W2L09)

当使用小批量梯度下降时,随着迭代次数增多,学习率如果一直保持固定值,导致学习算法可能无法很好地收敛到最优解周围。

一种可以改进的方法是逐渐减小学习率,称为学习率衰减。最初阶段可以使用较大学习率,使学习快速,但随着迭代次数增加,学习率逐渐减小,可以更精细地搜索最优解周围区域。

实现学习率衰减的一种方法是:

α=1/(1+衰减率×epoch数)×α0

这里α0是初始学习率,衰减率是一个超参数。

还有其他实现方法,比如指数衰减、平方根衰减等。

也可以采用阶梯状学习率,每隔一定迭代次数将学习率减半。

如果训练时间很长,也可以手动监测模型进度,然后适当降低学习率。

此外,在进行下一轮参数超参数调优前,需要学习如何有系统地选择和比较不同超参数组合,以更高效地训练模型。

## 24. Tuning Process (C2W3L01)

调优深度学习模型时需要选择许多超参数,例如学习率、动量系数、Batch大小等。

学习率调整最重要。其他重要超参数包括动量系数、Batch大小、隐藏单元数目等。

调优时可以采取随机采样,而不是在网格上采样。因为不同超参数对结果的影响可能不一样,随机采样可以更好地探索所有超参数的优值范围。

可以采取粗放 fined-grained 搜索策略。首先在广泛范围内随机采样取一些点,观察结果优良点周围值范围,然后在此范围内采更细粒度的随机采样。

多轮迭代这样的过程,可以逐步接近优解。

超参数搜索需要分析各超参数对结果的影响程度,采用合理的采样策略和范围,通过多次尝试逼近最优配置。整个过程需要系统化、逐步细化地进行。

## 25. Using an Appropriate Scale (C2W3L02)

在超参数 tuned 时,不应该简单随机均匀采样所有值。应考虑使用不同范围的采样比例。

例如隐藏单元数,可以直接采样目标范围内的值。

学习率如果范围很大,应该采用对数采样。取学习率低值和高值的对数,然后对数范围内随机采样。

层数可以直接采样目标范围内的值。

动量项采用的Beta,采样 1-Beta 范围内的值为好,这样可以更充分覆盖0.9到0.999范围。

采样过程需要考虑超参数对结果的敏感程度,在敏感范围内更密集采样,可以提高效率。

在Python中,可以使用如下方法实现对数采样:

```python
R = -math.log(a) * random.random() + math.log(b)  
param = math.10**R
```

总之,采样范围和密度需要根据超参数实际性质进行调整,才能更好地探索配置空间。

## 26. Hyperparameter Tuning in Practice (C2W3L03)

不同应用领域的经验不一定适用于其他领域。但各领域之间会有交叉学习。

即使在同一应用领域,随着时间和条件变化,最优超参设置也可能不再适用,需要重新评估。

超参调优主要有两种方法:

1. 「熊猫方式」:只训练一个模型,长期跟踪优化进程,逐步调整超参。适用于资源限制情况。

2. 「鱼子方式」:并行训练多个模型,不同模型采取不同超参设置。结束时选择性能最好的一个。适用于资源充足情况。

两种方法取决于计算资源情况。例如大数据场景下,可能需要采用「熊猫方式」逐步优化一个模型。

在进行时,也可以在原有基础上增加新的模型训练。总体上,模型数量要根据资源决定采用哪种方式。

调优需要长期跟踪优化进展。条件变化时,需要重新评估最优超参设置。这可以提高模型性能。

最后,还提到一种能简化调优难度的技术,但并未具体介绍。

## 27. Normalizing Activations in a Network (C2W3L04)

深层网络训练难点在于,不同层次的节点激活值 distribution可能会影响后续层次的参数学习效率。

Balch标准化(Batch Normalization)可以解决这个问题。它将每个batch中的激活值进行标准化处理,使其均值为0,方差为1。

该处理分为以下步骤:

1. 计算批量样本某层节点Zi的均值μ和方差σ^2

2. 标准化处理:

   zi_norm=(zi-μ)/σ

3. 加入学习参数:

   z_hat=γzi_norm+β

这里γ和β是需要学习的缩放和平移参数。它们可以控制zi_norm的分布,使得不同层次节点的值分布更适于后续学习。

Batch Normalization的好处在于:

1. 标准化各层节点值,可以加快和优化网络训练

2. 使网络更容易训练,不易陷入局部最优

3. 网络对超参数选择和初始化的敏感性大幅降低

它通过在网络各层加入γ和β参数实现标准化处理,从而有效解决深层网络训练难点。

## 28. Fitting Batch Norm Into Neural Networks (C2W3L05)

Deep神经网络的隐层中,不同节点的激活值分布情况会影响后续层次的参数学习效率。BatchNormalization可以解决这个问题。

BatchNormalization的工作原理:

1. 对每一批数据计算隐层各节点Zi的均值和方差

2. 对Zi进行标准化处理:

   zi_norm=(zi-μ)/σ

3. 添加学习参数γ和β:

   z_hat=γzi_norm+β

将BatchNormalization插入到网络中的步骤:

1. 计算隐层Zi值

2. 对Zi进行BatchNormalization,得到标准化后的Zi_norm

3. 将Zi_norm传给激活函数,计算Ai

4. 使用Ai计算下一层Zi,并进行BatchNormalization

5. 如此循环计算每一层,BatchNormalization操作在计算Zi和Ai之间进行

BatchNormalization向网络添加γ和β作为额外参数进行优化。

训练时常使用小批量数据代替全量数据进行计算。每一小批次数据独立进行BatchNormalization。

优点:

1. 标准化各层节点值,加速网络训练

2. 网络对超参数选择和初始化敏感性大幅降低

3. 网络训练更稳定,陷入局部最优可能性下降

使用深度学习框架实现BatchNormalization通常只需一行代码。无需自己实现标准化计算细节。

## 29. Why Does Batch Norm Work? (C2W3L06)

### 一、标准化输入特征可以加速学习

同样道理,规范化隐藏单元的值也可以加速学习。这也是batchnorm工作的一部分原因。

### 二、batchnorm使得更深层网络参数更鲁森

如果训练数据分布发生变化(如训练只有黑猫图片,但测试数据加入颜色猫图片),深层网络的参数需要重新学习以适应变化。

batchnorm通过限制隐藏单元值的平均值和方差变化来减少此问题。从某一层看,下层值可以看作是特征,batchnorm限制特征分布的变化。

### 三、batchnorm起到了一定的正则化效果

由于batchnorm使用小批量得到均值和方差估计,它会加入一定噪声。类似dropout一致添加隐藏单元值噪声,正则化网络。但是正则化效果很小,不应视batchnorm为正则项。

### 四、测试时使用移动均值和方差

训练时基于小批量得到均值和方差,但测试时只有一个例子,无法使用小批量。此时使用训练期间的 moving average 均值和方差。

## 30. Batch Norm At Test Time (C2W3L07)

训练时,batch norm是对mini-batch中的每个样本zi进行批量计算:

- 计算mini-batch中zi的均值μ
- 计算mini-batch中zi的方差σ^2
- 使用μ和σ^2对zi进行规范化,得到V~i
- 使用学习的参数γ和β对V~i进行缩放,得到最终的V~i

但是测试时可能只能一个一个样本进行预测,无法形成mini-batch。为了适应这种情况,需要对μ和σ^2进行估计:

- 采用指数均值来维护μ和σ^2的运行平均值
- 训练每个mini-batch后,使用μ和σ^2来更新运行平均值
- 测试时,直接使用运行平均μ和σ^2来进行zi的规范化和缩放

采用运行平均值的好处是:

- 能在没有mini-batch情况下估计μ和σ^2
- 运行平均值利用了所有遇到的μ和σ^2信息
- 测试时利用的μ和σ^2接近训练时的真实分布

所以通过运行平均值,可以将训练时依赖mini-batch的batch norm方法扩展到测试单个样本的情况。

## 31. Softmax Regression (C2W3L08)

 softmax回归是 logistic回归的推广,用于多类别分类问题。假设要识别图片中的猫、狗、小鸡3类对象。

将最后一层网络输出设为C个单元,这里C等于分类类别数目4。每个单元分别表示给定输入X属于对应类别的概率。

最后一层计算线性值Z=W*X+b。然后将Z输入softmax激活函数。

softmax函数首先对Z的值取指数,得到中间变量T。然后将T归一化,使各元素加和为1,得到最终输出Y。

Y的各元素就表示输入X属于不同类别的概率分布。因为概率和为1,softmax层的输出可以理解为各类别的softmax化(软最大)概率。

softmax网络可以学习出复杂的非线性决策边界,将多分类问题化解开来。当没有隐藏层时,决策边界会近似直线。

训练softmax网络的时候,可以采用交叉熵作为成本函数。反向传播算法可以很好地学习网络参数,从而实现多类别分类任务。

## 32. Training Softmax Classifier (C2W3L09)

Softmax回归用于多类别分类问题。它通过softmax激活函数将最后一层输出映射到多维概率分布。

 softmax函数首先对Z值取指数,得到中间变量T。然后将T归一化,使各元素加和为1,得到概率输出Y。

训练softmax模型时,采用交叉熵作为损失函数。单个样本的损失是目标类别的概率与预测结果的负对数似然。

整个训练集的损失函数是所有训练样本损失的和。使用梯度下降法最小化这个代价函数,来优化模型参数。

具体来说,给定一个分类实例的标签y和预测结果Y^,单个样本的损失定义为:-Σy_jlogY^_j  

其中y_j为样本的真实标签,Y^_j为对应类别的预测概率。目标是将预测概率最大化。

对于整个训练集,损失函数定义为所有样本损失的和。由此驱动梯度下降进行参数更新,以优化模型。

在实现时,标签y和预测概率Y^均为C类的一维向量。整个训练集的标签矩阵Y和预测矩阵Y^都通过水平堆叠单个样本构成。

训练过程中,无需计算反向传播的具体Derivative。只需指定前向计算,框架会自动进行参数更新。

## 33. The Problem of Local Optima (C2W3L10)

在深度学习早期,人们常常担心优化算法会停留在局部最优点,但随着深度学习理论的发展,我们对局部最优点的理解也在不断变化。

在低维空间内,成本函数J的表面可能存在许多局部最优点。但在高维空间中,J的绝大多数零梯度点实际上是鞍点,而不是局部最优点。鞍点在各个方向上,成本函数J既可能呈凸形,也可能呈凹形。在数以万计的参数空间中,局部最优点的概率远远低于鞍点的概率。

plateauregion是梯度值长时间靠近零的区域。在plateau上,算法需要很长时间才能慢慢下降并找到出口。这就会使学习速度变慢。momentum方法和最速下降法等算法可以有效加速这一过程。

总体来说,深度学习模型通常不易陷入局部最优点。但plateau确实会引起学习问题。理解高维空间的特点对优化也很重要。

## 34. TensorFlow (C2W3L11)

### 引言

本节视频将介绍TensorFlow框架的基本结构,并使用一个简单的例子来实现梯度下降算法对线性回归模型的参数进行优化.

### TensorFlow基本概念

- 使用TensorFlow定义参数时,需要使用tf.Variable函数.例如定义一个名为W的参数.

- 定义损失函数(cost function)时,使用tf提供的各种数学运算运算符比如add, multiply等.也可以直接使用+-*/运算符.

- 定义优化器,如使用tf.train.GradientDescentOptimizer,设置学习速率.

- 使用tf.global_variables_initializer()初始化所有变量.

- 使用tf.Session()来运行会话,运行优化步骤训练过程.

### 一个简单的例子

本例将使用梯度下降算法来最小化一个简单的二次函数:

J(W) = W^2 - 10W + 25

具体步骤:

1. 定义参数W为一个变量
2. 定义损失函数J(W) = W^2 - 10W + 25
3. 定义优化器train为梯度下降,设置学习率
4. 初始化变量
5. 开启Session运行train来进行训练
6. 打印W查看是否收敛到理论最小值5

运行1000次迭代后,W收敛到很接近理论最小值5,验证算法正确.

### 数据驱动的损失函数

在实际中,损失函数通常取决于训练数据.

使用placeholder定义数据输入X,修改损失函数使其系数取决于X:

J(W) = X[0] *W^2 + X[1]* W + X[2]

其中X初始化为[1, -10, 25]可表示原始示例.
运行后W还是收敛到5,验证修改后算法依然正确.

通过placeholder和feed_dict可以将真实数据输入到模型中,这是TensorFlow的一个重要功能.

### 总结

本节视频介绍了TensorFlow框架的基本概念和API,并用一个简单例子展示了如何定义模型,优化器和训练循环来实现参数学习.这为后续更复杂模型的构建打下了基础.
