# Crash Course Computer Science

> <https://www.youtube.com/playlist?list=PL8dPuuaLjXtNlUrzyH5r6jN9ulIgZBpdo>

## 1. Crash Course Computer Science Preview

### 主要概述

这门课程将内容覆盖计算机科学的广泛领域。会介绍计算机的历史,从没有电前的计算机开始。会讨论操作系统的工作原理,YouTube如何通过网络传输,智能手机和其他智能设备是如何成为更聪明。还将涉及量子计算和网络攻击等未来主义和当前问题的主题。

### 不会涵盖的内容

不会教如何编程。但会讨论 hardware 和 software 设计背后的逻辑规则。也不会教如何用 Arduino Uno 给植物浇水或修改 CSS 让网站访客的光标变成小猫。

### 计算机科学的定义

在美国,计算机科学指计算机能做什么。但在其他国家,计算机科学的定义不尽相同。

### 讲师简介

讲师Carrie Anne Philbin,她是一位获奖计算机教师。著有《树莓派冒险》一书。她也制作了面向青少年的“极客女孩日记”YouTube视频系列。工作中,她作为树莓派基金会教育部主任,致力于帮助人们学习技术和使用计算机制作项目。她热情地提倡这一领域,认为计算机在今天社会已然至关重要。

## 2. Early Computing: Crash Course Computer Science #1

### 计算机科学系列概述

该系列将从比特、字节、晶体管和逻辑门,一直探讨到操作系统、虚拟现实和机器人等主题。

### 早期计算设备

最早的计算设备是书写于公元前2500年左右的算盘,它利用珠子来执行加减法计算。1613年是第一次记录“计算机”一词的用法,指计算工作人员。直到19世纪末,计算机开始指代计算设备。最早的计算机包括1694年莱布尼茨设计的步进计算器。

### 计算应用的兴起

19世纪,随着炮兵射程表的计算需求,计算开始应用于军事领域。1890年美国人口普查需要大量数据计算,帮助推动了赫尔默发明穿孔卡技术和推动计算机在商业领域应用。20世纪中期,随着人口增长和贸易兴起,数字计算机应运而生。

### 计算机历史先驱

查尔斯·巴贝奇提出差分机和分析引擎构想,被视为计算机之父。阿达·拉芙蕾斯为分析引擎写下程序,被誉为世界上第一位程序员。20世纪初期,计算机科学家承袭巴贝奇理念,构建早期电子计算机。

## 3. Electronic Computing: Crash Course Computer Science #2

### 20世纪初计算需求的增长

20世纪首半叶,人口和社会体系规模快速增加,带来计算需求增长。

### 电击机械计算机

1944年,IBM为盟军研发了马克一号计算机,包含765,000个组件。计算依靠电击继电器开关。速度慢,维修频繁。

### 真空管的出现

1904年发明真空管,1906年李·德福尔改进添加控制电极,实现开关功能。真空管没有运动部件,开关速度更快,成为无线电、电话的基础。

### 电子计算机的出现

20世纪40年代,飞来福公司开发第一个真空管程序控制计算机——第一台代码破解机Colossus。1946年,宾夕法尼亚大学完成世界第一台通用电子电脑ENIAC。

### 导体的发展

1947年贝尔实验室发明晶体管,体积小尺寸快。1957年IBM推出全晶体管电脑608型电脑。晶体管带来计算机 miniaturization 和低成本化。

### 创新中心的形成

硅谷因其常用半导体硅而得名,成为全球计算机芯片最重要的研制和生产基地。

## 4. Boolean Logic & Logic Gates: Crash Course Computer Science #3

### 二进制表示

计算机中使用电信号高低态表示true和false,称为二进制。

### 布尔代数

乔治·布尔提出用真值表描述逻辑语句的真假,建立了三元运算:NOT、AND、OR。

### 逻辑门

利用晶体管可以建立NOT门、AND门和OR门,计算单个或组合逻辑。

### 异或门

XOR门输出只在一个输入为true时为true。可以用NOT、AND、OR组合建立。

### 更高层抽象

可以使用逻辑门符号表示不同逻辑组合,不用考虑内部具体实现,达到更高层次的抽象。

## 5. Representing Numbers and Letters with Binary: Crash Course Computer Science #4

### 二进制表示数字

计算机使用二进制表示数字,每一位代表2的倍数。杂凑码可以表示更大范围的数字。

### 表示浮点数

IEEE 754标准使用指数和 significand 表示浮点数,精度较高但范围有限。

### 表示字母

早期使用ASCII码将字母对应的数字编码存储文字。Unicode统一不同国家语言字符编码,兼容更多语言。

### 数据单位

1字节=8位,KB(字节)=1024字节。32位系统表示的最大正整数范围约42亿,64位系统最大约922亿万亿。

### 文件格式

图片、视频、音频等文件也使用二进制编码存储像素、声音数据等信息。网络通信最终也是以二进制比特流形式传输。

## 6. How Computers Calculate - the ALU: Crash Course Computer Science #5

### ALU组成

ALU包含算术单元和逻辑单元,分别实现数值运算和逻辑运算。

### 算术单元设计

利用半加器和全加器观念,通过逻辑门实现二进制加法。采用串行进位加法构建多位加法器。

### 逻辑单元设计

利用逻辑门实现数值判断功能,如判断条件运算结果是否为0。

### 扩展ALU功能

通过增加乘法电路实现乘法,但是速度慢。较高端处理器专门设计乘法电路。

### 特征输出标志

ALU输出结果外,还有特征标志位表明结果特性,如进位位、零标志、负数标志等。

### 更高级抽象

ALU内部复杂,外部通过操作码和标志位简化访问接口。现代CPU内核往往集成高性能ALU。

## 7. Registers and RAM: Crash Course Computer Science #6

### 记忆单元设计

利用逻辑门设计可以存储1位数据的锁存器。进一步设计可以设置和复位的双锁存器。

### 寄存器

将多组锁存器并联,形成可以存储多位二进制数字的寄存器组件。根据位宽可分为8位、16位、32位和64位等级别。

### RAM存储单元

采用矩阵结构布置锁存器,利用行列地址线唯一选择单个存储单元,大大减少控制线路。

### RAM存储模块

将多组矩阵存储单元整合为一个模块,通过地址寻址特定字节位置。通过读写使能控制读写操作。

### RAM存储器

将多个RAM模块整合为一个统一的存储器,可以通过地址寻址任意字节,实现隐秘的随机读写访问。

### RAM容量扩展

通过更大地址编码或者存储器整合,扩展存储量级,从KB到MB、GB无限扩大。现代计算机主要使用Dynamic RAM技术。

### RAM功能

RAM作为计算机的短期工作存储器,可以任意顺序高效访问,保存当前任务的数据和状态信息。

## 8. The Central Processing Unit (CPU): Crash Course Computer Science #7

### CPU的作用

CPU的作用是执行程序指令,程序由一系列指令组成,指导计算机进行不同操作。

### CPU组成

CPU内含ALU、寄存器组、控制单元、时钟和RAM模块接口。ALU执行算数和逻辑运算,寄存器存储数据和地址值。控制单元指导CPU运行。

### 指令执行过程

执行一个指令包括取指、解码和执行三个阶段。取指阶段从存储器取出指令,解码阶段分析指令内容,执行阶段进行对应操作如读取、写入操作。

### 时钟控制

时钟发出定时脉冲控制CPU逐步完成各个阶段的执行,保证不同部件同步运作。时钟速率称为CPU主频,单位赫兹。

### 实例程序运行

详细介绍一个简单程序在CPU中运行的整个过程,包括加载、相加和存储指令。

### 动态调频

现代CPU支持动态调整时钟频率,根据负载轻重运行在不同主频下,以提高性能和节约能源。

### RAM与CPU交互

RAM独立于CPU,通过地址、数据和控制线与CPU通信,共同实现程序的执行。在RAM中存取所需数据或保存运算结果。

## 9. Instructions & Programs: Crash Course Computer Science #8

### CPU执行程序

CPU通过程序指令来完成任务。程序由一系列指令组成,每条指令都具有特定的操作内容。

### 指令格式

指令中包含操作码和运算数地址等内容。操作码代表执行动作,运算数地址表示数据来源或目标位置。

### 实例程序运行流程

详细介绍一个简单程序运行在CPU中的全过程,包括加载、相加、条件跳转等一系列指令。

### 条件跳转

条件跳转指令只有在满足条件时才执行跳转,比如负数跳转只在运算结果为负数时跳转。

### 无限循环

无条件跳转指令可能形成无限循环,需要条件跳转指令解除。

### 程序功能

通过重新组织指令顺序和条件判断,可以实现除四则运算外更复杂的功能,比如求取余数。

### 指令长度

现代CPU采用更长和可变长指令来支持更多指令种类和地址范围,如Intel 4004CPU采用8位操作码和立即值。

### 现代CPU指令

现代计算机处理器如Intel Core i7支持上千条不同长度的指令,实现更强大的功能。

## 10. Advanced CPU Designs: Crash Course Computer Science #9

### CPU计算能力进步

计算机处理器不断提高主频,现阶段根据千兆赫运作,每秒可执行数十亿条指令。

### 早期CPU速度提高方式

通过改进晶体管开关时间来加快计算速度。

### 现代CPU速度优化方式

增加计算单元有利硬件执行更复杂指令,如图形运算、视频解码、文件加密等。

### 指令集扩展

为满足需求增加MMX、SSE等子集,执行高级操作。随时间推进指令集不断扩展。

### CPU数据瓶颈

高性能CPU需要及时为ALU提供大量数据,否则会呈现等待状态。

### 缓存技术

采用块访问模式,将RAM中的一块数据读入缓存以满足后续访问。会产生缓存未命中情况。

### 脏位技术

记录缓存与RAM数据是否一致,不同步时将脏块写回内存。

### 浮点数寄存器

特殊寄存器支持高性能浮点计算。

### 分支预测

预估指令跳转方向提前填充流水线。

### 命中率技术

指令流水线、超标量、多级流水线等技术实现指令级并行,每周期执行多条指令。

### 多核CPU

将一个计算单位分成多个独立核,实现多线程运算能力。

### 服务器和超级计算机

采用多CPU互联架构来满足大规模并行计算需求。

## 11. 早期编程:Crash Course计算机科学#10

在早期的机械纺织时代,若要织出带花纹图案的织物便需要人工定期调整织布机以符合设定的花纹图案,这对于生产带图样织物成本很高。1810年,Joseph Marie Jacquard发明了可编程的织布机,使用打孔卡片来存储每行织物的花纹图案设定,能够自动化生产带图案花纹的织物。

后来在1890年的美国人口普查中,也采用打孔卡片来存储每个人的基本资料,如种族、婚姻状况、子女人数、出生地等,利用卡片上的孔片来表示答案的选择。这些卡片可以输入到统计机器中自动统计每个问题的总人数。

20世纪初,这些商业计算机开始添加其他算术功能如减法、乘法、除法等。操作顺序通过接线板进行设定。1920年代开始采用可拔插接线板来更换不同程序。1940年代电子存储记忆开始实用化,程序得以存储在计算机内存中而非物理接线,以 von Neumann 架构通常被视为第一台能运行完全存储程序的计算机。

直到1980年代,计算机必须通过打孔卡片输入输出介质读取程序和数据。一个程序可能需通过数百张卡片输入。如果卡片顺序混乱需要很长时间进行调整。初期家用计算机也广泛使用开关面板来输入程序。难度大且效率低下。

需要一种更简单高效的方式来告诉计算机应该执行什么操作,这就是编程语言的产生。不同的编程语言给出不同层次的抽象,隐藏底层硬件细节从而降低编程难度。

## 12. 第一代编程语言:Crash Course计算机科学#11

早期计算机只能运行二进制机器码程序。程序员需要手工将高级语言描述转写为机器码,过程复杂容易出错。雅各布斯在20世纪50年代设计了第一代编程语言A-0,采用高级描述来简化编程。她于1952年建立第一台编译器,将源程序转译成机器码。

此后,IBM推出FORTRAN语言,程序长度比汇编码缩短20倍。编译器自动转译源程序,提高效率。1959年成立委员会研发跨平台语言COBOL,解决不同机器需要重新编写程序的问题。这些语言大大降低了计算机使用门槛,使更广泛领域使用计算机。

编程语言设计与硬件进步同步发展。60年代语言有ALGOL、LISP、BASIC。70年代语言有Pascal、C、Smalltalk。80年代有C++、Objective-C、Perl。90年代有Python、Ruby、Java。新世纪语言有Swift、C#、Go等。每种语言都在不断提高抽象层次,简化编程难度。

现代编译器可以将源程序自动优化编译为各种平台的机器码。编程语言通过定义变量和常用功能隐藏了底层细节,使更多人使用编程创造。未来可能实现自然语言编程。软件就是使用编程语言开发的各类应用程序。

## 13. 编程基础:语句与函数: Crash Course计算机科学#12

编程语言都有语句,即独立的完整思想。语句结合不同单词可以改变含义,但语法结构必须保持一致。语句遵循的规则称语法。

语句可以包含变量赋值,如“A等于5”。变量可以任何名称,但最好能明了代码含义。一系列语句组成程序,类似菜谱一步步执行。

流程控制语句用于改变程序正常顺序执行。条件语句IF可以根据条件选择执行不同代码块。IF后接表达式,如果为true执行then代码块,否则执行else代码块。

函数可以封装复杂代码,方便代码再利用。函数包含参数、变量、语句和返回值。函数通过调用使用,隐藏内部复杂逻辑。

常用控制流程有while循环和for循环。while循环根据条件重复执行块代码,直到条件不满足结束。for循环重复次数限定,每个循环都更新循环变量。

将相关代码封装成函数后,只需简单调用即可获得结果,提高代码复用性、可读性和模块性。现代程序依靠大量预编写函数库进行编程。

## 14. Intro to Algorithms: Crash Course Computer Science #13

本节介绍了算法的概念。

算法是完成某项计算的具体步骤。不同的算法可能得到相同的结果,但效率不同。算法的效率通常用时间复杂度衡量。

算法这个词来源于九世纪波斯科学家Al-Khwarizmi,他开创了代数学。设计高效算法早在计算机出现前就已成为一门重要学问。

排序是一个具代表性的算法问题。选择排序算法每次从待排数组中选择最小元素,放在已排列部分的末尾。它的时间复杂度是O(n^2)。

合并排序首先将数组分成大小相同的两半,然后递归地排序子数组,最后将有序子数组合并。它的时间复杂度是O(nlogn),效率更高。

图形搜索也是一类典型算法问题。狄克斯特拉算法可以高效地在图中寻找节点间的最短路径。

算法是计算机科学的核心内容之一。研究和设计新算法对解决实际问题至关重要。

## 15. Data Structures: Crash Course Computer Science #14

数据结构是用于组织和存储数据的特定方式,可以使数据在计算机内存中得到有效组织。

数组是最基本的数据结构,它允许存储一系列按顺序排列的值。数组通过索引计数来访问其中的每个元素。字符串是字符数组的特例。

矩阵是二维数组,每个元素都有两个索引。系统还可以定义更高维度的矩阵。

结构体可以把相关变量封装在一起,形成一个复合数据类型。我们可以定义数组中的元素为结构体。

链表通过每个节点里存储下一个节点的地址,实现了灵活的变长数据存储。它沿用了首尾相连的思想实现了FIFO队列和LIFO栈这两种基本数据结构。

树是一个hierachical的数据结构。每个节点最多可以有两个分支,称为二叉树。节点包括根节点、父节点、子节点和叶节点。

图通过随意连接节点来表示关系型数据。它没有层次结构的限制。

程序员日常使用这些基本数据结构和它们衍生的更复杂结构,通过合理选择数据结构,可以简化算法设计和提高效率。主流语言都内置丰富的数据结构库供程序直接使用。

## 16. Alan Turing: Crash Course Computer Science #15

阿兰·图灵1912年出生于英国伦敦,自幼就表现出对数学和科学的天赋。1935年就读硕士期间,他开始研究计算机科学的问题。

图灵试图解决一个德国数学家希尔伯特提出的决定问题,即是否存在一个算法可以判断任意形式逻辑语句是否成立。阿隆佐·张塞最早给出了 lambda演算的解答。同时,图灵提出了图灵机这个计算模型。

图灵机是一个理论计算设备,它装备有无限长的内存带以存储符号,并可读写或修改带上的符号。图灵机定义了状态变量和一组规则描述其行为。它可以完成任何计算任务,成为通用计算模型。

通过图灵机,图灵证明了停机问题不可解。即对任意程序和输入,不存在算法可以预测程序是否会停机。这说明计算机存在固有限制。

二战期间,图灵在英国破解机代码工作室解决德国恩际密码机密码。他设计了“电子解码机”,大大提升了盟军破解密码的能力,对战争结果有很大影响。

战后,图灵回到学术界,提出了图灵测试判断计算机智能的标准,为人工智能奠定基础。但由于他的同性恋身份,图灵在1954年选择了自杀,结束了自己短暂而影响深远的生命。

## 17. Software Engineering: Crash Course Computer Science #16

软件工程涉及使用工具和实践来构建大型软件项目。它解决了单个程序员无法完成庞大项目的问题。

破解大型项目的关键是将代码封装进功能单元中,如函数和对象。这允许多个开发人员并行工作不同部分。

对象导向编程将相关功能打包成对象。对象可以包含子对象、函数和变量。这种层级结构为大型项目提供良好组织。

集成开发环境为程序员提供代码编辑、调试、构建等一体化功能,提高开发效率。

版本控制系统識别代码版本,让多个开发人员可并行开发同一项目不同部分,避免冲突。

良好的文档注释和接口定义让开发人员理解和复用代码。测试工作验证代码功能和质量。

软件工程方法论有效解决了单人开发无法完成的大型软件项目问题,构建了当今软件工业的基础。

## 18. Integrated Circuits & Moore’s Law: Crash Course Computer Science #17

20世纪40-60年代,每台计算机都是由许多离散组件以及上千万根电线手工连接而成。这给设计和制造带来很大困难。

1958年,杰克·基尔比发明了集成电路技术。通过将大量组件封装到一个单一物理集成电路中解决了这个问题。这可以大幅减少电线和组件数量,从而降低成本和提高可靠性。

1959年,诺伊斯在Fairchild公司实现了集成电路的半导体化,采用硅作为基底材料使其更加稳定。这被视为现代集成电路的发明。

光刻技术可以在硅芯片上一次性多次转印微小电路图案。通过掺杂等工艺可控制硅的导通性,从而构建晶体管等器件。

印路板提供了将电路组装起来的载体。使用集成电路和印路板能以相同功能实现离散组件电路,但实际组件和线路数量大幅减少。

20世纪60年代初,一个集成电路内很难装得下5个晶体管,但到60年代中期已有100多个晶体管。这是摩尔定律的初期体现。

1970年英特尔推出的4004微处理器是首个以集成电路形式实现的CPU,标志着第三代计算机时代的开始。随后几十年,随着光刻技术的发展,晶体管数量和集成度急速增长,大规模集成电路的应用也迅速扩大。

## 19. Operating Systems: Crash Course Computer Science #18

20世纪40-50年代,计算机运行一个程序需要程序员将程序写入到纸带或打孔卡上交给计算机操作员。操作员将程序放入计算机运行,输出后计算机停止,这种手动过程在计算机很慢时可行。

随着计算机速度提升,由人工运行程序已经成为瓶颈。为让计算机自动运行程序,操作系统应运而生。最初操作系统能自动加载程序批处理运行,解决人工上下程序的问题。

50年代,随计算机使用范围扩大,它们的配置不尽相同,这给编程带来困难。不同设备如打印机仍需编程低级硬件细节接口。操作系统通过设备驱动程序实现软件抽象层,简化编程接口。

60年代初,计算机处理能力超过机械设备如打印机速度,带来闲置。曼彻斯特大学开发的阿特拉斯超级计算机操作系统通过任务调度使多个程序同时运行,实现并发运行。

为运行多个程序,每个程序分配独立内存空间。操作系统通过虚拟内存实现内存地址虚拟化,简化编程。阿特拉斯是首个支持虚拟和保护内存的计算机。

70年代,计算机降价推广,学校等机构采购计算机供学生使用。操作系统支持多用户通过终端同时交互访问计算机资源。

微软DOS成为80年代初个人计算机主流操作系统。现代操作系统如Windows和Linux支持多任务、虚拟内存等功能,实现单台计算机运行多个应用。

## 20. Memory & Storage: Crash Course Computer Science #19

计算机内存是不永久的,如果断电数据会丢失,称为易失性内存。存储器保留数据即使断电,称为非易失性存储器。

早期计算机存储使用打孔卡片和纸带存储少量数据。20世纪40年代,打孔卡格格式化为80列12行存储960位数据。最大程程使用62500张卡片约5MB存储空间。

1944年,J. Presper Eckert发明延时线存储器。利用声波在水银管中传播实现数据存储。每个管存储352位,EDVAC拥有128个管线存储45600位。该技术读取数据需要等待循环。

20世纪50年代磁芯存储器问世。利用矿芯之间电流的方向来实现1和0的存储,可随机访问任意位。它成为主流RAM技术20年。  

磁带运用于UNIVAC计算机,每英寸存储128位,每卷存储1200英尺约1.5MB数据。磁鼓存储器利用磁介质旋转磁头存储写入读取数据。

IBM RAMAC 305于1956年首次使用硬盘存储器,50个24寸盘提供5MB存储空间。硬盘写入速度较慢,辅以磁芯和鼓存储形成内存级别结构。

从0.000001美元/位的磁芯降至今日0.000000000005美元/位。固态硬盘无移动部件访问时间更快,被广泛采用。

## 21. Files & File Systems: Crash Course Computer Science #20

文件保存计算机数据,常见格式有文本文件、音乐文件、图片文件等。

文件格式规定了文件内数据的组织方式。文本文件使用ASCII码表示字母和字符。音频文件WAV格式在文件头储存采样率等音频属性信息,音频数据储存采样值序列。

图象文件BMP格式也先储存宽高和颜色位数等图像元数据,后储存像素值组成的图像数据。每个像素用三个8位整数表示红绿蓝三原色值。

计算机利用文件系统管理文件。早期文件系统直接将所有文件依次储存,使用目录文件记录文件名称和位置。

进一步发展 Formatted文件系统将文件装入固定块中储存,解决文件增长不足问题。同时支持文件分块存储,避免互相覆盖。目录文件记录每个文件的所有块位置。

随文件删除和增加导致文件碎片化,需要定期执行碎片整理。

分层文件系统允许建立目录层次结构管理大量文件。目录文件中同时记录下级目录和文件信息。只需更改目录文件指向即可实现文件移动。

文件系统通过抽象计算机底层设备,让用户视角下数据以文件形式进行管理。

## 22. Compression: Crash Course Computer Science #21

文件压缩可以将文件大小压缩到原始大小的一小部分。

无损压缩不会丢失任何数据,经过解压后数据与原始完全相同。运行长度编码(RLE)利用重复值进行压缩。

字典编码法使用更小的代码代替高频出现的数据块,需要额外保存映射字典。

兴帕森树(Huffman Tree)算法可以生成前缀代码,保证每个代码唯一且不会重复。

有损压缩允许一定误差来换取更高压缩率。对音频抛弃超音频成分,图像抛弃细节差异较大区域。

视频利用帧间相似度只编码差异部分,或通过简单变换复用匹配块,进一步提升压缩率。

常见文件格式JPEG、MP3等采用混合无损和有损方法进行高效压缩。压缩技术大幅降低存储和传输成本,使互联网和多媒体应用得以实可。

## 23. Keyboards & Command Line Interfaces: Crash Course Computer Science #22

早期计算机的输入和输出主要是通过机械控制面板实现,例如齿轮、旋钮和开关。即使是第一个电子计算机如Colossus和ENIAC,也是通过大量机械控制面板和交叉线路进行配置。

1950年代,机械输入方式逐渐被程序和数据储存在卡片和磁带等媒介中所取代。打印机成为主要的输出设备。同时开发了大量指示灯提供运行时的实时反馈。计算机输入的设计旨在简单和可靠,注重计算机的易用性而非用户体验。

打孔带就以计算机可读的方式设计,但人类无法直接以打孔形式来思考概念和程序。因此程序员需要将想法转换为计算机能理解的格式。

1950年前,计算机对人类输入的理解较为简单,主要是将程序和数据输入计算机,而非与人类进行交互。运行后结果也难以实时掌握。

1950年代后期,随着小型计算机和支持多程序和多用户的大型计算机的出现,计算机开始需要一种输入来源与用户进行交互。这时计算机开始借鉴打字机的键盘作为输入设备。

克里斯托弗·拉瑟姆·肖尔斯在1868年发明了现代打字机,但其QWERTY键盘的排列理由至今仍有争议。不论原因何在,QWERTY布局随后应用于所有打字机,即便今天150多年后,我们仍在使用它。

1960-70年代,电传打字机开始被用于计算机,它允许用户通过键盘与计算机进行“文字对话”交流。这种命令行界面成为人机交互的主流形式,直到1980年代图形用户界面兴起。

1970年代,随着商用电视机市场的兴起和处理器内存技术的进步,终端开始取代电传打字机,通过屏幕模拟无限纸带进行文本输入输出。

即使命令行界面看似简陋,但早期文字游戏如Zork等依然成为畅销作品。这类互动 fiction 游戏后发展为多人网络游戏MUD。现今流行的网络游戏源于它们。

命令行界面尽管简单直接,但在编程工作中仍旧受到广泛使用。访问远程服务器也以此方式为主。Windows、MacOS和Linux都内置有命令行界面终端。

## "24. Screens & 2D Graphics: Crash Course Computer Science #23"

早期计算机使用实物控制来进行输入和输出,例如轮子、旋钮和开关。这些早期计算机屏幕难以呈现清晰的文本,而打字纸提供了更高的对比度和分辨率。

阴极射线管(CRT)是最有影响力的显示技术之一。它通过向磷光涂层发射电子来工作。阵扫描和行扫描都是使用CRT的两种绘制图形的方法。

字符生成器存储每个字符的点阵模式,从内存读取字符后转换为栅格图形输出到屏幕上。这极大节省了内存,但只能绘图文本。人们也试图利用ASCII码字符构建简单的图形用户界面。

矢量图形模式允许绘制任意形状。所有内容都定义为一系列线段。这比像素更节省存储空间。早期游戏如Spacewar!就是使用矢量图形制作的。

Sketchpad是第一款完整图形应用程序。它使用光笔作为输入设备,允许用户交互绘制形状。这标志着计算机不仅是计算机,还可用于辅助人类任务。

1960年代后期出现了真正的像素图形,内存直接映射到屏幕像素上。这种位图 displays允许任意图形。程序可以直接修改像素值来绘制图形。Pong就是用这种方法实现的。

图形库提供绘制线条、形状、文本等功能,为程序员提供了更高级的抽象。但是,交互图形长期以来仍然很昂贵,直到显示器变得普遍。

## "25. The Cold War and Consumerism: Crash Course Computer Science #24"

1940年至1970年间,许多计算机科学领域取得了快速发展,例如编程语言、编译器、算法、集成电路、软盘、操作系统等。这是计算机产业形成前的时期。

二战结束后,美国与苏联成为两大超级大国,凭借冷战开始推动科技领域的大规模投入。计算机在曼哈顿工程和破解密码方面发挥作用,获得大量政府资金支持。

20世纪50年代,厄克特和白克利设计的UNIVAC-1成为首个商业性成功的计算机。大多数UNIVAC-1被政府机构和大公司采购。

电脑可以提升人类智能能力,不仅限于物理能力的增强。文尼瓦尔·布什概括性设想了一种记忆扩充设备“迷美克斯”。

美国国家科学基金会成立于1950年,为科技研究提供持续支持,保持美国在技术领域的领先地位。20世纪50年代,消费级半导体产品开始销售,代表性的电子管式收音机被晶体管收音机替代。

50年代中期,日本政府授权Bell实验室晶体管专利,助推日本半导体及电子产业的发展。随后索尼推出的TR-55晶体管收音机取得成功。

20世纪60年代,苏联在太空技术领先,成功发射史普尼克一号卫星,加加林成为首名进入太空的宇航员。 Kennedy号召美国在10年内实现登月目标。

美国航天局执行阿波罗计划,建设阿波罗导航计算机,采用IC技术,实现登月成功。IC技术的大规模应用主要得力于美国军事项目。

70年代,日本电子企业开始在计算机辅助计算器等新兴领域占据主导地位。Intel 4004微处理器的问世开启个人计算机产业蓬勃发展。

政府资助和消费需求是计算机科技持续发展的两个重要驱动力。

## 26. The Personal Computer Revolution: Crash Course Computer Science #25

By the early 1970s, the required components for building a low-cost but still usefully powerful computer had fallen into place. These components included single-chip CPUs, low-cost solid-state memory, circuit boards with entire computers, cheap storage like magnetic tapes and floppy disks, and low cost displays. If blended together, they formed microcomputers, which were much smaller compared to normal computers at that time.

More important than their size was their cost. For the first time, it was practical to buy one microcomputer and only have one person ever use it without time sharing or multi-user logins. This arrival of low-cost personal computers is considered the beginning of the personal computer era.

Though there was no single "first" personal computer, the Altair 8800 released in 1975 is considered the first commercially successful one. It debuted in Popular Electronics magazine and was sold as a $439 kit that users had to build themselves. Bill Gates and Paul Allen then wrote the first interpreted BASIC programming language for the Altair 8800, called Altair BASIC, which made the computer much more useful.

The Altair 8800 inspired many computer hobbyist groups and clubs, most notably the Homebrew Computer Club. One member, Steve Wozniak, was inspired to design his own computer after seeing the Altair 8800. In 1976, he and Steve Jobs started Apple Computer and released the Apple I computer as a kit.

Three particularly important computers were released in 1977: the Apple II, the TRS-80 Model I by Tandy Corporation, and the Commodore PET 2001. They were sold as complete units ready for use straight out of the box. They came bundled with BASIC languages and appealed to both consumers and small businesses. This helped spark the consumer software industry and popularized computers as home appliances rather than just industrial/hobbyist machines.

Seeing its market share shrinking, IBM entered the personal computer market in 1981 with the IBM PC. It had an open architecture with good documentation that allowed third parties to create new hardware and software for the platform. This drove competition and innovation. Compatible clones from companies like Compaq and Dell became popular as they could also run software on the huge IBM ecosystem. The dominance of IBM Compatible systems made them the de facto standard in personal computing.

## 27. Graphical User Interfaces: Crash Course Computer Science #26

在上一集中,我们讨论了1984年苹果公司推出的第一台设计给普通人使用的个人电脑-Mac。它是第一台可以通过图形用户界面和鼠标进行交互的个人电脑。

图形用户界面(GUI)相比前时代所有的个人电脑都只使用命令行方式来操作,显著革新。GUI通过在屏幕上显示各种功能按钮让用户可以看到所有可能操作,而不需要记住或猜测正确的命令。这样一来,只要看屏幕上有什么可以做的内容就可以通过“点选”方式操作。

这使得计算机使用起来非常直观。不需要是计算机专家,任何人都可以自学掌握怎样使用图形界面。

但是,GUI实际上是多年研究的結果。1962年發明的Sketchpad和Spacewar!就已经使用互動式图形界面。但它们只是个别程序,还不具备整合式的计算体验。

通常认为真正推动现代GUI发展的奠基人是道格拉斯·恩格尔巴特。他在读军旅期间阅读了范纳瓦尔·布什关于Memex的文章,受其启发后入学深造,并在1962年发表了“增强人的知识”报告,确立了计算机应用于交互式知识工作站的远见。

恩格尔巴特认为只有键盘操作是不够的,用户需要一种设备来移动屏幕上的光标。于是他和同事在1964年创建了第一台电脑鼠标。1968年,他在计算机会议上进行了90分钟长的“万众瞩目”展示,首次示意许多现代计算机功能,例如位图图形、视频会议、词处理软件等。

恩格尔巴特的成就在1997年得到图灵奖的recognation。他的团队成员后来转投帕洛阿尔托研究中心(PARC),为计算机未来的发展奠定基础。

在PARC,第一台真正意义上的GUI计算机-Xerox Alto在1973年完工。它采用“桌面隐喻”,将二维屏幕解读为一张可以摆放各种“文件”和“文件夹”的桌面。文件以窗口形式展示,可以重叠挡住后面的文件。这使得界面操作更接近人们在现实生活中理解和使用的表象。后来这套范式被称为“文书界面隐喻”。

史蒂夫·乔布斯在1979年参观PARC后深受影响。苹果公司于1983年和1984年分别推出Lisa和Macintosh,成为第一批采用鼠标和GUI的个人计算机。这为个人计算机的普及起到重要作用。

后来,微软也推出Windows操作系统,采用类似的GUI设计。随着Windows不断发展,它很快就在个人计算机上占据了绝对优势。图形用户界面也成为个人计算机的标准模式。

今天,GUI已经广泛应用于各种计算设备和软件上。尽管在用户体验上还可能有待改进,但它确实促进了计算机在日常生活中的应用。计算机科学家和界面设计师仍在努力创新,为用户提供更易使用和功能更强大的体验。

## 28. 3D Graphics: Crash Course Computer Science #27

### 3D坐标

- 3D图形由三个坐标表示,分别是X,Y,Z坐标
- 但计算机屏幕只有两维的X,Y坐标,所以需要3D到2D的投影转换

### 3D投影

- 正交投影:保持图片的平行关系
- 透视投影:远near物体与远物体相对关系如同真实视觉

### 三角形管理

- 三角形用于建模,因为三个点唯一确定一个平面
- 多个三角形组合形成多边形网格来表达更复杂的形状

### 线框渲染

- 仅绘制三角形的结合边框

### 光栅扫描渲染

- 将三角形像素填充为单一颜色
- 从上到下,从左到右进行扫描填充

### Z缓冲与透明处理

- Z缓冲记录每个像素的深度信息
- 保留最近的素面,实现遮挡效果
- 避免采用排序后绘制的方法

### 光照与着色

- 考虑表面法线、光源位置计算每面的亮度
- 着色算法使渲染效果更真实生动

### 纹理贴图

- 纹理图像贴至三角形上模拟不同材质

### GPU加速

- 图形处理单元负责大规模并行计算图形任务
- 赋予硬件特定功能以提升图形呈现性能

## 29. Computer Networks: Crash Course Computer Science #28

### 区域网(LAN)

- 直接连接在同一建筑或校区内的计算机组成区域网
- 共享打印机或大容量存储设备

### 以太网

- 使用共享介质传输数位电信号
- 每台计算机都有唯一的MAC地址作为标识
- 利用CSMA/CD方式处理介质共享冲突

### 交换机

- 将多个LAN通过交换机连接成更大的网络
- 根据MAC地址表实现定向转发,提升带宽利用率

### 路由

- 转接不同网络之间的数据包传输
- 电路交换固定连接两地,消息交换通过多跳传送
- 数据包交换将大文件分割,按地址转发小包实现动态路由

### 传输控制协议/网际传输协议(TCP/IP)

- 处理乱序数据包及各种网络传输问题
- 基于IP地址实现可靠的端到端连接

### 边界网关协议(BGP)

- 路由器之间交换全球路由信息表实现自动化路由

### 互联网

- 包含不同网络的集合,任意两台主机都能通讯
- 基于分布式无中心设计具有高可靠性

## 30. The Internet: Crash Course Computer Science #29

### 本地网(LAN)

- 连接房间内或校区内的计算机设备
- 共享打印机、存储设备等资源

### 城域网(WAN)

- 连接本地网与互联网服务供应商的路由器
- 形成区域网连接更大范围的网络

### IP包

- 标准化通信单位,包含目的地址和有效负载
- 需规定大小、格式传输

### UDP

- 简单快速但不可靠
- 添加源端口和校验和
- 不进行错误检测和修复

### TCP

- 可靠传输,添加序列号和确认报文
- 确认收包并检测错误
- 支持重传和流量控制

### 域名系统(DNS)

- 实现域名与IP地址的映射
- 分布式结构管理超过3亿域名信息

### OSI参考模型

- 7个层次理论框架划分网络功能
- 物理层、数据链路层、网络层、传输层、会话层等

## 31. The World Wide Web: Crash Course Computer Science #30

### 互联网与万维网的差异

- 互联网为各种应用提供底层通信基础
- 万维网是重要的分布式应用,使用超文本文件链接组成网状结构

### 超文本结构

- 每个网页是单独文档,包含内容和指向其他网页的超链接
- 超链接将各个网页纵横联系成一个庞大网络结构

### 统一资源定位符(URL)

- 规定每个网页的唯一标识地址,如thecrashcourse.com/courses

### 超文本传输协议(HTTP)

- 建立在TCP之上,通过GET请求获取网页内容  

### 超文本标记语言(HTML)

- 使用标签将文本格式设定为标题、段落、列表等结构和样式
- 插入图像、表单、按钮等丰富内容  

### 网络浏览器

- 请求网页、显示内容并支持用户操作如点击链接进行导航

### 搜索引擎

- 通过爬取网页并建立索引,实现基于关键词检索网页功能

## 32. Cybersecurity: Crash Course Computer Science #31

### 网络安全的目标

- 保护计算机系统和数据的机密性、完整性和可用性

### 安全等级

- 根据攻击者能力指定安全级别高低,不同级别设定不同限制和授权

### 身份认证

- 根据用户知道的秘密、拥有的证明或自身特征识别用户身份
- 常见方法有账号密码、物理密钥和生物识别等

### 授权控制

- 根据用户身份确定其对不同资源的操作权限,如阅读、修改等
- 常见模型有贝尔-拉帕杜拉模型和中国墙模型

### 安全机制

- 隔离运行环境保证程序安全隔离
- 形式验证和二次审计检测代码漏洞
- 限制程序授权减少危害范围
- 使用HTTPS、防火墙等网络安全保护通信

### 攻击方法

- 暴力破解破坏账号密码安全
- 侵入后门软件破坏运行环境安全
- DDOS攻击破坏系统可用性
- 天马行空利用系统漏洞

### 防护手段

- 增强密码复杂度
- 开启双因素认证
- 定期更新软件
- 尽量避免点击可疑链接

## 33. Hackers & Cyber Attacks: Crash Course Computer Science #32

### 黑客分类

- 白帽黑客:主要目的是找到软件漏洞并帮助修补,一般受雇于公司或政府
- 黑帽黑客:主要目的是偷窃、利用和出售计算机漏洞或数据
- 灰帽黑客:动机混杂,部分目的是兴趣或好奇心驱动
- 经济罪犯黑客:主要目的是经济利益
- 政治黑客:使用技术为社会或政治目标服务

### 社交工程攻击

- 网络钓鱼:欺骗用户提供账户名和密码
- 预文本攻击:欺骗用户提供机密信息或配置安全风险

### 软件攻击

- 木马程序:利用邮箱等载体传播恶意软件
- 蠕虫:自动在系统间传播
- 受控网络:控制大量计算机形成网络进行攻击

### 硬件攻击

- NAND镜像:复制存储器实现暴力破解复位攻击

### 常见漏洞攻击

- 溢出缓冲区攻击:利用输入超长数据覆盖内存值
- 代码注入:利用输入包含命令行代码实现攻击
- 0day漏洞:新发现且无修补程式的安全漏洞
- DDOS攻击:大流量请求瘫痪网站

### 防护 countermeasures

- 输入审计与过滤特殊字符
- 定期更新软件补丁
- 使用双因素认证
- 增强账户密码设置
- 隔离运行环境限制程序权限

## 34. Cryptography: Crash Course Computer Science #33

### 密码学基本概念

- 密码学研究如何使用算法将明文转换为密文以保密信息
- 加密是将明文转换为密文的过程
- 解密是将密文转换回明文的过程

### 古代密码

- 凯撒密码是将字母右移指定位数进行替换
- 其它替换密码包含各种字母映射
- 谷仓密码利用矩阵读出消息顺序进行排列置换

### 浏览密码机

- 英格玛机包含旋转轮和线路电路,使用多个替换轮和反射器实现高级密码
- 每次输入后轮自动旋转,密码随时变换

### 现代密码

- 数据加密标准DES采用56位密钥进行密文分组加密算法
- 高级加密标准AES使用更大128-256位密钥,提供更高安全性能
- 对称加密需要预共享密钥
- 数字签名采用非对称加密证明消息来源
- 迪菲-赫尔曼密钥交换实现安全密钥分发
- RSA算法使用公开和私有密钥对实现非对称加密

### 使用场景

- HTTPS安全连接使用SSL/TLS协议保护网络通信
- WIFI加密采用WPA2协议
- 文件加密软件实现本地数据和存储保护
- 金融系统交易采用数字签名验证身份

### 密码强度

- 密钥长度越长,暴力破解难度越大
- 密文算法循环越多越难分析
- 实现安全且高效需要考虑性能与安全平衡

## 35. Machine Learning & Artificial Intelligence: Crash Course Computer Science #34

### 机器学习基本概念

机器学习是让计算机具有学习从数据中并进行预测决策的能力的一组技术。它可以解决垃圾邮件筛选、健康诊断等问题。

### 分类任务与特征提取

将 distinguishing 王蛾与皇蛾为例,抽取翅展与体重为特征,收集标注数据训练分类模型,绘制决策边界来判定物种。

### 决策树算法

根据特征值划分决策空间来分类,可视化呈树状结构。它找出最优决策边界来最大化分类准确率。

### 支持向量机算法

以任意线条划分决策空间,线条不限为直线,也可以是多项式或其他数学函数。任务同样是找决策边界最大化准确率。

### 深度学习与人工神经网络

模拟人脑结构,以学习特征的不同权重来学习复杂关系。它包含输入层、隐藏层和输出层,每个节点执行加权和、偏置修正和传递函数来进行分类。

### 机器学习领域

除分类外,还有回归、聚类等任务。算法包括决策树、SVM、人工神经网络等。深层学习给出更好结果需要大量 labeled 数据和计算能力。

### 强弱人工智能的区别

弱AI只针对狭 domain 问题,强AI追求全面智能接近人脑,但尚未实现。人工智能应用范围很广,如医疗诊断、驾驶等都在不断改进。

## 36. Computer Vision: Crash Course Computer Science #35

### 视觉的重要性

视觉能提供大量环境信息帮助完成任务,发展计算机视觉技术给予计算机识别数字图像和视频的能力。

### 图像存储与像素

图像在计算机中以色块网格存储,每个色块用三原色RGB值表示颜色,通过组合值可以表示所有颜色。

### 颜色标记跟踪

通过记录目标颜色的RGB值,搜索图像每个色块找最接近的匹配色块来跟踪一个颜色物体。

### 边缘检测

使用Prewitt算子识别图像中水平和垂直边缘,其应用渐变算子处理图像区域找到色块间强差异的位置。

### 卷积神经网络

通过堆叠卷积-激活函数-pooling层学习特征,每层提取图像更高级结构,最后输出分类结果。它可以识别物体、表情等高级信息。

### 面部特征点检测

识别人脸后利用算法找到面部特征点如眼、鼻、嘴角位置,进而推断表情和认人。手部、体部特征点也同样重要。

### 计算机视觉的应用

计算机视觉广泛应用于自动驾驶、生物识别、互动系统等,随着技术进步,计算机将逐渐得到与人类相当的视觉能力。

## 37. Natural Language Processing: Crash Course Computer Science #36

### 自然语言与计算机语言的区别

自然语言具有大量词汇、词汇多重含义、语法错误等特征,而计算机语言要求严格。

### 词性标注

英语词性包含名词、代词、冠词、动词、形容词、副词、介词、连词、感叹词等9大类,识别词性有助于计算机理解语义。

### 语法规则与分析树  

语法规则描述语法结构,根据规则可以构建词汇分析树,明确语义关系。

### 机器翻译与对话系统

通过词性标注、语法分析及知识图谱实现机器翻译和问答功能。语义网络解释信息提供生成语言能力。

### 语音识别

分析语音信号频谱特征识别 Phoneme 单位,进而识别单词和划分语意单位。语言模型识别常见词组,提高识别准确率。

### 语音合成

将文本转换成 Phoneme 后串联输出,实现语音表达。随着深度学习的发展,合成语音质量不断提高,将成为主流交互方式。

## 38. Robots: Crash Course Computer Science #37

### 机器人定义

机器人是一类能自动按程序执行一系列操作的机械设备,包括视觉与物理外观无关。

### 自动机与机器人的发展史

1739年法国工程师让·德弗肯松制造的啄木鸭行为机械,显示出最早的自动机概念。1920年捷克剧本首次使用“机器人”一词。1940年代计算机数值控制(CNC)机器诞生。1960年通用汽车采用Unimate机器人进行工业自动化。

### 机器人分类

根据外观分型有无人机、医疗机器人、工业机械臂等。根据应用可划分为服务机器人、保安机器人、军用机器人等。

### 机器人控制理论

采用反馈控制环进行定位与移动控制,常用PID控制算法。高层软件负责任务规划、路径规划等功能。机器视觉与人工智能技术对解决复杂任务有重要作用。

### 机器翻译与自动驾驶

机器翻译通过词性标注、语法分析及语义网络实现。自动驾驶依赖感知传感器和计算机视觉识别交通信号、障碍物。

### 机器人在生产、军事等领域的应用

机器人在工业制造中的广泛应用改变了劳动模式。军用机器人可取代人员从事高风险任务,但 autonomous 杀伤性武器具有争议性。

### 机器人发展趋势

人工智能与深度学习技术将进一步提升机器人的可控性与复杂任务完成能力。但如何确保机器人安全使用仍需要长期探讨。

## 39. Psychology of Computing: Crash Course Computer Science #38

### 计算机设计需要考虑人因性

计算机系统由人使用,需要理解人的优势与局限性,如视觉、认知等方面。

### 可用性

可用性是人造物体实现目标的有效程度,直接影响用户体验。

### 视觉心理学

人易于识别颜色饱和度顺序,难于区分颜色名称顺序。应用颜色展示连续型或类目型数据不同。

### 认知心理学

人通过分组可更好记忆信息。 计算机界面应用分组,如电话号码、下拉菜单。

### 形象提示

形象提示告知操作方法,如门的推拉形式。图形用户界面按钮完全依赖此概念。

### 认知与回忆

人通过触发式线索(图标)较容易识别功能,而非凭记忆。

### 专业知识

界面应提供多种完成任务路径,兼顾新手体验和高手效率。

### 情感计算

考虑用户情感状态,提升体验满意度。芯片可监测生理指标分析情绪。

### 可圈可点

用于标明可拖动部件,源自现实工具设计。

### 社交交互与社交媒体

研究网络交流规则与语言特点,比面对面更易透露个人信息。

### 目光交互

互看可增强互动参与度。视频课程应模拟教师身体位置以此修正目光交互。

### 人机交互

研究人与机器人交流模式性与外表设计对人的影响。探讨机器人拟人化程度。

### 机器学习和人工智能

将推进机器人自主程度和完成复杂任务能力,惟须确保使用安全。

## 40. Educational Technology: Crash Course Computer Science #39

### 信息的广泛提供

互联网上已有130亿个网站,维基百科5百万多篇英文条目。Google每日查询40亿次,Youtube每分钟上传400小时视频。

### 信息与学习的关系

信息的提供不等于学习。交互式学习、讨论和体验活动有助于学习。

### 教育技术支持学习

计算机科学可以支持教育技术,如在线视频课程。

### 视频学习的优化方法

调节视频速度,随时暂停回顾难点,练习例题都能有效提升学习效果。

### MOOC发展和问题

早期MOOC只有视频讲座,人数众多导致问题,如如何给大量学习者反馈。

### 人机混合系统

将学习伴侣匹配算法、部分自动化评阅等技术应用在MOOC中缓解问题。

### 个性化学习

算法分析学习情况给出学习建议,实现如Netflix个性推荐的目的。

### 产知规则

用表征程序流程的产知规则描述学科知识和错误类型,识别学习难点。

### 贝叶斯知识跟踪

通过观察答题情况更新学习能力估算,实现个性化学习路径。

### 教育数据挖掘

分析大量学习者交互数据识别通用难点,改进个性学习。

### 未来趋势

探讨语言代理、VR/AR、脑学习接口在教育中的应用前景。

## 41. The Singularity, Skynet, and the Future of Computing: Crash Course Computer Science #40

### 计算机在未来的应用

计算机可能成为智能机器人或嵌入式系统的一部分,甚至进入人体,融合人类与技术。

### 智能化程度与人工智能

目前计算机能力仅相当于小鼠,但技术进步可能在10年内拉近与人脑的差距。

### 科技失业问题

60%的工作可能被自动化取代,如客服、收银等,给社会带来挑战。

### 人与机器的融合

脑机界面及穿戴设备已出现,未来可能实现智能增强或数字化后续上传。

### 超智能机器的可能性

若AI智能突破人类,可能带来巨大影响,如机器主导或人类转型成为数字实体。

### 计算机可能比人类长寿

计算机可实现太空殖民,甚至比人类文明存续的时间更长。

### 未来发展趋势

增强现实、无人驾驶、穿戴设备等将普及,人工智能也将持续增强各行各业。
