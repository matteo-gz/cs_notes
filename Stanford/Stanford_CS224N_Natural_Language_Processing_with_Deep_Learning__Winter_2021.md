# stanford CS224N: Natural Language Processing with Deep Learning | Winter 2021

> <https://www.youtube.com/playlist?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ>

## 1. Stanford CS224N: NLP with Deep Learning | Winter 2021 | Lecture 1 - Intro & Word Vectors

### 课程目标

本课程的主要目标有三点:

1. 教授深度学习应用于自然语言处理(NLP)的基础知识,包括循环神经网络,注意力机制,Transformer等主流方法。

2. 提供有关人类语言本质及其理解难点的宏观了解。语言的产生仅几万至一百万年,对生命进化来说是一个很短的时间跨度。但口语交流能力极大推动了人类的优势地位。

3. 让学生掌握使用PyTorch框架开发NLP主流任务模型的能力,包括词向量学习,依存分析,机器翻译,问答等。

### 人类语言特性

1. 语言是由人类自行建构并通过社会传播的系统,随着人际交流不断演进。

2. 相对其他高等灵长目动物如黑猩猩,人类语言能力的发展较为晚近。语言约出现10-100万年前,对命门进化的总时间来说,这是一个非常短暂的时间跨度。

3. 但口语交流极大推动了人类的优势地位。约5000年前产生的书写系统进一步促进了知识的传播与应用。

4. 语言 transmission存在隐含的上下文和潜在意思,难以精确表达语义。跨文化翻译尤其困难。

5. 计算机理解人类语言是一个长期挑战。我们需要搭建语言-知识的互惠循环:语言包含丰富知识,但理解语言也需要依赖知识支持。

### 词向量学习

词向量学习算法Word2Vec能很好地用实数向量表示词义。这不符合传统看法,但最近十年深度学习证明其效果。

主要思想是:通过机器学习从大量语料中捕捉词与词之间的上下文/统计关系,从而将具有相似用法的词映射到相近的向量空间位置。

目前词向量技术广泛应用于机器翻译、依存分析、情感分析等任务,为自然语言处理的快速发展奠定基础。

### 课堂实践

教师还介绍了一些NLP任务模型的具体实现方法,比如:

- 根据词向量模拟词义之间的关系和共现统计规律

- 用具体例子演示如何计算词向量学习目标函数关于词向量的梯度

- 简要介绍优化算法在词向量训练中的应用

- 展示词向量应用实践,如完成类比问题“Italy:Rome::India:?”

这可以帮助学生从理论入手,逐步掌握深度学习在NLP中的实际运用。

## Stanford CS224N NLP with Deep Learning | Winter 2021 | Lecture 2 - Neural Classifiers

### 词向量模型

词向量模型最开始使用随机初始化每个单词的向量,然后通过大量文本语料迭代学习,目的是使得语义相近的词在向量空间距离近,可以更好地预测上下文词。

这个模型属于“袋模型”,不考虑词在句子中的顺序和位置,只关心词是否在上下文出现。这种模型对语言描述很粗糙,但即便如此也能学习到词之间的关系。

### 词向量学习

词向量学习的目标函数是对整个语料中的每个中心词,预测它周围词的概率分布。使用softmax函数将分数转化为概率。

学习算法使用随机梯度下降。每次随机选择少量样本计算梯度,然后使用学习率α更新参数,使目标函数值最大化。这样可以在短时间内学习更好的词向量,比全量迭代效率高几个数量级。

学习过程中,语义相近词的向量会越来越近,以提高预测正确上下文词的概率。最终学习出来的词向量可以很好地捕捉词语义相似性。

### 随机梯度下降

随机梯度下降的基本思路是:

1. 初始化模型参数θ为小随机值
2. 计算基于小样本的损失函数J的梯度
3. 使用学习率α,沿着负梯度方向更新θ,θ = θ - α*∇θJ
4. 循环执行前三步,不断更新θ,寻找最小化J的θ值

与全量梯度下降相比,随机梯度下降快速通过所有训练数据,实现学习。但每个更新仅基于少量样本,梯度估计带噪。实践证明这对神经网络学习很关键。

### 词向量表示

主流深度学习框架如PyTorch中,词向量默认采用行向量表示法。这与之前介绍的列向量表示不同,但本质是等价的。

## 3. Stanford CS224N NLP with Deep Learning | Winter 2021 | Lecture 3 - Backprop and Neural Networks

### 一. 词性标注任务简介

词性标注(Named Entity Recognition)是一个常见的自然语言处理任务。它的目的是在文本中识别各个单词是否归属于某个实体类别,如人名、地点名、产品名等。

对于句子"last night paris hilton wowed in the sequin gown samuel quinn was arrested in the hilton hotel in paris in april 1989",它给出了部分单词的实体分类,如"paris"既可以是地点也可以是人名,需要根据上下文进行判断。

### 二. 简单神经网络模型分类

使用神经网络进行词性标注任务的一个简单而有效的方法是:

1. 对每个待判断单词取其左右各两个单词作为窗口。

2. 将窗口内每个单词对应的词向量拼接成一个长向量作为输入。

3. 将输入向量输入神经网络中间层,进行矩阵乘加操作。

4. 将中间层输出向量与分类向量做点积,输出单词属于某类的概率。

5. 通过这个模型可以为每个窗口计算其成为某一类的概率,从而对窗口内文字进行分类。

### 三. 误差反向传播算法

使用梯度下降法更新模型参数θ,更新方程为:

θj(new) = θj(old) - α×∂L/∂θj

其中L为误差函数,α为学习率。我们需要计算每个参数θj关于L的梯度∂L/∂θj,以进行权重更新。这就需要使用误差反向传播算法来计算梯度。

### 四. 误差反向传播计算过程

1. 前向传播计算中间层和输出层结果。

2. 计算输出层单元误差δ。

3. 计算每一层单元的误差δ。

4. 计算每个权重θj关于L的梯度∂L/∂θj。

5. 根据梯度下降更新每个θj。

6. 重复1-5,每次使用新的θ进行更新,最后收敛到最佳解。

### 五. 其他注意事项

1. 这周的学习难点在于要理解神经网络中的数学原理。

2. 可以参考附加学习资料深入理解。如有任何问题欢迎去工作室咨询。

3. 这是该课程唯一深入探讨神经网络数学细节的课程。之后会使用软件进行实现。

4. 这周的作业要求理解数学原理和利用框架实现,对部分同学难度可能较大。

## 4. Stanford CS224N - NLP w/ DL | Winter 2021 | Lecture 4 - Syntactic Structure and Dependency Parsing

### 词类与词汇

- 词可以分为词汇词类,比如名词、动词、形容词等。
- 名词包括cat、dog等;动词包括talk、walked等;形容词包括large、barking等。
- 介词有by等;冠词有the等。现代语言学中,the等词类称为“限定词”。

### 短语结构

- 语言通过组合词来表达含义,形成更大的单位-语法短语。
- 名词短语如the cat、a barking dog等。
- 名词短语由限定词+名词构成,也可以在名词前添加任意个形容词。
- 介宾短语如by the door,由介词+名词短语构成。
- 动词短语如talk、talk to the cat,由动词±介宾短语构成。

### 上下文无关文法

- 上下文无关文法可以用来描述语法结构,将词组合成短语符合产生规则。
- 产生规则包含非终结符如名词短语、介宾短语等,和终结符如词汇。
- 名词短语->(限定词)(形容词...)名词(介宾短语)
- 介宾短语->介词名词短语
- 动词短语->动词(介宾短语)
- 句子->名词短语动词短语

### 依存结构

- 除上下文无关结构外,还有依存语法描述句子结构。
- 依存语法强调词与词之间的依存关系。

### 总结

该课讲授了语法结构的基本概念,如词类、短语结构、上下文无关文法等,为后续依存解析奠定理论基础。

## 5. Stanford CS224N - NLP w/ DL | Winter 2021 | Lecture 5 - Recurrent Neural networks (RNNs)

### 再次提起上次讲授的依存语法分析  

上次介绍了基于状态转换的依存语法分析器,使用了大量的语法特征。缺点是特征稀疏、不完整,且计算特征消耗了很大时间。

### 引入基于深度学习的依存语法分析器

新的依存语法分析器采用如下改进:

1. 每个单词使用分布式表示学习其词向量

2. 词性和依存关系标签也使用分布式表示学习向量空间

3. 配置(栈+队列)用concat获取更紧凑的表示

4. 使用softmax分类器预测下一个状态转换

5. 通过监督训练优化分类器参数

### 实验结果较好

实验结果显示,新的Neural依存分析器解析效果比传统语法分析器提升2%,运行速度比传统快两倍。

### 语言模型与循环神经网络

本次讲授的重点是语言模型和循环神经网络。语言模型学习单词的概率分布,预测下一个单词。循环神经网络genius于处理序列数据。

### 作业三内容

本次作业要实现基于PyTorch的新依存分析器。结构详细注释,实现步骤指导明确,依靠应用学习PyTorch。

## 6. Stanford CS224N NLP with Deep Learning | Winter 2021 | Lecture 6 - Simple and LSTM RNNs

### 简单RNN语言模型

- 简单RNN语言模型将文本看做一个长词序列,前面几个词作为上下文输入网络预测下一个词。
- 它包含词嵌入层将词映射成向量,隐状态层迭代计算每个时间步的隐状态, Softmax输出层预测下一个词的概率分布。
- 隐状态由前一个隐状态和当前词向量通过RNN计算公式更新而来。

### 训练RNN语言模型

- 获取大量文本作为训练 corpus ,将其看做一个长词序列。
- 对corpus中的每个词前缀,输入RNN预测下一个词的概率分布。
- 通过交叉熵损失来评估预测与实际下一个词的一致程度,作为训练目标。
- 逐步移动滑动窗口,计算每个位置的损失后求平均,作为该batch的总损失。
- 使用反向传播通过梯度下降来更新模型参数,减小损失。

### 教师强迫训练

- 训练中我们不使用RNN生成的下一个词作为下文,而是直接使用原corpus中的下一个词。
- 这样强制模型根据真实下文学习,而不是自行探索,简化了训练过程。

### 使用LSTM解决RNN问题

- 简单RNN难以学习长期依赖关系。LSTM结构引入门控 units可以更好记住远处信息。

- 双向RNN通过正向和反向同时学习上下文。

- 层 RNN通过添加隐层可以学习更高层次特征。

### 序列到序列模型

序列到序列模型通过注意力机制将编码器-解码器框架应用于机器翻译任务。

## 7. Stanford CS224N NLP with Deep Learning | Winter 2021 | Lecture 7 - Translation, Seq2Seq, Attention

### 机器翻译的历史

- 1950年代初人们开始研究机器翻译,旨在通过计算机帮助翻译苏联的文献来监视冷战时期苏联的消息
- 但当时计算机能力和语言学理论水平都很低,仅使用简单词汇查找表和规则匹配,效果不佳
- 1960年美国政府出台阿尔帕卡报告,认为这种方法行不通
- 之后研究一度中断,1990年代恢复基于规则的机器翻译研究

### 统计机器翻译

- 1990年代中期基于语料库统计模型开始兴起
- 需要大量的平行语料,如欧盟文档、加拿大议会记录提供英语与其他语言的翻译对照样本  
- 利用贝叶斯规则,将翻译概率分解为语言模型概率和翻译模型概率
- 语言模型用来评判目标语言语句的可能性
- 翻译模型学习源语言词汇与目标语言词汇之间的对应关系

### 对齐模型

- 将翻译任务进一步分解,引入对齐变量表示源语句与目标语句各部分的对应关系
- 学习不同语言词序差异及一对多、多对一等复杂对应规律
- 可以获取单个词或短语翻译的翻译概率
- 有助于翻译模型学习不同语言表达含义的差异

### 序列到序列模型

- 用于统计机器翻译的经典模型,将源语句与目标语句表示为序列,学习它们之间的映射关系
- 注意力机制改进该类模型,可以序列学习到句子全局信息

## 8. Stanford CS224N NLP with Deep Learning | Winter 2021 | Lecture 8 - Final Projects; Practical Tips

### 基本情况

- 本节课将介绍最后期末项目和一些实用技巧
- 先回顾上节未完成的注意力机制,然后主要讨论期末项目选题、数据获取以及研究方法
- 给予一个阅读理解问答系统的简要介绍,这是默认的期末项目;但将在第6周详细讲解  
- 也作为一个机会让同学提出任何疑问

### 注意力机制

- 使用编码器获 得源语言序列的隐状态
- 解码器每一步计算新隐状态,同时使用隐状态与编码器隐状态进行点积,得到注意分数
- 注意分数经Softmax归一化得到注意力分布
- 根据分布对编码器隐状态做加权平均,得到新的注意力输出向量
- 将注意力输出向量与解码器隐状态连接,作为下一个预测词的输入

### 注意力机制优点

- 明显提高了机器翻译效果
- 允许解码器专注源语言特定部分
- 消除隐状态信息瓶颈
- 帮助梯度更好流动,减轻消失梯度问题
- 提供可解释性,通过分布可以看出对准字词

### 期末项目

- 默认项目是阅读理解问答系统,但将在6周详细介绍
- 找研究话题时可考虑:应用领域、数据来源、模型和任务
- 寻找公开数据集前必需检查版权和使用许可
- 研究过程中可采集自己语料
- 鼓励同学提出任何问题

## 9. Stanford CS224N NLP with Deep Learning | Winter 2021 | Lecture 9 - Self- Attention and Transformers

### 自回归神经网络的问题

自回归神经网络对单词的顺序依赖很强,难以学习长距离依赖关系。它编码的是单词的线性顺序关系,但词序关系未必就是语句结构关系。此外,自回归神经网络各个时间步的计算是串联的,无法并行化,在大规模数据集上训练效率低。

### 以注意力机制取代递归

2016年,自回归神经网络在许多自然语言处理任务中表现不错。但其有长距离依赖关系难学和难并行化的问题。后来研究者提出用注意力机制来取代递归,这个思路取得成功。

### 窗口模型

窗口模型可以捕捉词汇的局部上下文。它通过一个词窗口来对中心词构建表示,这类似一维卷积。与自回归神经网络不同,窗口模型计算量不随序列长度增加。它可以独立地对每个词做嵌入和上下文提取,具有很好的并行性。

### 变形器模型

变形器模型是一种常用的注意力模型。它抛弃了递归结构,完全依靠注意力机制来建立词汇之间的关系。研究表明变形器模型在许多任务上效果很好。

### 改进变形器模型

变形器模型也存在一些缺点,比如计算开销大。近年来有许多工作试图改进和扩展它,如提出更高效的注意力实现方式。

## 10. Stanford CS224N NLP with Deep Learning | Winter 2021 | Lecture 10 - Transformers and Pretraining

### 词构成与子词模型

语言中的单词通常是可以分解的。比如英语中的形容词可以加上不同数量的"a"来表达程度,不同语言的动词也可以通过前缀和后缀表达语法信息。但固定词汇表并不能很好处理这类词汇。

子词模型试图在词汇和字符之间寻找一个平衡点。字节对编码(BPE)算法先从语料中学习基于字符的词汇表,然后 iteratively地将频率高的字符序列合并为一个子词加入词汇表。它可以很好处理常见词,同时也可以将未见词分解为子词进行处理。

### 预训练动机

早期词向量预训练可以使词向量学到词语分布信息。但词向量仅考虑单个词而没有捕捉上下文。为了利用更多语义信息,人们提出直接对模型进行预训练。

### 模型预训练方法

#### 解码器预训练

将 Transformer 解码器直接应用于下游任务,如机器翻译。

#### 编码器预训练

使用自回归语言模型进行预训练,将context作为输入,预测下一个token。

#### 编码器-解码器预训练

同时预训练编码器和解码器,解码器生成响应 conditioning 在编码器输出。

### 预训练目的

预训练的目的是让模型学到语言的结构特性,如语法和语义。如BERT通过近义词替换预训练任务让模型具备更好的上下文敏感性。但预训练目的的具体机制还需进一步探究。

### 很大模型与动态上下文学习

一些万亿参数级的模型如GPT-3已经发挥出强大的动态上下文学习能力。这类模型极大提升了自然语言处理能力。

## 11. Stanford CS224N NLP with Deep Learning | Winter 2021 | Lecture 11 - Question Answering

### 1. 什么是问题解答

问题解答(QA)的目标是建立系统来自动回答人类用自然语言提出的问题。QA可以追溯到1960年代,早期系统通过 dependency analysis 来找到问题与文本段之间的匹配来产生答案。

QA任务可以根据信息来源、问题类型和答案类型分类:

- 信息来源:单篇文本、大量文档集合、结构化数据库等
- 问题类型:事实性问题、开放域问题、复杂问题等  
- 答案类型:短句、段落、列表、是非答案等

### 2.深度学习改变了QA领域

与10年前复杂的模块化系统不同,当今主流QA系统多建立在端到端深度学习框架上,如BERT网络。深度学习大幅提升了QA领域的发展。

### 3. 文本阅读理解

文本阅读理解任务是根据单篇文本回答关于文本内容的问题。输入为文本、问题,输出为答案。

### 4. 问答系统实际应用

搜索引擎如Google可以回答各种类型的问题,如“地下湖位置”“如何防护新冠”等。智能助手如Alexa也被广泛用来解答问题。IBM Watson问答系统在2011年曾击败日本电视节目冠军。

### 5. 知识图谱问答

知识图谱问答根据结构化知识库回答问题,需要将问题转化为逻辑格式校验知识库。

### 6. 视觉问答

视觉问答需要同时理解问题和图像来回答,是计算机视觉与自然语言处理交叉领域。

## 12. Stanford CS224N NLP with Deep Learning | Winter 2021 | Lecture 12 - Natural Language Generation

### 定义自然语言生成

自然语言生成(NLG)指给定一些输入,生成文本来描述、应答、翻译或总结这些输入。NLG着重研究如何构建系统能自动生成连贯有用的书写语言。

以往NLG范围较小,许多任务今日视为NLG问题当时并不包括大量文本生成。随着深度学习的发展,NLG范围大幅扩展。

### NLG应用

- 机器翻译:2014年起应用神经网络,翻译质量快速提升。

- 对话系统:西里、亚马逊Alexa等都含NLG模块回答用户查询。

- 总结:见新闻摘要。也用于总结邮箱、会议笔记等。

- 数据到文本生成:总结表格、知识图等数据重要内容。

- 视觉描述:描述图像或视频内容。

- 创意应用:帮助人工写短篇小说、博客。自动生成十四行诗。

### NLG模型原理

NLG系统采取自回归设置,将已生成词语反馈给模型生成下一个词语。

模型计算每个词表索引对应的分数向量。softmax函数将其转化为词表概率分布。

采样算法从分布中选择下一个词语。最大似然训练最小化负对数似然函数进行多类预测,训练模型正确预测下一个词语。

### 总结

NLG广泛应用于机器翻译、对话系统、总结等,助力人与AI更好交流。随深度学习进步,NLG范围不断扩大,解决更复杂任务。

## 13. Stanford CS224N NLP with Deep Learning | Winter 2021 | Lecture 13 - Coreference Resolution

### 什么是共指解析

共指解析(co-reference resolution)是识别文本中提到同一个实体的所有提法,并将其连接起来。

例如,在一个短故事中:

- “Vanaga”是第一个提到的人物
- “Akilah”也是个人名
- “local park”指代一个地点
- 后续还多次出现“Akilah”和“Vanaga”
- “Prajwal”是“Akilah”的儿子

共指解析任务就是将文本中指代同一个实体的各个提法分组连接起来,如“Vanaga”、“her”都指代“Vanaga”,“Akilah”的多次提及都指代“Akilah”这个人等。

### 共指解析中的语言结构

共指表达会有复杂的语法结构,例如:

- “Akilah’s son”本身也是一个包含多个名词短语的长名词短语
- “they”可以同时指代“Prajwal”和“Akash”这两个名词,称为分裂先行词

### 共指解析算法

尽管人类语言具有分裂先行词的现象,但大多数NLP算法会做以下简化:

- 每个名词短语最多只能与一个实体匹配
- 无法处理分裂先行词情况

### CNN用于共指解析

字符级CNN也常用于表达词汇,有助于共指解析模型学习词汇之间的关系。

### 状态级语言模型

纽约大学研发了一款新模型,效果领先同类型其他模型,但无法很好处理分裂先行词情况。

### 评估方法

主流评估标准是MUC、B3和CEAFe,比较不同系统的预测结果与人工标注结果的一致程度。

## 14. Stanford CS224N NLP with Deep Learning | Winter 2021 | Lecture 14 - T5 and Large Language Models

### 传统迁移学习方法

- 2018年爆发出的一系列论文开启了NLP领域使用预训练模型的热潮,比如ULMFiT、ALBERT等
- 2019年研究方法更是雨后春笋般涌现,包括新的预训练任务、数据集、模型结构等
- 但这也导致难以判断哪种方法效果最好,因为每个方法都有不同的设计变量如模型大小、预训练时间等

### T5模型

- T5 paper提出把每个NLP任务视为文本生成任务,将输入文本和任务前缀一起输入模型,输出生成响应文本
- 这种统一处理不同任务的方法消除了研究中常见的变量,让各种任务可以在同一个模型架构下进行
- T5模型采用经典的编码器-解码器结构,新加入的任务前缀让模型知道应该如何处理输入

### 任务格式化示例

- 机器翻译:英文句子+“translate english to german”作为输入,德文句子作为输出
- 分类任务:句子+“classify”作为输入,分类标签文本如“not acceptable”作为输出  
-回归任务:将预测值转换成字符串后进行预测
- 更多NLP任务均可视为文本生成问题进行格式化

### T5实验与结论

- 实验验证了mask language modeling预训练任务效果最好
- 模型规模扩大可以显著提升transfer效果
- T5架构可以很好地处理各种NLP任务,在许多任务上刷新SOTA
- 验证了将NLP问题统一处理的重要性

### 后续研究

- 研究如何支持非英语语言
- 检视预训练模型具备哪些知识
- 分析是否在预训练过程中记住了训练数据
- 探索transformer结构的新修改是否可进一步提升效果

## Integrating knowledge and language models

### 介绍

- 简要介绍标准语言模型和掩蔽语言模型。
- 语言模型在没有人工标注数据的情况下，在大量未标记文本上进行训练。
- 最近，语言模型可以用来生成带有语言理解概念的上下文表示。

### 语言模型可以编码什么样的知识？

- 语言模型可能已经从训练数据中编码了一些事实/常识知识。
- 但是它们可靠地回忆知识的能力是有限的。
- 它们倾向于生成合理但不一定是事实上正确的填空语句的预测。
- 原因包括在训练过程中没有看到知识、知识太稀缺或对语句的措辞敏感。

### 增加知识的动机

- 预训练表示在下游任务中使用，其中一些是知识密集型任务。
- 包含实体知识可以帮助任务，如关系抽取。
- 作为一个长期目标，语言模型可以取代结构化知识库来进行知识查询。

### 添加知识的技术

- 添加预训练的实体嵌入。
- 使用外部存储器/键值存储。
- 修改训练数据。
- 最近的工作实现了这些技术并显示了有希望的结果。

### 评估挑战

- 知识评估需要在表面模式之外探究语言理解。
- 评估对语句的措辞和问题风格敏感。

### 结论

- 在语言模型中编码更多知识取得了显著进展。
- 但是可靠地回忆知识仍然是一个挑战。
- 未来的工作将继续探索构建更具知识丰富的语言模型的技术。

## 16. Stanford CS224N NLP with Deep Learning | Winter 2021 | Lecture 16 - Social & Ethical Considerations

### 定义伦理学

伦理学是研究在生活中追求善与恶和行为右与错的学问。它是一个实践性的学科,旨在确定人应该如何生活及应该采取什么样的行为。

简而言之,伦理学就是做善事和正确的事。

### 语言与人的关系

语言之所以与伦理学相关,是因为语言源于人,并且包含人的偏视。语言总是由人创造和使用,目的是与其他人交流,因此它必然会涉及到人和社会层面。

### 伦理考量在NLP中的重要性

任何涉及语言的技术,如词性标注、句法分析等,都可能影响人,因此我们应考虑其中的伦理问题。我们建立的模型可能会吸取社会偏见,影响其他人。所以在处理数据、规划模型等各个环节,我们都应重视其中的伦理因素。

### 困惑车辆悖论

这是一个经典的伦理困惑。假设你可以控制一辆失控的火车发生事故的轨道,你可以选择牺牲1或5人。这就引发很多考量,比如如果牺牲的1人是你的家人呢?这类问题很难下定论。

### 鸡分类困惑

假设我们训练一个模型来识别鸡蛋里面的雏鸡 gender,以决定它的 destiny - 是否去肉鸡场或蛋鸡场。这是否有伦理问题?

实际上,我们今天已经在做这种分类。但我们也可以考虑,随着社会进步,未来是否也可以尊重动物生命?这类问题决不是简单的对错。

### 算法偏差

算法偏差就是模型在某些人群上表现不佳的问题。它会直接影响这些群体的利益,从而产生不公正结果。这是NLP领域重要的伦理问题之一。

### 总结

伦理问题往往没有明确答案。我们在研发新技术时,应考虑各方面影响,平衡各种因素协商最优解。重要的是以人为本,保障每个群体的权益,同时也考虑技术是否可行和商业可持续等实际条件。

## Stanford CS224N NLP with Deep Learning | Winter 2021 | Lecture 17 - Model Analysis and Explanation

### 理解模型的重要性

理解模型对我们来说重要的原因有以下几点:

1. 我们需要知道模型是如何工作的。否则模型就像一个黑匣子,输入与输出之间的关系无法理解。

2. 我们需要根据模型的工作原理来改进模型,制作更好的下一代模型。通过分析模型成功和失败的例子,找到模型需要改进的地方。

3. 分析模型可以发现模型中的偏差问题,如性别偏差等。这对建造更公正的模型很重要。

4. 分析可以帮助我们思考未来10-25年深度学习在自然语言处理领域的发展方向和难点。

### 分析模型的不同层次

我们可以从不同程度的层次来分析模型:

1. 最高层次上,看模型只是一个概率分布,可以给输入预测输出。

2. 查看模型每个层次的状态,如transformer编码器每层状态的变化。

3. 查看模型每一个细节,如参数和计算图结构。

不同层次分析各有优势,可以提供不同角度的理解。

### 出域评估

出域评估用新的测试集对模型进行测试,这个测试集与训练集不同。这可以检测模型是否过拟合,是否真正学习了语义关系。

### 例子解释能力

对单个例子,找出模型做此预测的依据,给出一个易于理解的解释。这可以帮助理解模型成功或失败的原因。

### 分析模型表示

研究模型内部隐状态表示,如隐层向量,试图理解模型内部的表示和计算机制。

### 模型组件对性能的影响

移除模型部分组件后测试性能,与分析结果相对应,可以进一步理解模型工作原理。

### 总结

模型分析可以从不同层次提供部分理解,但无法完全理解模型。应根据问题从高到低抽象程度进行分析,找到问题根源。分析结果可以指导模型改进与发展。

## 18. Stanford CS224N NLP with Deep Learning | Winter 2021 | Lecture 18 - Future of NLP + Deep Learning

### 引言

通过自动总结材料中重要知识点,介绍NLP领域最新发展趋势及研究前景。

### 大规模语言模型和GPT-3

常见的自监督学习方法为:1. 将数据转换成整数序列 2. 定义损失函数最大化数据概率或创建冗余自动编码损失 3. 在大量数据上训练。这种方法可用于多种模态。

GPT-3模型为96层Transformer模型,拥有150亿个参数,训练数据量达500亿词汇。通过稀疏注意力机制实现了更大规模。

### GPT-3的任务能力

GPT-3在语言建模、文本完成、阅读理解等任务上优于GPT-2,在少量示例学习任务后也能表现出学习能力。它在知识密集型任务如问答上也有很好表现。

### 上下文学习

GPT-3可通过上下文学习来实现新的任务的快速适应。其训练可以看作内外两个循环,外循环学习参数使内循环学习更高效。这使它同时也成为一个学习快的系统。

### 上下文学习示例

给出若干任务示例后,GPT-3可以学习任务规范并成功完成。比如根据数据库定义范例学习数据库概念,根据概念混合定义学习新概念等。但对偏导例无法泛化。

### 模型评估与未来趋势

尽管Transformer表现卓著,但在实际应用中也会表现出不稳定性。需要更全面评估模型,弥补当前基于文本的学习限制。比如学习从多模态交互中获得语言能力。

### 总结

概括本次讲座介绍的NLP前沿技术发展趋势,包括大规模Self-supervised学习、GPT-3等大规模语言模型的能力及限制,以及如何全面评估模型表现指出研究发展方向。

## 19. Stanford CS224N: NLP with Deep Learning | Winter 2020 | Low Resource Machine Translation

### 机器翻译问题

我们想要在英语和法语之间进行翻译。我们有一大批英语句子和其法语翻译对配的语料库,我们称这些英语句子为“源句子”,对应的法语句子为“目标句子”。学习的问题是给定一英语句子,预测其法语翻译。我们使用交叉熵损失函数最大化目标翻译给定源句子的概率,使用梯度下降训练序列到序列模型。

### 假设

我们的假设是:

1. 两个语言相对相关,如英语和法语。

2. 拥有大量paralleldataset。此处为监督学习的优良例子。

### 世界语言状况

世界有超过6000种语言,大多数不属于同一语系。英语只作为5%人口的母语。如果按语言使用人口数排序,前10大语言也只涵盖世界人口的不足一半。许多语言使用人口很少,甚至没有数字数据进行训练。

### 低资源语言翻译问题

低资源语言指域内paralleldataset少于1万句的语言。Nepali语有2500万使用人口,但其与英语的paralleldataset量远少于英法语。我们希望用于测试的新闻文本,但Nepali与英语新闻文本之间没有paralleldataset。我们只有一点paralleldata来自其他领域,以及对应语言的单语语料库。此时,如何利用所有这些数据进行我们最终任务的翻译就是一个综合学习问题。

### 低资源机器翻译挑战

1. 数据方面:很难获取与目标域相近的训练数据;如何利用其他语言或领域的数据;如何获取评估数据。

2. 模型方面:如何在极少监督下学习;如何处理多语言和多领域框架。

### 解决方案

将介绍利用paralleldata、单语数据和其他语言资源,通过预训练和迁移学习等方法进行低资源机器翻译。

## 20. Stanford CS224N: NLP with Deep Learning | Winter 2020 | BERT and Other Pre-trained Language Models

### 历史与背景

词嵌入深深影响了NLP领域。2003年Bengio等人首先提出词嵌入思想,可以将离散的文本转化为连续的向量表示,这极大促进了深度学习在语言处理中的应用。

接着,GloVe和word2vec采用更高效的统计模型训练词嵌入,可以在更大规模数据集上训练,但它们都是无上下文的。

2015年,Andrew Dai和Quoc Le通过先训练语言模型在某些任务上微调模型,实现了第一种上下文表示。但模型规模和数据集还不够大,效果一般。

2017年,ELMo首次提出双向LSTM语言模型提取特征,在各种任务上效果优于word2vec。在很大数据集上训练更大模型实现上下文表示,无需改变原有模型结构。

同年,OpenAI提出GPT,采用12层层Transformer训练超大规模语言模型,通过微调最后一层进行分类,效果不错。但仍是单向的。

### Transformer与BERT

Transformer克服了LSTM局部性偏差问题,长程依赖关系也可以被充分考虑。并且由于层层注意力机制,可以将一个长序列放入一个batch中计算,充分利用GPU并行计算能力。

基于此,谷歌提出BERT模型。BERT采用Transformer encoder对一个长序列进行双向训练,消除了过往语言模型的单向限制。它可以很好地学习词语在不同上下文中的表示,取得NLP许多任务的state-of-the-art效果。

### 总结

通过话语历史,可以看到预训练语言模型从原始词嵌入到考虑上下文信息的发展过程。ELMo首次提出上下文表示提取,GPT进一步优化,但都是单向的。Transformer架构令BERT能够实现真正的双向上下文学习,极大推进了预训练语言模型在NLP各项任务上的应用。

## 21. Stanford CS224N I NLP with Deep Learning | Spring 2022 | Socially Intelligent NLP Systems

### 社交不平等话语中的循环关系

语言常常会反映社会不平等,这会体现在少数群体的描述上会更加刻板或偏颇。同时,仇恨言论也主要针对少数群体。语言又会影响社会,例如仇恨言论可能会加剧不同群体之间的关系。这形成了一个循环关系。

### NLP任务中存在的风险

自然语言处理任务如果没有考虑训练数据中的社会动态,将面临下列风险:

1. 对话系统会快速采取冒犯性立场,例如微软Tay系统转变为种族主义言论。

2. 语言生成可能会产生不一致或偏颇的内容,例如オペンAI的GPT-3模型研究显示它很快就可能产生有毒内容。

3. 情绪分析和仇恨言论检测模型可能会对少数群体输入表现不佳,甚至表现出偏见。

4. 若训练数据中存在社会不平等,模型很难学习到公正的概念。

### 语言模型训练数据问题

目前大型语言预训练模型如BERT系列的训练数据来源互联网,包括Reddit论坛等网站。这可能让模型学习到许多社会偏差和立场,同时这些模型本身缺乏社会意识,很容易产生有毒内容。

### 检测语言中的偏差与有毒内容

研究發现目前的仇恨言论检测模型可能会表现出种族偏见。如只能更好地检测白人群体的仇恨言论,对其他群体表现不佳。这可能是因为训练数据和标签本身可能带有偏差。

### 通过重新生成文本来减少偏差

使用强化学习训练的Power Transformer模型,可以检测文本中的社会偏差,并对其进行修改,从而产生减少偏差的新文本。这为减少NLP模型产生的不当影响提供一种方法。

### 未来工作

未来可探索将人性化视角结合到模型训练和评估中,以更好捕捉与理解语言中的复杂社会动态,实现公正的自动语言处理。

## 22. Stanford CS224N NLP with Deep Learning |Spring 2022|Guest Lecture: Building Knowledge Representation

### 语言模型如何表示知识

- 语言模型主要通过transformer结构学习知识,transformer包含词向量、前馈网络和注意力网络。

- 前馈网络实质上是一个关键值记忆结构。它通过矩阵乘法将输入向量映射为与各个词向量间的相似程度,通过非线性激活函数保留正值,实现关键值选择。

- 第一个矩阵乘法用来计算输入向量与每一行向量的点积,即各词向量与输入间的相似程度。

- 非线性激活函数将负值置0,保留正值。

- 第二个矩阵乘法通过列向量进行加权求和,选择关键值输出。这里的第二矩阵可以看成存储值,通过第一个矩阵选择过程得到的权重来选择输出。

### 对现有知识表示是否满意

- 虽然语言模型取得很大进步,但现有知识表示方式在复杂任务上还不够。

- 语言模型无法对医疗病例进行诊断,不能修车,无法进行新颖科研等。这些任务同时需要智能和专业领域知识。

- 早期尝试使用规则本体直接人工输入知识,但规则一旦出错模型很脆弱。

- 今天的语言模型能从网络自动学习知识,给解决这个问题提供了机会。

### 建议增强模型知识能力的方法

- 研究人员提出使用内存增强模型来解决问题。

- 他们以知识编辑任务为例,指出如果能成功编辑模型内知识,说明我们对模型内部结构有一定了解。

- 知识编辑任务比如要求模型将“艾菲尔铁塔位于罗马”这个概念转变为细粒度知识。

- 他们提出的ROME模型通过搜索找到影响知识的关键参数,进行微调来实现编辑。编辑后模型在相关问题上的答案都随之改变。

- 内存增强模型通过在transformer结构外增加一个外部内存模块,可以更好地表示和使用知识。未来工作会深入研究这个方向。

## 23. Stanford CS224N NLP with Deep Learning | Spring 2022 | Guest Lecture: Scaling Language Models

### 语言建模的动机

语言是人类用来高效准确地记录世界各种知识的手段,对AI模型来说也很有价值。

1. 语言本身是人类智慧的体现,研究它对开发AI理解能力很重要。

2. Internet和书籍中含有大量免费的语言数据,可以用于训练模型。图书馆大约有1000亿词,互联网上的语言数据远大于此。

3. 通过语言交流能更好地理解模型的长处和短板,以及如何让模型与人类偏好一致。

### 语言建模需要的基本要素

主要包括模型、数据集、计算资源、损失函数和优化器。

大多数语言建模任务都采用下一个词预测作为损失函数。

### 语言建模规模的数据和计算量

1. 一般人如果每天读一本长篇小说,大约可读2000亿词语言。

2. GPT-3训练数据约为2000亿词。

3. Common Crawl约有1万亿词,图书馆约有1000亿词。

4. GPT-3模型参数约为2000亿,层数96,嵌入维度10000。

5. Transformer每参数每个token进行一次加法和一次乘法运算。参数越多,计算量越大。

6. 训练GPT-3类模型需要计算量约为1024乘以1024乘以300亿极大规模。

7. 单张A100显卡每秒约为3×1014FLOPs,每天约为2×1019FLOPs。

8. 训练一亿参数模型需要计算量约为1024乘以1024乘以300亿,约为1024乘以300亿=1024乘以1024乘以100亿=10^24FLOPs。

### 语言建模规模依赖定律

随着模型和数据规模的增加,模型表现会线性或平方根级提升。这对生成模型和机器学习模型普遍适用。
