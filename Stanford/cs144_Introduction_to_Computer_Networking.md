
# cs144 Introduction to Computer Networking

> <https://www.youtube.com/playlist?list=PL6RdenZrxrw9inR-IJv-erlOKRHjymxMN>

## 1. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn1 p1 1 0   The Internet and IP Introdu

### 1.1 什么是互联网

互联网是一种使用协议连接不同计算机网络的全球性网络。它能将各种不同的网络连接起来,容许计算机用户进行通信。

### 1.2 基础知识

互联网工作原理采用分层设计。有4个主要层级:物理层、数据链路层、网络层和传输层。网络层采用互联网协议(IP)进行数据包传输。传输层常采用传输控制协议(TCP)处理流量控制和错误检测。

各层之间通过封装和协议实现通信。数据会被分割成小数据包进行传输。每一包会附加地址头、校验信息以实现正确传输。不同层级提供不同的服务。

### 1.3 应用原理

万维网等应用层协议通过TCP/IP进行通信。请求网页时,计算机会将网页数据分割成数据包,通过IP寻址传送到目标服务器。服务器处理请求后,会将响应分片返回。IP核心功能即根据地址选择最佳路径传输数据包。

### 1.4 网络软件工具

学习网络原理后,可以使用网络抓包软件Wireshark等工具,监测本机网络活动,观察数据包的传输过程,帮助理解网络知识。

## 2. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn2 p2 1 1   A day in the life of an app

### 网络应用的基本运作模式

网络应用的基本模式是两台计算机分别运行本地程序,这两个本地程序通过网络进行通信。最常见的通信模式是一个可靠的双向字节流。

程序A运行在计算机A上,可以将数据写入网络,这样数据就可以通过网络被程序B运行在计算机B上的读取。同样,程序B也可以将数据写入网络,程序A读取。

### 世界宽网络

世界宽网络使用了HTTP协议,当浏览器显示一个URL时,表示它使用HTTP协议进行通信。

客户端打开与服务器的连接,向服务器发送GET请求要求页面。服务器接收请求,检查请求是否有效,然后返回响应。响应包含状态码告知请求结果,如200表示请求被接受,响应内容包含网页数据。

### BitTorrent

BitTorrent允许人们共享和交换大文件。不同于网络只从服务器请求文档,在BitTorrent中客户端可以从多个其他客户端请求文档。

BitTorrent将文件分割为数据片段,当客户端从另一个客户端下载完整数据片后,它就可以告诉其他客户端这个数据片可供下载。这些协作客户端形成一个“联合”。

BitTorrent也使用可靠双向字节流进行通信。客户端首先需要找到种子文件描述待下载的数据,种子还告诉BitTorrenttracker节点该种子的联合成员情况。

### Skype

Skype允许语音和视频聊天。当客户端A呼叫客户端B时,它与rendezvous服务器建立连接,服务器通知B有来电,B接听后与A直接通信。

由于家用路由器使计算机变成了NAT下的客户端,这给Skype通信带来困难。Skype使用反向连接或中继服务器来置顶此问题,实现客户端之间可靠通信。

### 总结

可靠双向字节流为不同主机上的程序提供了简单地读取写入数据的抽象,隐藏了网络细节。这种模式被广泛应用于web、BitTorrent和语音通讯等网络应用,实现了分布式系统之间高效交互。

## 3. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn3 p3 1 2   The four layer Internet model

网络工程师将互联网的各种功能分为不同的层次,以便于方便的整理和管理。

最上层是应用层,包括比特币客户端、Skype、万维网等应用程序。应用程序通过应用层协议将数据发送给对端应用程序。

传输层的主要职责是可靠地将数据传输给对端,可以保证数据的顺序及完整性送达。常见的传输层协议有TCP和UDP。TCP提供可靠传输服务,UDP则不提供任何保障。

网络层的主要任务是将数据包通过互联网从源地传送至目的地。IP就是网络层协议,它采用“尽量送达”的服务,但不做任何保障。

链路层负责将数据包通过单个链路传输给下一跳路由器或者目的主机。常见的链路层技术有以太网和WiFi。

每个层级都提供了一种服务供上层使用。应用层可以使用TCP或UDP向对端传输数据,而不需了解下层工作原理。传输层可以使用IP网络来传输数据包,而不用考虑具体的链路实现。这种分层结构简化了各层设计,提高了可扩展性。

## 4. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn4 p4 1 3   The IP service model 64

### IP的数据报

IP数据报是由头和数据两部分组成的。传输层交给网络层一个传输段时,网络层会将传输段封装到一个新的IP数据报内。

IP的工作是将数据报传送到互联网的另一端。首先数据报需要通过第一跳的链路层帧传递到第一个路由器。所以IP会将数据报发送给链路层,链路层再将其封装到以以太网包或其他链路层帧中,然后发送给第一个路由器。

### IP服务模型的特征

IP服务模型有以下四个特征:

1. 它会将数据报从源主机发送到目的主机。

2. 它是不可靠的,但会尽最大努力将数据报传输。

3. 网络不会为数据报维持任何连接状态。

4. 每个数据报都会独立地传送,网络层不会为任何通信保留状态信息。

### IP是不可靠的

IP不保证数据包一定能成功送达目标主机,可能会延迟送达、乱序送达或完全未送达。但IP不会毫无理由地丢弃数据包,只会在必要时(如路由器队列满时)丢包。IP也不会主动重发丢包的数据。

### IP服务的其他设计原因

1. 保持网络的简单性,使网络运行更快、维护成本更低。

2. 引导“端到端原则”,尽可能在端主机实现功能特性。

3. 一个简单的IP服务可以支持各种可靠或不可靠的上层服务。

4. IP能在任何链路层运行,这符合Internet旨在互连现有网络的初衷。

此外,IP内置了一些额外功能,如防止数据包无限循环和支持数据包分片。

## 5. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn5 p5 1 4   A Day in the Life of a Pack

### 四层模型

四层模型将数据从应用层传输到传输层,传输层将数据分成段将其可靠地传输到另一台计算机上的应用。传输层将数据段封装为网络层数据包传输。

### TCP连接

大部分网页使用TCP协议传输。TCP连接包含客户端和服务器,服务器监听连接请求,客户端向服务器发起连接请求,服务器响应,建立连接需要进行三次握手:客户端SYN包,服务器SYN-ACK包,客户端ACK包。

### IP地址

打开TCP连接需要两个地址:IP地址用于网络层传输数据包到计算机,端口号用于告诉计算机应用层数据应传输到哪个应用。网页服务器通常使用端口80。

### 路由

数据包从客户端到服务器可能需要数次路由跳转。首先从客户端无线网络到接入点,接入点有线连接互联网,数据包通过若干路由器传输。每个路由器根据路由表决定将数据包送往哪个接口。默认路由用于未知目的地的数据包。

### 数据包分析

使用Wireshark查看请求网页产生的TCP三次握手包和HTTP请求响应包。使用Traceroute追踪数据包从客户端到服务器经过的各个路由器。

## 6. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn6 p6 1 5   Packet switching principle

### 分组交换

分组交换是把数据分割成独立且自包含的分组,每个分组内含需达到目的地的信息。分组包含源地址和目的地址,并在网络中独立传输。

### 分组的路径

源计算机将分组发送给第一路由器,然后依次由路由器转发,直至目的地计算机。每一个路由器都根据 Destination 地址决定将分组交给下一个路由器。

### 静态路由分组

每个分组内含明确的路径信息,指定整个传输路径上的每个路由器ID。源计算机设置路径,分组内带有路径信息传输。每个路由器根据信息进行转发。

### 动态路由分组

每个路由器保存 Destination 地址与下一跳路由器映射表,根据表查找将分组发送到下一节点。分组仅带有Destination地址,每个路由器动态决定下一跳。这是目前网络中更常用的方式。

### 分组交换优点

1. 分组独立传输,每个路由器仅处理单个分组,简化路由器设计。

2. 可以高效的动态共享链路资源。如多个用户共享WiFi,利用其中一个空闲时给予其他用户带宽。

### 统计复用

将单个资源(如链路带宽)在多个用户之间进行统计分配。每个用户动态分享资源,根据其他用户使用情况提供带宽。

## 7. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn7 p7 1 6   Layering principle 64

### 分层设计原理

分层设计是将系统划分为多个分离的功能模块或层级结构。各层之间采用前后流通的交互模式,每个层级只与上下层交互。

### 分层设计好处

1. 简化系统设计,将复杂问题分解为独立模块。

2. 每层提供明确定义的服务接口。

3. 层与层之间可以重复使用已经开发完善的模块,提高效率。

4. 分层能明确划分职责范围,各层独立开发不影响其他层。

5. 允许各层独立优化和持续改进。

6. 支持点对点通信,无需关注下层工作原理。

### 分层设计例子

1. 机票网站搜索多个航空公司机票。

2. 邮递服务分拣分区递送邮件。

3. 编程语言通过编译系统调用硬件。

4. 网络协议栈各层协议独立运行。

### 分层可能出现问题

为提升性能,可能需要跨层优化,但会降低系统灵活性。例如网络地址转换NAT极大限制了互联网新增传输协议。应仅在必要时打破层次边界。

## 8. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn8 p8 1 7   Encapslation principle 64

### 封装原理

封装原理是通过组合分层和分组交换来实现的。它允许我们将数据划分为离散的数据单元或数据包,同时保留各层独立性。

各层协议都有头、负载和尾部。下层协议负载即上层协议的数据包。例如TCP段可以作为IP数据包的负载,IP数据包又可以作为以太网帧的负载。

通过封装,各层协议可以独立开发和优化,上层协议无需了解下层细节。例如HTTP不用关注TCP变化。

### 网络数据表示

网络数据常按从左到右或从右到左的顺序排列协议头部。软件文档常采用从左到右,硬件设计常采用从右到左。

抓包软件Wireshark可以查看实际数据包结构,明确显示各层协议位置。

### 例子

1. HTTP请求经TCP封装为TCP段,作为IP数据包负载,再作为以太网帧负载传输。

2. VPN通过SSL/TLS安全隧道封装IP数据包,实现内网访问。

封装提供了强大的灵活性,可以实现复杂的协议封装,如VPN隧道封装。

## 9. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn9 p9 1 8a   byte order 64

### 计算机内存

计算机内存以字节为单位,每个字节8位。内存地址从0开始,64位系统支持最大264字节的内存。实际中计算机内存一般为几GB大小。

### 多字节值表示

若要表示大于1字节的值如1024(16进制0x0400),需要使用2个字节。计算机如何在内存中排列这2个字节就是字节顺序问题。

有小端字节顺序和大端字节顺序两种:

- 小端字节顺序:低地址字节为最低有效字节。

- 大端字节顺序:低地址字节为最高有效字节。

从计算效率来看,小端字节顺序更合理;从阅读习惯来看,大端字节顺序更符合人类阅读习惯。

字节顺序问题对计算机内部处理很重要,但对软件程序来说通常是透明的。

## 10. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn10 p10 1 8b byte order 64

### 字节顺序测试题

给出若干个十进制数字,需要判断其对应的十六进制表示是否为小端字节顺序还是大端字节顺序,不允许使用计算器或其他工具。

## 11. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn11 p11 1 8c byte order 64

### 字节顺序练习

1. 53以小端字节顺序表示为0x35

2. 4116以大端字节顺序表示为0x1014

3. 5以大端字节顺序表示  

4. 83,886以小端字节顺序表示

5. 80以小端字节顺序表示为0x0500

6. 305,414,945以小端字节顺序表示,其最低有效位为1,因此是奇数,实际值应为0x2121。

通过解析数字含义和判断位数位置来判断其二进制表示的字节顺序。无需进行具体运算。

## 12. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn12 p12 1 8d byte order 64

### 字节顺序的重要性

不同处理器采用不同的字节顺序,为了通信,协议需统一采用一种字节顺序。因此网络协议规范都选择采用大端字节顺序。

### 转换字节顺序

操作系统提供函数如htons、ntohs来将主机字节顺序与网络字节顺序进行转换。应谨慎使用,避免反复转换或遗漏转换而导致问题。

### IP报文格式

IPV4报文Header至少20字节,包含字段如总长度(2字节)。报文采用大端字节顺序传输。Wireshark可以查看报文实际字节顺序与字段对应关系。

### 写网路程序注意事项

应明确处理网络数据时主机字节顺序与网络字节顺序的转换位置,严格按规定执行,否则容易因为重复或遗漏转换而出现难trace的bug。

## 13. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn13 p13 1 9a IPv4 addresses 64

### IPv4地址

IPv4地址长度32位,采用点分十进制表示法,如“171.64.64.64”。每台设备都有一个独一无二的IPv4地址。

### 子网掩码

子网掩码用来区分内外网,以连续1表示地址匹配的位长度,如“255.255.255.0”表示匹配前24位。

可以通过与地址进行位与运算判断两个地址是否在同一子网内:如果结果相等,则在同一子网。

### 查看本机网络配置

使用ifconfig命令可以查看本机网络接口配置,包括IPv4地址和子网掩码。例如一个WiFi接口可能得到:

IPv4地址:192.168.0.106
子网掩码:255.255.255.0(等价为24位掩码)

它表示局域网分配的是192.168.0.0/24网段内的地址。

## 14. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn14 p14 1 9b IPv4 addresses 64

### IPv4地址判断练习

给定源地址、目的地址和子网掩码,判断目的地址是否在与源地址相同的子网内:

1. 源地址:192.168.1.33 目的地址:192.168.1.66 子网掩码:255.255.255.0
   结果: 是

2. 源地址:172.16.33.12 目的地址:192.168.1.23 子网掩码:255.255.255.0  
   结果: 不是

3. 源地址:10.0.0.5 目的地址:10.0.1.7 子网掩码:255.255.255.0
   结果: 不是

根据子网掩码与地址进行与运算判断两个地址子网是否匹配。

## 15. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn15 p15 1 9c IPv4 addresses 64

### IPv4地址判断练习答案解析

1. 不在同一网段,第二八集不同
2. 在同一网段,与掩码位与运算结果相同  
3. 不在同一网段,第三八集不同
4. 不在同一网段,源地址171.64.15.32,目的地址171.64.15.0
5. 在同一网段,与掩码位与运算结果171.0.0.0相同

判断两个IPv4地址是否在同一子网内,需要:

1. 对地址进行位与运算与子网掩码
2. 比较结果是否相同
3. 根据不同八集判断所在网段

这样可以正确判断给出的不同案例是否在统一子网内。

## 16. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn16 p16 1 9d IPv4 addresses 64

### 原始分类与限制

原先IPv4地址分为A、B、C三类,分配范围不同且不灵活。

### CIDR(无分类域间路由)

采用CIDR,允许任意位宽的前缀,比如 slash 16表示16位前缀,划分出65536个地址段。

### 地址分配机构

IANA(互联网号码分配机构)将大块IPv4地址授予各RIR(区域互联注册机构),如ARIN和APNIC。RIR再细分分配给各地区网络机构。

### 地址管理现状

 IPv4地址以CIDR块管理,块大小由前缀长度决定。IANA已经将最后5个slash 8块分给各RIR,地址管理工作交给RIR层面进行。

虽然报道称“耗尽IPv4地址”,但实际上许多地址尚未使用。地址分配采用更细粒度的方式进行管理。

## 17. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn17 p17 1 10a Longest prefix match LP

### 路由转发表

路由器根据转发表决定将数据包送往哪条链路。转发表包含IP地址前缀和下一跳路由器。

### 最长前缀匹配LPM

当数据包到来时,路由器会查询转发表,选择与数据包目的地址最匹配(最长前缀)的表项,即最具体的表项前缀。

### 简单示例

转发表包含默认路由与171.33.0.0/16两个表项。如果数据包目的地址是171.33.XX.XX,则依次匹配两个表项,选择171.33.0.0/16项,并发送到下一跳路由器。

### 步骤

1. 检查数据包目的地址
2. 查询转发表匹配度最长的表项
3. 根据该表项选择下一跳路由器

通过LPM算法,路由器实现了智能的路由选择转发决定。

## 18. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn18 p18 1 10b Longest prefix match LP

### LPM算法数据包转发示例

给定一个路由器的转发表:

|  前缀  | 下一跳  |
|-|-|
| 0.0.0.0/0 | 链接1 |
| 171.33.0.0/16 | 链接5 |
| 171.64.0.0/16 | 链接2 |
| 171.64.15.0/24 | 链接3|

根据此表,对不同目的IP地址使用LPM算法后的转发效果:

- IP地址:171.33.1.1
   匹配表项:171.33.0.0/16
   下一跳:链接5

- IP地址:171.64.15.1
   匹配表项:171.64.15.0/24  
   下一跳:链接3

- IP地址:171.64.1.1
   匹配表项:171.64.0.0/16
   下一跳:链接2

通过比较匹配度选择最佳路由转发表项。

## 19. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn19 p19 1 10c Longest prefix match LP

### LPM算法数据包转发示例2

给定一个路由表:

|  前缀  | 下一跳  |
|-|-|
| 0.0.0.0/0 | 链接1 |
| 63.19.5.0/30 | 链接3 |
| 171.0.0.0/8 | 链接2 |
| 171.0.0.0/10 | 链接4 |

不同目的IP地址使用LPM算法的转发效果:

- IP:63.19.5.3 → 匹配63.19.5.0/30→ 链接3
- IP:171.15.15.0 → 匹配171.0.0.0/10→ 链接4  
- IP:63.19.5.32 → 匹配默认路由→ 链接1
- IP:44.199.230.1 → 匹配默认路由→ 链接1
- IP:171.128.16.0 → 匹配171.0.0.0/8→ 链接2

根据 prefix 长度选择匹配度最长的表项决定下一跳。此示例进一步解释了 LPM 算法在实际路由转发中的应用。

## 20. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn20 p20 1 11 Address Resolution Protocol ARP

### ARP原理

地址解析协议(Address Resolution Protocol,ARP)是网络层与链路层地址转换的机制。

网络层的IP地址表示主机,链路层的MAC地址表示网卡。两个地址系统没有直接对应关系。

当主机需要发送数据包时,它必须获取目标主机对应的MAC地址。ARP根据IP地址查询对应的MAC地址,实现网络层与链路层的映射。

ARP运行过程为广播查询-单播应答:

1. 发送ARP请求数据包(请求者的IP、MAC地址及目标IP地址),广播给同一网络段内所有主机

2. 拥有目标IP地址的主机回复单播ARP应答数据包(回复者的IP、MAC地址),发送给请求者

3. 请求者收到应答后,将映射缓存起来,用于后续数据包的封装转发

4. 缓存时间一般为20分钟,过期后将重新查询

ARP广播特点能实现快速地址查询,但会增加网络流量。

### 网关配置多IP

网关需要连接不同网络,需要配置多张网卡和IP地址。

每个网卡对应一个IP地址,同时进行网络地址转换转发。

例如:

- 左端网卡IP:192.168.0.1
- 右端网卡IP:171.43.22.8

实现不同网络之间的数据通信。

## 21. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn21 p21 1 12 The Internet and IP Recap

### 本单元内容概要

1. 应用如何使用互联网:多种应用(Skype、BitTorrent、web)都采用可靠的双向字节流通信方式

2. 互联网结构:四层模型、每个层负责的内容、IP作为互联网的基础通信协议

3. IP协议:IPv4的基本概念和工作机制

4. 基本网络原理:分组交换、分层架构、封装等

### 网络层和传输层

网络层主要实现主机间互联,使用IP地址标识主机。传输层采用端到端的可靠传输机制。

常见的传输层协议有TCP和UDP。TCP提供双向可靠连接,UDP提供单播 datagram服务。

### IP地址

IP地址标识主机在网络层,使用点分十进制表示法,如192.168.0.1。路由器根据IP地址寻找下一跳路由。

目前主要使用IPv4,未来将逐步过渡到IPv6。

### 网络基础知识

分组交换、分层架构和封装是网络的三大基本原理,为应用提供了统一的工作机制。这些原理构成了Internet的基石。

## 22. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn22 p22 1 13   SIP    Jon Peterson Internet治理简介

### 早期计算机网络和电话交换

1990年代早期,计算机网络上还未有商用的语音通信产品。1996-1997年,计算机性能和网络带宽提高,才出现第一次商用的语音通信服务。

### 软交换技术

软交换技术将传统电话交换机的控制逻辑从专用硬件移植到通用计算机上运行,控制别的硬件设备实现实质的交换功能。这极大改变了电话交换机市场,成为主流模式。

### SIP协议

为了使软交换设备能够通过Internet进行通信,提出了会话初始协议(SIP)。SIP能够在Internet上设置电话呼叫,使电脑实现与普通电话联网的通话能力。SIP的安全模型也是一个难点。

### 现今SIP应用

目前,Skype内部通信采用SIP协议; cable 网络提供的语音业务;3G/4G手机的语音服务;都广泛采用SIP协议。但网络运营商实施的SIP与电信网络更类似,依赖网络元素控制。理想状态下,SIP应由终端驱动,而非网络中间产品。

## 23. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn23 p23 2 0   Transport intro 64

### 传输层简介

传输层提供应用层数据通信服务。UDP提供简单无连接数据报服务,TCP提供可靠的双向字节流服务。

### TCP连接建立

TCP通过三次握手建立连接,并使用序列号标识报文。连接释放经过四次挥手。

### 数据传输可靠性

TCP需要知道数据是否损坏。利用校验和、循环冗余校验和消息认证码三种算法检测错误。

### 状态机

状态机是网络协议设计的基本工具。TCP使用状态机描述各种状态和状态转换实现可靠数据传输。

### UDP和ICMP

UDP提供不可靠但低开销的传输。ICMP传输像路由信息等控制信息。

## 24. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn24 p24 2 1   TCP service model 64

TCP提供三种服务:

1. 可靠的数据传输服务。TCP提供一种在两个应用程序之间传输字节流的可靠服务。即使在网络不稳定或存在问题时,也能确保数据以正确的顺序被传输和接收。

2. 顺序性服务。TCP保证数据以正确的顺序传输和接收。如果数据包 receiving out of order,TCP层会进行重新序列化。

3. 流量控制服务。TCP设有流量控制机制,避免发送端数据传输速度大于接收端处理能力,从而过载接收端。接收端会告知发送端自己当前缓冲区的空余容量,限制发送速度。

TCP通过四种机制实现可靠传输:

1.确认报文。当接收方收到数据后,会发送确认报文告知发送方该数据已收到。

2.校验和。TCP报文头和数据体计算校验和,用于检测传输过程中的错误。

3.序号。每个数据段带有序号,标记数据流中的位置,用于检测丢包。

4.流量控制。接收方告知发送方可以发送多少新数据,防止过载。

TCP还需保证:

1.数据以原顺序发送给应用层。

2.网络延时与拥塞均匀分配带宽。TCP运行拥塞控制算法达成这一目标。

## 25. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn25 p25 2 2   UDP service model 64

UDP传输层提供无连接的服务。

UDP报文无头部字段,仅包含4个字段:

1. 源端口:表示发送报文应用的端口号。

2. 目的端口:表示接收报文应用的端口号。

3. 长度:报文总长度(含头部和数据域)。

4. 校验和:可选,计算报文校验和用于错误检测。

UDP具有以下三个特征:

1. 无连接服务:无需建立连接,每个报文独立传输。

2. 无序服务:报文可能乱序到达,应用层需要自己重组顺序。

3. 非可靠传输:不确认也不重传丢包,但应用可以自行实现。

UDP适用于不需要可靠传输的应用,如DNS、DHCP等查询响应协议。通过报文端口号实现应用层流量分发。比TCP传输效率高,对实时流媒体也比较适用。

## 26. 英字【计算子网路导论】斯坦福大学 Introduction to Computer Networking CS 144 pn26 p26 2 3   ICMP service model 64

### ICMP协议

ICMP协议用于在网络层与传输层之间传送错误报告和诊断信息。它运行在网络层之上,从技术上说也是一种传输层协议。

ICMP报文包含以下几个主要部分:

- 原始IP报文的IP头
- 原始IP报文第一个8字节的数据
- 消息类型和代码

当路由器或主机需要报告错误时,它将上述报文内容封装到新的ICMP报文中,再由IP传送。

主要ICMP消息类型包括:

- 3/0:网络不可达 - 路由器无法找到目的网络
- 3/1:主机不可达 - 找到目的网络但无法找到主机
- 3/2:端口不可达 - 端口或协议识别错误
- 8/0:回显请求 - Ping命令产生
- 0/0:回显响应 - 对回显请求的响应
- 11/0:TTL超时 - TTL字段减为0导致报文丢弃

### Ping命令原理

Ping命令发送ICMP回显请求,对方主机响应回ICMP回显应答。通过测量往返时间,可以检测网络连通性。

### Traceroute命令原理

Traceroute通过发送不同TTL的UDP报文,并利用ICMP TTL超时报文,来探测报文经过的每一个路由器,并测量到每个路由器的往返时间。

它发送TTL为1的报文,第一个路由器返回TTL超时报文。然后发送TTL为2的报文,第二个路由器返回报文。依次增加TTL值,就可以追踪报文的整条路由路径。

## 27. 英字【计算子网路导论】斯坦福大学 Introduction to Computer Networking CS 144 pn27 p27 2 4   End to End Principle 64

### 端到端原则的重要性

端到端原则在互联网设计中占有重要位置。它主要包含以下两个原则:

1. 正确性原则:如果不遵循端到端原则,网络系统很可能存在 bug,数据会传输错误。

2. 强端到端原则:网络的职责仅仅是高效灵活地传输数据包,其他功能全都应该由网络边缘执行。

### 端到端完整性检查的重要性

文件在源计算机和目的计算机之间可能通过多个计算机传输。网络层提供错误检测功能,但无法保证传输的完整性。只有源和目的计算机进行端到端完整性检查,才能确保文件完整无误传输。

当年 MIT 开发者由于误以为网络层可以检测所有错误,导致大量源代码丢失。这 induced 子之后人 formulize 端到端原则。

### 网络层可以提供的性能优化

网络层可以提供一些功能来提升性能,如无线链路层重传以提高可靠性,满足 TCP 工作要求。这属于端到端原则允许的“性能优化”范畴。

但从长远来看,强端到端原则更值得遵循。因为一旦网络层加入过多优化,就会限制协议层的自由创新。

## 28. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn28 p28 2 5   Error detection 64

网络和主机都可能会引入错误。为了网络正常运行,必须能检测到这些错误。常用的三类错误检测算法是:

### 校验和

校验和是通过把数据包中的每个字组相加来计算的。TCP和IP使用一类互补校验和算法。计算步骤是:

1. 将校验和字段设置为0;
2. 将数据包中的每个16位字相加;
3. 当相加结果超过65535时,进位;  
4. 求和完毕后,对结果取反;
5. 求和结果作为校验和;
6. 再把校验和加入求和,如果结果为全1,则校验和正确。

优点是计算简单快速,但错误检测能力很弱,很容易因两处错误互相抵消而未被检测出来。

### 循环冗余校验码

CRC通过将源数据看作为一个多项式,与一个生成多项式做除法余数来计算。 CRC能更好地检测奇数个错误和长度小于CRC长度的错误burst。

使用CRC的链路层(以太网使用32位CRC)可以弥补IP层校验和的不足。

### 消息认证码

MAC算法将消息与密钥相结合,生成认证值。只有知道密钥才能生成或验证MAC,所以它可以防篡改。但对错误检测不如CRC,一个bit错误MAC很可能还能通过。

MAC主要用于TLS等传输层安全协议中。

以上三种算法各有优劣,需要结合不同场景选择使用。

## 29. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn29 p29 2 6a   Finite state machines 1

有限状态机(Finite State Machine,FSM)是描述网络协议和系统的一种常用方法。

FSM由有限个状态组成,每个状态代表系统的一个配置。状态之间通过边进行转移,边指定了转移事件和操作。

一个 FSM 包含:

- 有限个状态
- 状态之间的转移边
- 每条边上指定的转移事件
- 可选的转移操作

当系统处于某个状态时,如果接收到该状态没有定义的事件,FSM的行为是未定义的。

一个状态可以有多个出边,但同一个事件只能对应唯一的状态转移。

FSM可以用来描述复杂的通信协议过程,比如TCP三次握手。但完整定义每种事件下的转移往往会使FSM过于复杂,所以文档中常只定义主流程,其他情况以文字叙述。

未完全定义部分也可以留给后续细化。FSM的目的是描述必要的交互行为 TO ensure可互操作。

## 30. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn30 p30 2 6b   Finite state machines 2

### 问题一

如果FSM起始于关闭状态,然后调用listen(),再接收到一个SYN报文,最后调用close(),那么socket的状态将是什么?

答案: 关闭状态。从关闭状态通过listen()变为监听状态,在无其他事件下直接调用close(),会返回到关闭状态。

### 问题二

如果FSM起始于关闭状态,然后调用connect(),再在无其他事件下直接调用close(),那么socket的状态将是什么?

答案: 关闭状态。从关闭状态通过connect()发出SYN,但在无其他事件下直接调用close(),状态不会发生变化,还是关闭状态。

这两个问题测试了在不同状态下直接调用close()的效果。根据FSM图可以得出上述两个问题的答案。

## 31. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn31 p31 2 6c   Finite state machines 3

问题一的答案是关闭状态。

原因分析:

1. FSM开始处于关闭状态
2. 调用listen()函数,状态转移到监听状态
3. 接收到SYN报文,状态转移到SYN收到状态
4. 在SYN收到状态下,调用close()函数
5. 根据FSM图中,关闭事件下从SYN收到状态转移到FIN等待状态1
6. 所以最后状态是FIN等待状态1,即关闭状态。

所以问题一给出的答案关闭状态是正确的。通过 step by step 按FSM图分析每一个状态转移的原因,可以验证问题一的解答。

## 32. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn32 p32 2 6d   Finite state machines 4

TCP连接的建立和断开采用对称方法:

- 连接建立使用SYN报文
- 连接断开使用FIN报文

如果一方调用close(),它发送FIN报文变为主动关闭方,进入FIN_WAIT_1状态。

另一方接收到FIN后进入CLOSED_WAIT状态。它可以继续发送数据,也可以主动调用close()发送FIN报文。

主动关闭方进入FIN_WAIT_2状态后,可能有以下结果:

1. 被动关闭方ACK但不FIN,进入TIME_WAIT状态。被动关闭方处于CLOSED_WAIT状态继续发送数据。

2. 被动关闭方也FIN ACK,共同进入TIME_WAIT状态。

3. 两方同时FIN,互发FIN报文,共同进入CLOSING状态。

TIME_WAIT状态之后进入CLOSED状态,完成连接断开。

TCP终结连接的12个状态详细描述了不同情况下的变迁流程,给出了标准规范。这比原来的描述更为精确。

## 33. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn33 p33 2 7   Stop and wait 64

流量控制的目的是防止发送方发送数据的速度超过接收方处理数据的速度,造成部分数据丢失。

停止等待流量控制协议允许在任意时刻只有一个数据包在网络中传输。

发送方发送一个数据包后,进入等待ACK状态。接收到ACK后再发送下一个数据包。如果ACK超时,重新发送该数据包。

接收方处于等待状态,接收到新数据后发送ACK。

这个算法可以正常工作,但如果ACK被延迟超过重传定时时间,可能导致数据重复发送。

为了识别ACK来源,可以在数据和ACK包上加入单位位计数器。ACK为0表示上一个数据包,ACK为1表示当前数据包。

但是此方法有以下限制:

1. 网络不能重复数据包

2. 数据包延迟时间不能超过多个重传定时时间

可以通过增加序列号空间来解决这些问题,但对单纯协议来说,单位位计数器也能很好工作。

## 34. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn34 p34 2 8   Sliding window 64

### 停待协议的问题

停待协议允许一次只有一个数据包在传送过程中。如果源地和目的地之间链路带宽十兆比特每秒,但往返时间为50毫秒,根据停待协议,每50毫秒只能传输一个数据包。假设每个数据包为1.5KB,那么每秒最大传输速率只有240kb,远小于10Mbps的链路带宽。

### 滑动窗口概述

滑动窗口协议允许同时有多个数据包在传送过程中,Generalization了停待协议。它定义一个窗口大小n,如果n为1,等同于停待协议;如果n大于1,允许同时有n个数据包在传送。

### 滑动窗口协议工作原理

源发送者和目的接收者都维护着发送/接收窗口、最后确认序号和最后发送/接收序号。发送者要保持最后发送序号减去最后确认序号不能大于发送窗口大小;接收者同样要保持最后可接收序号减去最后实际接收序号不能大于接收窗口大小。

发送者会给每包数据分配个序号。接收到数据后,接收者会发回累计确认包,表示确认收到对应序号及其之前所有数据包。确认包收到后,发送者可以发送序号大于最后确认序号但小于窗口值的新数据包。

如果设置好滑动窗口大小,就可以保证链路利用率达到最大,即能保持链路持续传输数据而不是间断传输一个包。

### TCP滑动窗口机制

TCP滑动窗口也是基于序号和累计确认的。不同的是,TCP确认值表示确认到的下一个要接收的数据字节,而不是实际已经接收到的最后字节。

## 35. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn35 p35 2 9   Reliable comm      Retran

### 可靠通信的重传策略

视频主要介绍了滑动窗口可靠通信协议在包丢失情况下的两种重传策略:go back N 和选择性重复。

go back N策略假设如果一个包丢失,整个窗口内的包都可能丢失。它会重新传输整个未确认窗口内的包。这种策略具有保守性,但效率较低。

选择性重复假设只有一个包丢失,它只会重新传输未被确认的那个包。这种策略更加高效,但可能在复杂包丢失情况下恢复速度较慢。

### 重传定时器

协议为每个包设置重传定时器。如果在定时时间内没有收到对某包的确认,就认为这个包丢失,需要重新传输。

### go back N工作原理

以窗口大小为4的例子进行解释。当第二个包丢失时,go back N策略会重新传输窗口内的1-4号所有包。

### 选择性重复工作原理

同样以窗口大小为4的例子,当第二个包丢失时,它只会重新传输第二个包,并不影响其他已确认包的传输。

### 协议行为的影响因素

接收窗口大小和传输窗口大小都会影响协议的实际行为,可能导致go back N或选择性重复效果。

可以在实现可靠传输协议时,策略选择go back N或选择性重复,取决于对重新传输包数量和恢复速度的平衡要求。

## 36. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn36 p36 2 10   Reliable comm     TCP he

### TCP报头格式

标准TCP报头长度为20字节,由源端口、目的端口、序列号、确认号、窗口大小、校验和、标志位等字段组成。

### 序列号和确认号

序列号表示分组内第一个数据字节的序号,确认号表示接收端完成接收数据的下一个字节序号。

### 校验和

校验和计算得出 TCP 报头和部分IP报头组成的伪首部以及分组数据,检测报文是否损坏。

### 窗口字段

表示接收端可以接收但还未确认的数据字节数上限,用于流量控制。

### 标志位

SYN标志位用于 TCP 连接建立同步序列号;FIN 标志位用于关闭连接;ACK 标志位表示确认号有效等。

### 选择确认位

仅当紧急数据标志位设置时,才有意义,表示紧急数据在分组内的偏移位置。

### 偏移字段

用于指出TCP报头后实际数据的起始位置,若存在选项字段,需要根据偏移量计算数据位置。

### TCP连接建立流程

客户端和服务器使用SYN标志位和序列号交换完成同步握手,建立可靠的TCP连接通道传输数据。

## 37. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn37 p37 2 11   Reliable comm     Connec

### TCP三次握手建立连接

TCP连接的建立采用三次握手。

1. 主动打开端发送SYN报文段,用于同步发送方数据流的起始序列号Sa。

2. 被动打开端响应SYN-ACK报文段。同时同步接收方数据流的起始序列号Sp,并确认Sa。

3. 主动打开端回应ACK报文段。确认Sp。此时两端序列号相互同步,完成三次握手建立连接。

### 同时打开连接

如果双方都主动打开连接,可以用四次握手建立连接:

1. 双方同时各自发送SYN报文段。

2. 双方各自回应SYN-ACK报文段。

3. 双方各自回应ACK报文段。完成同步。

### 数据传输

  已建立连接后,TCP通过序列号和确认号字段来进行可靠传输。

  发送方使用序列号标识每个报文段第一个字节的位置,接收方使用确认号告知下一个预期接收的字节位置。

  每次收到报文段后,接收方通过ACK报文段确认收到字节流。发送方根据ACK继续发送下一个报文段。

  这样,就实现了可靠字节流传输。

### 关闭连接

  使用FIN报文标记发送方没有更多数据需要发送。

  接收到FIN后,接收方通过ACK报文 acknowledging FIN。

  当双方都发送并确认对方的FIN后,才 truly关闭连接释放资源。

## 38. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn38 p38 2 12   Transport recap 64

### 传输层协议

传输层主要提供三种协议:

1. TCP:可靠传输字节流的传输控制协议。实现可靠交付。

2. UDP:不可靠地传输数据报的用户数据报协议。没有交付确认机制。

3. ICMP:网络控制报文协议。用于传达网络错误或其他消息。

### TCP工作原理

TCP通过序列号和确认号可靠传输字节流。发送方使用序列号标识每个报文段,接收方使用确认号确认收到字节流。

TCP通过三次握手建立连接,使用FIN报文关闭连接。同时保持连接状态机以跟踪连接状态。

TCP支持选择性重传,根据接收方ACK选择性重传丢失或错误报文段。也支持滑动窗口机制控制传输速度。

### UDP工作原理

UDP为应用程序提供简单的无连接传输服务。它将应用数据封装成UDP数据报传输。

UDP自己不实现可靠传输,丢包处理完全依赖于应用层。一小部分应用如DNS和DHCP使用UDP。

### ICMP工作原理

ICMP主要用于路由器或主机检测网络错误并向源发送反馈,如目的不可达等错误报文。

它有助于诊断两端主机之间的网络连接问题,监测网络连接质量。

### 尾端到尾端原则

这是互联网设计的核心原则。即功能应该只在网络尾端实现,而不是在内部网络中。

它有助于简化网络,同时将复杂功能推到对计算能力要求高的主机上实现。

## 39. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn39 p39 2 13   TCP IP    Kevin Fall 64

### 肯文·富赖尔的网络研究背景

肯文·富赖尔在加州大学伯克利分校和旧金山分校学习,研究网络实现和操作系统。后在劳伦斯伯克利国家实验室参与网络模拟器的开发工作。

### 《TCP/IP协议插图》作者

《TCP/IP协议插图》是网络领域的经典教材。由于原著需要更新,富赖尔提交了重新编写提案被接受,花7年完成此书更新版。

### TCP/IP工作原理

TCP提供可靠的两端字节流传输 service。UDP为应用提供简单的数据报传输。ICMP用于网络检测和报告错误。

### 数据报和分组的区别

分组早期用于虚拟电路传输,目的地 recorded 在路由表。数据报直接在报文中记录目的地,以在任意路由器间传输。

### 3D打印和网络医疗应用发展

3D打印使任何物质都可能打印输出,甚至生物体。这将带来法律隐私和安全性问题。网络医疗也将通过3D打印对病人提供定制服务。

### 总结

网络技术不断发展,同时也带来新的研究方向和挑战。系统结构设计需要兼顾技术进步和政策法规间的矛盾和拖延。

## 40. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn40 p40 3 0   Packet Switching 64

### 包交换原理

每个数据包是独立的、自包含的,携带目标地址信息。网际协议套采用包交换,高效利用链路资源。

### 数据包延迟组成

数据包延迟由分组长度延迟、传播延迟、排队延迟三部分组成。分别来源于对数据分片、在链路上的传播、路由器队列中排队。

### 数据包传输不确定性

由于排队延迟,同一源目标主机间的数据包传输延迟可能不同。实时应用需要设计播放缓冲来吸收网络延迟变化。

### 路由器工作原理

路由器根据地址查表转发数据包。内部设有队列缓冲数据包,排队延迟导致传输延时不确定。此单元还将介绍交换机与路由器的区别。

### 本单元学习效果

理解包交换网络工作机制,包括数据包延迟组成、路由器转发原理等。能分析网络传输问题,如源地到伦敦的传输时延。

## 41. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn41 p41 3 1   The History of Networks

### 长距离通讯的发展史

距今约2000年前,人类开始使用信号火堆传达确定信息。1000BC时,埃及和中国已开始使用通讯骡马传递信息。中世纪时,马可波罗描述了忽必烈汗使用的马驿传统。19世纪,美国西部的驿传系统也采用马驿传递邮件。

1600年后,人们开始使用信号旗和日光信号机编码字母数字信息。1793年,法国工程师克洛德·夏普发明了无线电报系统。这种系统在塔与塔之间传达简单的手势信号,可以在30分钟内传递信息跨越全法国。

### 电话的发明

19世纪后期,各种尝试提高电报网络容量。1876年,亚历山大·格拉汉姆·贝尔在美国发明并完成首次电话通话。1876-1915年间,电话用户和通讯线路数量迅速增长。

### 计算机网络的兴起

1960年代,计算机专家开始研究连接远端计算机的可能性。1965年成功建立首个广域计算机网络,连接马萨诸塞和加利福尼亚两台计算机。1960-1970年间,美国国防部长期支持网络研究。

1969年,四所大学之间建成第一代ARPANET,标志着互联网的诞生。1970年代,各种数据包交换网络应运而生,TCP/IP协议形成。1983年,TCP/IP在全网应用。1980年代末,互联网规模扩展到10万台主机。

1990年,提姆·伯纳斯-李在瑞士CERN实验室发明万维网。1993年,第一款图形式浏览器应运,互联网快速普及。

## 42. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn42 p42 3 2   Packet Switching   Principles

### 分组交换原理

分组交换是一种网络交换技术。它允许数据以分组的形式发送,每个分组都包含源和目标地址。

分组在网络中的传输是分组式的,即每个分组独立地在网络内进行转发。分组交换网络由主机、链路和分组交换机组成。

当主机发送数据时,会将数据分割为一个个分组,每个分组都附上目的地址。分组通过分组交换机逐跳转发,每跳分组交换机通过转发表查找下一个跳的地址,将分组发送到下一个分组交换机,直到目的主机。

分组交换机内部需要进行转发表查询和分组缓冲。转发表记录每个地址对应的下一跳,以确定分组的下一个转发节点。分组缓冲是为了解决输入输出速度不匹配问题而设计的。

分组交换不需要预设专用通路,主机可以随时发送分组,更便于随时变化的网络拓扑和通信量。但每个分组逐个路由转发也带来一定开销。典型的应用是因特网。

## 43. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn43 p43 3 3   Packet Switching   Principles

### 传播延迟与数据包化延迟

传播延迟是单个比特从一个节点传输到另一个节点需要的时间。它可以用链路长度L除以传播速度C表示,公式为T sub l=L/C。

数据包化延迟是从将数据包的第一个比特插入链路开始,至将数据包的最后一个比特插入链路结束所需要的时间。它取决于数据包长度P和链路传输率R,公式为T sub p=P/R。

例如,一个64字节(512比特)的数据包在1Mbps链路上传输需要5.12μs;一个1Kb的数据包在1Kbps链路上传输需要1.024s。

### 端到端延迟

端到端延迟是从源节点发送第一个比特,至目的节点接收最后一个比特的时间。

它可以表示为各个链路上的传播延迟和数据包化延迟之和:

T=∑(T sub l+T sub p)

也就是统计从源至终的每个链路上传播和数据包化的延迟之和。

### 队列延迟

但是,实际情况下由于多个数据包竞争同一个链路通道,部分数据包需要在交换机的队列buffer中排队,这就会增加额外的队列延迟。队列越大,丢包概率越低。

所以实际的端到端延迟是不确定的,受到网络拥塞状况的影响。

## 44. 英字【计算人网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn44 p44 3 4   Packet Switching   Principles

### 1. 包交换的原理

网络中的数据包通过多个路由器进行转发,在每个路由器中可能会有排队延迟。这样就造成了端到端传输延迟是可变的。

### 2. 延迟的影响

对大多数应用来说,例如下载网页或发送邮件,具体每个数据包的延迟不重要,只要整体完成快即可。但对实时应用如视频会议来说,延迟的可变性就很重要了。

### 3. 缓冲策略

实时应用采用 playback buffer 来缓冲数据包,以 absorbs 延迟带来的影响。但缓冲区设计牵动一个 balanced:缓冲太少面临短期波动,太多则等待时间长。

### 4. YouTube 客户端示例

YouTube 客户端底部红线表示已经播放部分,蓝点表示当前播放进度,灰条表示缓冲区。这就是 playback buffer 的示意。

### 5. 数据包时间轴示意图

用时间轴可以清晰展示数据包从服务器发送到客户端接收的过程中可能出现的variable queuing delay。同时也可以看出Buffer里缓冲数量的变化。

### 6. 保证实时性的策略

实时应用需确保播放点随时有数据包供播放。因此需要提前采取策略如预播放一定数量数据包来构建播放缓冲区,以吸收网络波动影响。

## 45. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn45 p45 3 5   Packet Switching   Principles

### 简单确定性队列模型

本视频继续讨论分组交换,将介绍几种不同的队列模型。

首先是最简单的确定性队列模型。这种模型可以帮助我们理解许多简单队列系统的动态过程,常被用于初步了解网络情况。

模型中假设一个四端口路由器中存在一个队列,用于在拥塞时期暂存分组。队列容量 q(t) 表示时间 t 时队列中的分组数量。此外,还可以看作是一个“水桶”,a(t)表示累计入队分组数,d(t)表示累计出队分组数,r表示固定的出队速率。

然后绘制a(t)和d(t)随时间变化的示意图。可以看出q(t)= a(t)-d(t),即队列占用;一个分组通过队列的时延d(t)等于其出队时间减入队时间。

### 一个简单队列模型例子

按以下参数给出一个例子:

- 每秒有一个100比特的分组以1000比特/秒的速率入队  
- 最大出队速率为500比特/秒

从a(t)和d(t)图中可以看出,每个1秒循环中:

- 首0.1秒队列以500比特/秒的速度填充  
- 后0.1秒以500比特/秒速度排空
-平均占用为0.5×0.1×500=25比特
- 剩余0.8秒队列空闲
- 总平均占用为0.2×25+0.8×0=5比特

### 小分组可以减少端到端时延的原因

如果将整个消息分成较小的分组,可以减少端到端时延。

原因是:端到端时延由不同路由器队列中各个分组的时延之和组成。如果分组越小,每个路由器中待传输分组数量越小,平均排队时延越短,从而减小整个消息的端到端时延。

## 46. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn46 p46 3 6   Packet Switching   Princi

### 队列参数

本视频将介绍队列中的一些有用参数,这些参数在理解队列如何发展和包缓冲区如何影响包通过网络的队列延迟时会很有帮助。

### 随机抵达与 burstiness 增加了延迟

使用循环定时的抵达率,队列占用率只可能为0或1,平均值介于0-1之间。

使用随机抵达但平均抵达率相同的情况下,队列占用率可以从0增加到5,平均值和方差都会增加。这说明 burstiness 会增加延迟。

### 确定性降低了延迟

相对于随机抵达,周期性抵达会减少延迟。

### Little的定律

在没有丢包的队列系统中,队列平均数量L = 平均抵达率λ × 平均通过队列的客户平均延迟D。

### 泊松过程

研究随机抵达队列时,很常用泊松过程来模拟随机事件。

以上内容侧重理解基本概念而不是详细数学原理。

## 47. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn47 p47 3 7   Packet Switching   Practi

### 电路交换与分组交换

本视频将进一步讲解分组交换的工作原理。分组交换包括以以太网交换机、互联网路由器等产品。

### 分组交换的构成

分组交换主要由三个阶段组成:

1. 地址查找:当包到达时,首先需要查找包的目标地址,以确定包的下一个传输节点。这通过查阅转发表实现。

2. 头部修改:有时需要修改包头,例如互联网路由器需要减少TTL值并更新checksum。

3. 发送:将包发送到正确的输出端口。由于输出端口可能存在拥塞,需要在缓冲区中对包进行排队传输。

### 以太网交换机

以太网交换机的四个基本操作:

1. 检查每一个到达帧的以太网头,根据目标地址在转发表中查找输出端口。

2. 如果找不到目标地址,进行广播以帮助寻找目标。

3. 通过学习源地址动态建立转发表。

4. 如果找到目标地址,将帧转发到对应的输出端口。

### 互联网路由器

互联网路由器的七个基本操作:

1. 检查以太网帧目的地地址
2. 检查IP报文版本号
3. 减少TTL值并更新校验和  
4. 根据IP目的地址进行最长匹配查找输出端口
5. 封装IP报文为新的以太网帧
6. 发送报文
7. 动态学习路由

### 地址查找方式

1. 以太网交换机使用哈希表进行精确匹配48位的MAC地址

2. 路由器使用最长前缀匹配算法对IP地址进行前缀匹配,匹配不同长度的IPv4地址前缀表示不同子网段。

## 48. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn48 p48 3 8   Packet Switching   Practi

本节内容主要总结了数据包交换中基本的操作及其实现机制。

### 数据包交换基本操作

数据包交换设备进行两个基本操作:

1. 通过查找转发表,根据目标地址将数据包路由到正确的输出端口。

2. 将数据包交换或转移到正确的输出端口,以便通过正确的输出链路发送。

### 输出队列交换和输入队列交换

最基本的交换方式是输出队列交换。它将队列设置在输出端口,当输出端口挂起时, datos包会被缓冲在对应输出队列中,按先入先出顺序发送。

但是,输出队列交换存在性能 bottle neck问题。在最差情况下,每个输出队列的读写速率需要达到n+1倍于链路速率,对内存要求很高。

为解决此问题,人们提出输入队列交换方式。它将队列设置在输入端口,仅需读写速率2倍于链路速率就可以满足需求,比输出队列交换性能提升近n倍。

但是输入队列交换也存在头阻塞问题。若输入队列头数据包输出端口被堵塞,后续数据包也需要等待。

### 虚拟输出队列

为解决头阻塞问题,采用虚拟输出队列方式。它在每个输入端口为每个输出端口设置一个独立的FIFO队列。

这样,数据包根据输出端口预分类到对应队列,队列内数据包目标一致,后续数据包不会因为队列头数据包输出堵塞而被阻塞。

完整实现了输入队列交换的低内存需求,同时解决了头阻塞问题,是目前交换机广泛采用的优秀机制。

## 49. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn49 p49 3 9   Packet Switching   Principles

首先介绍简单的 fifo 队列在分配带宽时存在的问题。如果多个流通过同一个 fifo 队列,发送速率最高的流将以最高利用率使用输出链路。这鼓励不良行为,流量应该尽量多地进入队列中挤占其他流量。

其次介绍严格优先级队列,将高优先级和低优先级流分类到不同的队列中。高优先级流享有独占性,不受低优先级流影响。但如果高优先级流量过多,也会阻塞低优先级流量。

接着介绍带权重优先级队列,不同队列根据设置的权重分配带宽。 qi 队列的服务率 Ri = Wi / ∑Wi * R,其中Wi是qi队列的权重,R是输出链路速率。如果所有报文长度相同,这种模式很容易实现。

但实际报文长度差异巨大,直接按报文服务不同队列会破坏权重设计。为解决这个问题,需要引入“魔术队列”的概念。在每轮服务中,每个普通队列qi发送Wi位流,魔术队列负责流量整合成报文输出。这样就可以保证不同队列根据设定的权重分配带宽,同时兼容不同长度的报文。

最后提醒,最大等待时间小于或等于队列大小B除以输出速率R。

## 50. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn50 p50 3 10   Packet Switching   Principles

本节视频将继续阐述交换包原理。

视频主要内容有:

1. 如何保证从一个网络终端到另一个网络终端的延迟。之前视频说过,队列延迟是可变的,所以通常无法控制网络中的延迟。现在将介绍利用特殊技术来保证延迟。

2. 结束对结束延迟公式的回顾。延迟由三部分组成:包大小/速率(固定)、传播延迟(固定)、队列延迟(不确定)。

3. 如果可以控制每个路由器中的队列速率和缓冲区大小,那么就可以控制结束到结束的延迟。

4. 但是,如果到达速率过快导致缓冲区溢出,则无法提供延迟保证。需要解决这个问题。

5. 提出利用加权公平队列的思想,通过设置每条队列的服务速率来控制每个队列的延迟上限。

6. 建立分级队列模型。通过识别报文所属流,将报文插入对应的队列中,每个队列以不同的速率提供服务。

7. 但是,如果到达速率过快可能导致队列溢出。采用σρ调度理论对到达流进行约束,保证在任意时间内到达流量不超过某一速率,就可以避免队列溢出。

8. σρ调度如果满足,则队列长度和单包延迟可以得到确定的上限。

## 51. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn51 p51 3 10a   Delay Guarantees Example

本节视频给出了端到端延迟保证的一个实际例子:

- 两个端主机通过三个路由器和四条每100Mbps的250公里链路相连。

- 两个端主机之间发送1500字节的包,速率15Mbps。但不希望端到端延迟超过10ms。

- 如果每个路由器以15Mbps的速率服务此流,每个路由器的队列延迟是多少?

计算步骤:

1. 队列总延迟为10ms减去固定延迟总和。

2. 固定延迟包括:

   - 包大小/链路速率,四条链路总计0.48ms

   - 传播延迟,四条250km链路总计5ms

3. 固定延迟总和为5.48ms

4. 队列延迟为10ms-5.48ms=4.52ms

5. 等分给三个路由器,每个路由器队列延迟为4.52ms/3=1.507ms

6. 每个路由器以15Mbps服务,需要缓冲22605bit,约等于24000bit。

这个例子说明了如何根据端到端延迟要求,利用固定延迟公式计算每个路由器的最大队列延迟和缓冲长度。

## 52. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn52 p52 3 11   Packet Switching recap 6

本节视频回顾了之前关于分组交换的主要内容:

- 分组交换简单有效地利用了网络资源,每当有数据需要传输时就使用链路,而不需要预留资源。

- 分组携带 sender 和 receiver 地址,实现自我转发到目的地。

- 分组交换可以快速恢复网络故障,由于没有每个流的状态,只需简单前向即可快速路由。

- 分组交换的数学模型比较复杂,包括分组时间、传播时间和队列等待时间三个 delay 成分。

- 理解这三个 delay 成分及其影响因素对网络品质了解很重要。

- 定性队列模型可以直观展示队列变化规律,理解为什么需要缓冲区以及其大小设计。

- 应用程序需要播放缓冲区平衡动态 delay,防止停播问题。

- 网络可以通过优先级定时实现流量最小服务率和端到端最大 delay 保证。

- 分组交换的基本操作原理是在交换机和路由器查地址表转发分组,在输出端缓冲服务。

Video还强调了这一单元的核心概念,对网络性能了解和设计应用都很重要。

## 53. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn53 p53 3 12   DC Switches    Tom Edsal

### 以太网交换机和路由器的发展历史

第一个成功的以太网交换机是1995年由思科设计的Catalyst 5000产品线。初期是单片交换技术,每个端口有一个专用集成电路,每个线卡上有12个这样的集成电路。

思科当时主流的路由器还是基于软件的MIPS微处理器实现。EDSAL小组开始研究如何将路由功能硬件化。初期产品采用流缓存技术,第一个报文交给软件路由器处理,从中获得流信息后存储在硬件缓存中,其余报文直接在硬件完成重写头层转发。

### 交换机和路由器的复杂功能

除了基础转发外,现今产品支持许多安全检查、流量过滤与速率限制等功能。另外重点项目还有:

- 多播:实现困难,需要考虑100多个特征细节。
- 流量监控:支持多个端口镜像以实时监测流量。
- 服务质量:实现优先级调度以满足不同应用的带宽与时延要求。
- 复杂拓扑:大型设备支持模块化外接线卡与分布式架构。

### 产品规模扩展技术

随着Moore定律的推进,单片交换容量不断增长,但未能跟上网络带宽增长速度。主要的扩展技术包括:

- 使用中心化交换结构,采用高速交换总线替代早期单片式架构。
- 支持外接模块化线卡,每个线卡集成若干端口。
- 支持分布式架构,通过分布多个交换机架与线卡架实现更大规模交换。

以上内容概括了视频里对斯坦福网络基础课程中 routing 和 switching 的补充,以及产品发展史的回顾与技术关键点概述。

## 54. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn54 p54 4 0   Congestion Control 64

### 拥塞控制的目标

拥塞控制旨在防止发送端将过多报文注入网络,避免网络缓冲区、路由器以及链路被过载,从而产生丢包。

同时,拥塞控制机制应确保流量分配公平。所有受控流应得到等量的带宽限制。

### 拥塞控制的实施位置

根据“端到端”原则,智能应位于网络边缘,网络内部仅进行简单转发。这一原则指出,拥塞控制应由TCP发送端和接收端协作完成。

### TCP拥塞控制算法——AIMD

TCP使用了增加加成减少乘法(Additive Increase Multiplicative Decrease,AIMD)算法进行拥塞控制。

AIMD算法在实际网络中表现出良好的稳定性,能很好地控制拥塞并保证公平性。它被认为是网络技术中最重要的创新之一。

### 课程内容

该课程将详细介绍拥塞控制的概念、目标和TCP拥塞控制机制AIMD。同时揭示AIMD在不同场景下的工作机制,以及TCP拥塞控制未来可能的发展方向。

## 55. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn55 p55 4 1   Congestion Control   Basic

### 拥塞的几个时间尺度

拥塞可以发生在不同的时间尺度:

1. 小时尺度,当多个数据包同时进入路由器的同一个输出端口时,可能会发生碰撞。

2. 流尺度,以 TCP 流为例,一个长时间的通信过程中,其流量率可能会发生变化,导致暂时性的拥塞。

3. 人的时间尺度,在高峰时间段(如早上),大量用户同时访问同一个链路可能会导致拥塞。

### 拥塞的例子

拥塞是指数据包的到达速率超过输出链路的容量速率,从而导致队列长度的增长。

例如,两个源节点 A 和 B 分别试图以 12Mbps 的速率向目标节点 X 传输数据,但连接路由器和目标节点 X 的链路只有 12Mbps 的带宽。则两个流量叠加后,到达速率将超过输出链路的速率,队列将不断增长,最终导致数据包的丢失。

### 公平性

在拥塞网络中,我们期望每个流量源根据自己请求的带宽来分配链路资源。

例如,如果有4个流量源请求12、12、12、1Mbps的带宽,考虑到输出链路只有12Mbps,我们可以给每个流量源分配等量的3Mbps带宽。而请求1Mbps的流量源应该分配它请求的全部1Mbps带宽。

### 拥塞的好处

拥塞是包交换网络不可避免的结果。实际上,一定程度的拥塞可以提高网络利用率。只要能及时控制拥塞,避免延迟和丢包率变高影响用户体验。

## 56. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn56 p56 4 2   Congestion Control   Basi

### 视频内容简介

本视频介绍了拥堵控制的基本方法。首先分析了拥堵控制是否应该在网络层进行,还是应该在端系统进行。然后详细介绍了TCP如何通过观察网络状态实现拥堵控制的方法。

### 拥堵控制位置选择

拥堵控制可以采用网络基础设施支持或端到端支持两种方式:

1. 网络支持方式:路由器向源发送拥堵信息信号,如丢包率、队列长度等,源根据信号调整发送速率。这种方式响应快,分布式且可以实现最大公平性。

2. 端到端支持方式:源系统仅通过观察ACK和丢包情况等因素,自行判断网络拥堵状态,调整发送速率。这种方式更容易扩展,不依赖网络支持。

### TCP拥堵控制原理

TCP通过观察丢包和重复ACK实现拥堵控制:

1. TCP利用滑动窗口记录已经发送、未确认的数据段。

2. 通过滑动窗口大小控制能处于网络中的最大未确认数据段数,避免拥堵。

3. 通过重复ACK和超时判断包是否丢失,进而判断网络是否拥堵。

4. 在拥堵发生时缩小滑动窗口大小,减少未确认数据,缓解拥堵; Otherwise增加滑动窗口大小,增加吞吐量。

5. 该机制是端到端的,不依赖IP网络层支持,直接利用TCP拥有的滑动窗口和ACK机制实现。

### TCP拥堵控制算法

TCP采用加增乘减(ADD/INC/MUL/DEC)算法调整滑动窗口大小来控制拥堵:

- 拥堵未发生时,窗口一直进行线性增加试探加大发送速度。

- 拥堵发生时窗口进行乘法减小,一次性收缩较大幅度减少未确认数据。

人: 检查一下,没有问题就OK。

## 57. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn57 p57 4 3   Congestion Control   Dynamics

### 自增多重减少算法

负载控制算法 AIMD(Additive Increase Multiplicative Decrease)可以用来调节TCP滑动窗口大小和网络中流量包数量。

- 每次收到确认报文,窗口大小加1;
- 每当发生丢包,窗口大小乘以0.5减少。

AIMD可以让TCP源主机自行控制网络拥挤,不需要网路支持。

### 单个流AIMD示意图

示意图中显示:

- 报文从源点发到目的地(蓝色);每个报文对应一个确认报文返回(红色)。
- 源点的拥堵窗口大小随时间变化,窗口大小控制可以发送的未确认报文数量。
- 路由器缓冲区承载发送速度快于传出链路速度时产生的报文。

通过调整窗口大小,AIMD可以控制缓冲区中的报文数量。初值最小时缓冲区空,窗口加1时报文进入缓冲区。等收到全窗口确认报文后窗口再加1。

当缓冲区满时,再增加窗口大小会使报文丢失,此时窗口大小减半。缓冲区随之清空,循环往复。

### AIMD动态分析

通过ns网络模拟器模拟单个TCP流通过单瓶颈链路,结果表明:

- 拥堵窗口和RTT同步变化。
- 缓冲区占用也同步随窗口变化。
- 由于窗口和RTT同步,TCP流速率保持恒定。
- AIMD其实调整了可放在网络中的报文数量,而不是实际调整流量速率。

因此,对于单个流,AIMD主要通过探测网络“容量袋”大小,保持链路利用率100%,而不是调节实际速率。

## 58. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn58 p58 4 3a   Single AIMD flow worked

### 案例一

爱丽斯从旧金山服务器每秒流视频10Mbps,报文大小250字节。

到服务器的最短Ping时间为5ms。AIMD窗口稳定后,窗口将在最小值和最大值之间震荡变化。

### 问题一

AIMD窗口最小值是多少字节?

10Mbps链路每5ms传输50000比特,最小值窗口为62500字节。

### 问题二

AIMD窗口最大值是多少字节?

当缓冲区和链路全部满时,Ping时间为10ms,最大值为100000比特,即12500字节。

### 问题三

路由器包缓冲区大小是多少字节?

50000比特,对应最小Ping时间。

### 问题四

丢包后,窗口何时重新达到最大值?

每个Ping周期窗口增2000比特,需要25个Ping周期增长至50000比特,平均Ping为7.5ms,需187.5ms。

### 问题五

如果从澳大利亚服务器流视频,Ping为250ms,缓冲区应设多大?  

250ms×10Mbps=2500000比特,298KB。

### 问题六

丢包后窗口恢复最大值需多长时间?

需要1250个Ping周期,平均Ping为375ms,需468.75秒,近8分钟。这将在实际应用中造成问题。

## 59. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn59 p59 4 4   AIMD Multiple Flows 64

### 多流的网络中AIMD控制方式

视频中解释了在具有多个流的网络中,AIMD如何控制拥塞。

- 路由器输出缓冲区通常可以容纳数十万个数据包,其中包含来自多个流的数据包。

- 每个流都会独立按照AIMD曲线增加和减少其窗口大小。

- 当一个流的数据包被丢弃时,只有该流会缩减一半窗口大小,其他流不受影响。

- 由于流数量众多,单个流占据缓冲区的比例很小。一个流的数据包被丢弃基本是随机事件。

- 假设RTT保持常量,则每个周期流通过量等于窗口大小除以RTT。平均通过量等于平均窗口大小除以RTT。

- 通过put等于面积A除以最大窗口大小Wmax除以2乘以RTT。面积A计算公式为3/8×Wmax^2。

- 引入丢包概率P,根据A和P关系式P=1/A,可推导流通过量等于√(3/2)除以RTT乘以√P。

- AIMD特点是通过量随RTT成反比,随丢包概率P成正比。丢包对AIMD很重要,它控制窗口大小的上限。

### 多流中AIMD的运行机制原理已详细阐述完毕

## 60. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn60 p60 4 5   Congestion Control   TCP

TCP拥塞控制是为了解决网络拥塞问题提出的。

在TCP标准之前,TCP的工作机制是:

1. 设置连接,获取流控窗口大小。

2. 直接发送流控窗口数量的数据包。

3. 设置每个数据包的重传定时器。

4. 如果数据包在定时器时间内没有收到确认,就重传该数据包。

这种机制的问题是:如果流控窗口比网络真实支持的数据量大,直接发送流控窗口数量的数据包很可能会导致网络拥塞。大部分数据包会丢失,TCP需要进行大量重传就无法正常工作。

为此,Van Jacobson提出了三点改进:

1. 引入拥塞窗口概念。TCP通过检测网络情况,动态调整拥塞窗口大小,限制发送数据量不超过网络负载能力。

2. 改进重传定时器的估算。

3. 自时钟控制。

TCP通过慢启动和拥塞避免两种模式控制发送数据。

慢启动模式用于连接开始和拥塞检测时,窗口大小从1MSS增加到拥塞窗口大小。每收到一个ACK,窗口增加1MSS。这样在一个RTT内只发送1个包,第二个RTT发送2个包,指数级增长探测网络负载能力。

拥塞避免模式用于网络运行正常时,以Additive Increase Multiplicative Decrease的方式逐步增加当前拥塞窗口大小进行发送,同时快速响应拥塞指示进行减小。动态调整利用网络资源,避免拥塞。

## 61. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn61 p61 4 6   Congestion Control   RTT

TCP太浩算法引入了三种基本机制来控制拥塞:拥塞窗口、慢启动阶段和拥塞避免阶段。

除此之外,TCP太浩还增加了两种更好的机制:

### RTT估计

RTT的估计对重新传输和超时都很重要。如果估计的RTT过短,就会导致 unnecessary 的重新传输,并触发慢启动,浪费带宽。如果估计的RTT过长,也会造成问题。

TCP太浩使用加权移动平均法估计RTT:

1. 初始RTT值
2. 根据ACK数据计算实际RTT(m)
3. R←α×R+(1-α)×m ,α为权重系数
4. 超时时间为β×R,β原本为2

但是,这个算法没有考虑RTT的分布情况。如果分布比较集中,β×R会过于宽松;如果分布较分散,β×R又可能过于保守。

### TCP太浩改进了RTT估计算法

1. 还是使用加权移动平均法估计平均RTT(R)

2. 同时估计RTT的方差

3. 超时时间为R+4×方差

这样就考虑到了RTT分布的广泛情况,能够更精准地判断包是否丢失。

### 自时钟机制

发送方发送数据的速度应由接受方的ACK来进行“钟划”。

加入了易通瓶颈的情况下:

1. 发送方发包会被瓶颈拉长输出时间

2. 接受方ACK也因此被“钟划”而间隔输出  

3. 如果发送方依据ACK来发送,也就能间隔发包,匹配瓶颈带宽

这样就实现了拥塞控制—只有数据出去了,才允许更多数据进入网络,杜绝拥塞。

## 62. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn62 p62 4 7   Congestion Control   TCP

### TCP拥挤控制概述

- TCP Tahoe解决了拥挤控制中的问题,使TCP能正常工作。但性能还可以提高。

- 随后提出TCP Reno和New Reno,在TCP Tahoe基础上改进提高TCP拥挤控制的性能。

### TCP Tahoe拥挤控制机制

- triple duplicate ACK(三重重复ACK)或超时,会将拥塞窗口大小重设为1,进入慢启动状态。

- 将慢启动阈值设置为当前拥塞窗口大小的一半。

- 慢启动阶段窗口大小以指数形式增长,超过慢启动阈值后进入拥塞避免状态以线性增加窗口大小。

### TCP Reno改进

- 对triple duplicate ACK,不将拥塞窗口重置为1,而是将其减半。通过快速恢复状态快速进入拥塞避免状态。

- 对超时情况,仍照TCP Tahoe机制将拥塞窗口重置为1进入慢启动。

- 快速重传立即重传丢失报文,而不等待超时,缩短等待时间,提高吞吐量。

### TCP New Reno进一步改进

- 在快速恢复状态中,对每接收到一个duplicate ACK,将拥塞窗口增大一个MSS。

- 最后一个未确认报文确认后,将拥塞窗口重置为进入快速恢复状态时的值,避免网络拥塞。

- 允许在快速重传期间发送新报文,而不像TCP Reno需要等待确认才能继续发送,减少空闲时间, Further improve throughput.

## 63. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn63 p63 4 8   Congestion Control   AIMD

### 拥挤控制目标

- 服务提供商希望利用率最大化,使用率高。

- 用户希望平分网络带宽,获得公平份额。

- 要避免拥塞崩溃,网络一直处于有用工作状态。

### 拥挤窗口大小

拥挤窗口大小应为“带宽-延迟积”,即让网络充分利用带宽资源但不造成拥塞。

### AIMD原理

- 加法增加(Additive Increase):每次拥挤窗口增长固定值。

- 乘法减少(Multiplicative Decrease):一旦拥塞,窗口立即下降一半或更多。

### Chew-Jain图

- X轴为流A速率,Y轴为流B速率。

- 公平条件下,A=B。总容量条件下,A+B=网络容量。

- AIMD机制能使两条流趋向公平且高效区域。

### AIMD优点

- 通过加法增加使网络利用率最大化。

- 乘法减少使各流获得公平带宽。

- 相对于其他算法,AIMD实现复杂度低,收敛速度快。

## 64. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn64 p64 4 9

### 什么是RFC

RFC全称为Request for Comments,意为请求意见。它是互联网工程任务组(IETF)发布的一系列标准文件和互联网草案。RFC中记录了互联网相关技术规范、过程或程序,被视为Internet标准。

### RFC的类型

RFC主要有5种类型:

- 提议标准:是一群人提出应该成为标准的文件。

- 标准轨道:通过讨论实现与测试,逐步成为稳定标准。

- 信息性RFC:提供有价值信息,但不是协议规范。

- 实验性RFC:探索新想法但未定型的文件。

- 最佳现行实践:根据当前知识,描述最佳实践方法。

### RFC编写过程

RFC编写过程大致如下:

1. 起草阶段,以个人名义提交草稿。

2. 进入IETF工作组审核,修改迭代。

3. 工作组批准后,以IETF名义提交。

4. 最后通过IETF审核后发布为RFC文件。

整个过程需实现广泛讨论与反馈,充分考虑各方面意见,才能最终发布。

### RFC重要术语

RFC 2119规定了在RFC中常用并带特定含义的几个英文词:

- MUST:是一个强制要求。

- SHOULD:强烈建议这样做,但有例外。

- MAY:是可选的,不采纳不影响整体。

这些词大写显示,阅读RFC时需要重点关注。

### TCP拥塞控制RFC详解

以RFC 5681为例,阐述TCP拥塞控制机制规范,重点梳理其中的MUST、SHOULD以及MAY用法。

## 65. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn65 p65 4 10    Congestion Control 64

### 流量控制与拥塞控制

流量控制确保源主机不会发送比目的地可以接收更多的数据以免过载目的地。拥塞控制防止源主机过多发送数据以免过载网络中的链路和路由器。

### TCP拥塞控制算法

TCP使用拥塞窗口大小控制能够在网络中发送但还未确认的数据量,以防止填满路由器队列。TCP主要使用Additive Increase Multiplicative Decrease(AIMD)算法。

### TCP吞吐量计算

当丢包率为p时,TCP流的理论吞吐量为:√(3/2)×rtt^−1×√p,rtt越大,吞吐量越小。

### 最大最小公平

网络拥塞期望实现最大最小公平策略,即无法增加某个流的速率而不减少其他流速率更低流的速率。

### TCP版本演进

TCP Tahoe、TCP Reno、TCP New Reno依次添加和优化了快速重传、快速恢复和窗口膨胀机制等,以进一步降低网络拥塞。

### 总结

网络拥塞是随着Internet规模增大而逐渐显现出的问题。TCP通过不断完善的拥塞控制算法,使数据传输得以高效公平地进行。其理论基础也为后续研究奠定基础。

## 67. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn67 p67 5 0   Applications and NATs 64

### 本单元内容

本单元将介绍三个重要的Internet应用:DNS(域名系统)、HTTP(万维网)和Bittorrent。其中DNS使用UDP,HTTP和Bittorrent使用TCP。

### DNS

DNS是域名到IP地址的映射服务。它使用客户端-服务器交互模式,客户端可以查询域名获得相关信息。

### HTTP

HTTP操作在TCP上,也是客户端-服务器模式。将描述HTTP请求格式,以及基于Google Speedy提出的HTTP新版本。

### Bittorrent

Bittorrent使用TCP交付可靠传输,但采用P2P交换文件块的模型,而不是客户端-服务器模型。它使大文件传输效率很高。

### NAT设备

NAT设备允许多个内部主机使用单一IP地址与外部网络通信,也提供一定的安全功能。但它增加了建立 initiating connections 的难度,给应用带来不便。

### 总结

介绍应用开发时需要解决的NAT问题。掌握NAT工作原理对建立新型Internet应用很重要。

## 68. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn68 p68 5 1   NATs   Introduction 64

### 网络地址翻译(NAT)

NAT是一种网络设备,位于内部网络和外部网络(互联网)之间。NAT具有内部和外部两个网卡,为内部主机分配私有IP地址,而NAT自己使用公有IP地址与外部网络通信。

当内部主机向外网发起连接时,NAT会记录这个内外对应关系(映射),为内部主机分配一个临时的外部IP地址和端口。收到回复后会把数据转发给内部主机。这样就实现了多个内部主机共享一个外网IP地址的功能。

NAT提供以下优点:

1. 节约IP地址资源。私有IP范围内的地址不会冲突,可以给更多主机分配IP。

2. 提高网络安全性。内部主机被隐藏在NAT设备后面,外网无法直接访问内部主机。

3. 连接互联网无需直接公有IP地址。

4. 现今大多数无线路由器都内建NAT功能。

NAT工作原理:

- 内部主机向外网发起连接请求时,请求报文源IP和源端口会被NAT改写。

- NAT记录这个内外对应关系。

- 外部应答报文经NAT翻译回内部主机地址后入内部网络。

- 多个内部主机可以共享同一个外部IP,但不同连接会对应不同的临时外部端口。

- NAT根据报文的5元组(协议、源IP、源端口、目的IP、目的端口)来进行状态管理和转换。

### NAT工作模式

NAT工作模式包括静态NAT和动态NAT两种。静态NAT对内外地址映射进行静态配置,动态NAT在内部主机请求外网连接时临时分配外部地址资源。

## 69. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn69 p69 5 2   NATs   Types 64

### 全锥型NAT(Full Cone NAT)

- 全锥型NAT是对穿过映射允许的包最不限制的NAT类型。任何到达NAT内部端口的包都会被转发到外部端口。

- 对内部主机来说,外部看起来就像直接与它连接一样,不限制来源IP和源端口。

### 限制锥型NAT(Restricted Cone NAT)

- 限制锥型NAT根据源IP地址过滤包。只允许与外部映射相关的内部主机源IP可以通过NAT。

- 如果来源IP与外部映射一致,不论源端口如何,都可以通过NAT。

### 端口限制型NAT(Port Restricted NAT)

- 与限制锥型NAT类似,但同时也根据源端口进行过滤。

- 只允许与外部映射中的内部地址和端口一致的包通过NAT。

### 对称型NAT(Symmetric NAT)

- 对称NAT为同一个内部地址和端口到不同外部目标地址和端口会设置不同的外部地址端口映射。

- 例如在游戏服务器间进行设备迁移时,会因NAT设置新的映射而导致连接中断。

### NAT类型总结

NAT类型依次从开放到限制:全锥型NAT、限制锥型NAT、端口限制型NAT、对称型NAT。应用程序难度也随之增大。

### 参考文献

RFC 3489为NAT类型与行为提供了详细说明。RFC 5382和RFC 4787给出了NAT标准化建议。

## 70. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn70 p70 5 3   NATs   Implications 64

网络地址转换(NAT)向应用程序提出一些挑战。主要影响如下:

### 无法接收传入连接

NAT后主机无法直接接收来自外部的TCP连接,因为NAT没有设置映射。例如,如果A位于NAT后,B无法直接建立SSH连接到A的22端口。

### 连接转发

通过使用中继服务器进行连接转发来解决这个问题。例如,A和B都连接到中继R,然后R转发A和B之间的流量。

### 连接倒置

如果A位于NAT后,B先联系中继服务器请求连接A。然后A主动建立连接到B。这样B实际上建立了连接。

### 双NAT情况下的连接

如果A和B同时位于NAT后,两者先都连接到中继R,然后R转发A和B之间的流量。

### NAT打洞

A和B先联系外部服务器获取对方在外部的地址和端口。然后A和B同步地向对方的外部地址发送流量,从而让NAT建立映射,实现直接连接。但对对称NAT无效。

### 对传输层的影响

NAT需要了解传输层协议的报头格式,才能进行地址和端口转换。所以新兴传输层协议很难在Internet上部署。

总之,NAT给应用程序带来了很多限制,需要复杂的机制如连接转发、倒置来工作。

## 71. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn71 p71 5 4   Nats   Operation 64

### 网络地址转换系统(NAT)的工作原理

NAT主要完成将内部网络的IP地址和端口与外部网络的IP地址和端口建立映射的工作。

NAT设置映射时,会将内部主机的IP地址和端口号与分配给它的外部IP地址和端口号建立对应关系。对于TCP协议,当检测到SYN包时会设置映射;对于UDP协议,则一般在检测到来自内部主机的第一个数据包时设置映射。

映射的删除取决于具体协议。对于UDP,由于它没有连接控制序列,因此NAT会在超时后删除映射;对于TCP,如果检测到完整的FIN-ACK序列,NAT会更快地删除连接状态和对应的映射。

NAT作为网络设备还可以独立响应对自身IP地址和端口的连接请求。如果当前没有其他主机通过它,它就像普通路由器一样工作。

### NAT必须遵循的行为规范

规范中明确了NAT在处理UDP和TCP流量时必须具备的行为要求,以保证兼容最广泛的应用场景。

对于UDP,NAT设置的映射不能依赖于通信的对端地址,必须为每个外部IP地址和端口独立设置映射;同时,来自同一内部IP地址的UDP包在外部应具有一致的源IP地址。

对于TCP,NAT必须支持包括同时打开连接在内的所有有效TCP连接序列;同时,内部和外部端口之间也有对应规则,以保证应用层兼容性。

这些建议源于对实际NAT设备行为的大量测试,目的是推荐NAT行为的最佳实践,避免因NAT设置导致应用层通信失败。

### 总结

NAT 的工作机制是将内外网络的地址和端口通过映射关系相互对应,以实现多个内部主机共享外部IP地址的目的。同时,为保证最广泛的应用兼容性,NAT必须遵守RFC标准中定义的关键行为规范。

## 72. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn72 p72 5 5a   HTTP 64

### 超文本传输协议HTTP

HTTP是构建在TCP基础上的应用层协议,用于在客户端和服务器之间进行请求和响应。

HTTP采用请求响应模型,客户端向服务器发送请求,服务器返回响应。最常见的请求方法是GET,用于请求页面。

#### 超文本

超文本(hypertext)是一种允许在文件内嵌格式和内容信息的文档格式。网页就是一种超文本文档。

与其他格式如Word文档不同,超文本全部采用ASCII可打印字符。格式信息用HTML标签表示,比如<h1>表示大标题。浏览器根据标签进行渲染展示。

#### HTTP请求

HTTP请求包含第一行请求行(描述方法、URL和HTTP版本)和若干请求报头行。请求方法包括GET、POST等。

GET请求正文为空,POST请求可能包含请求数据。POST常用于表单提交。

#### HTTP响应

HTTP响应包含第一行状态行(描述HTTP版本、状态码和原因短语)和若干响应报头行,接着是一个空行后是响应正文。

状态码200表示请求成功,304表示内容未修改无需返回体。响应正文一般为Requested资源或错误信息。

#### 资源引用

超文本可以通过标签将外部资源如图片嵌入文档内,例如<img>标签。浏览器在解析文档时会自动请求所引用的资源。

#### HTTP开发工具

开发者工具可以查看HTTP请求和响应详细信息。也可以使用Telnet直接发出HTTP请求查看报文格式。

这可以帮助更深入理解HTTP工作原理。

## 74. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn74 p74 5 5c   HTTP Quiz 1 Explanation

### TCP三次握手和报文传输时间

- TCP建立连接需要经历三次握手过程(SYN、SYN-ACK、ACK),这里耗时100ms。

- 客户端向服务器发送第一个HTTP请求,耗时60ms到达服务器。

- 160ms时,服务器可以开始发送第一个响应报文。每个响应包含2个TCP分组。

- 作为第一个响应分组传出时,服务器接收到第二个请求,将后续2个响应分组加入队列。

### 请求响应时间

- 第一个HTTP请求的请求响应完成需要230ms(160ms+90ms)。

- 队列中的后续响应分组将第二个请求的额外传输延迟隐藏起来。

- 总计请求第一个HTTP页面加请求两个图像需要480ms:
  - 第一个HTTP请求230ms
  - 后两个图像分别 250ms

- 所以两个图像全部下载完成需要总计250ms。

## 75. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn75 p75 5 5d   HTTP Quiz 2 Intro 64

### HTTP加载时间测量案例

该视频提出一个HTTP加载时间测量的案例,需要根据以下参数计算加载时间:

1. 页面大小为100KB,网络带宽为1MB/s

2. 页面包含2张图像,大小分别为50KB和20KB。服务器延迟为100ms,带宽为1MB/s。

对于第二个案例,需要仔细考虑请求和响应是否可能重叠从而影响总时间。

这是一个测算实际HTTP加载需时的代表案例。提供的参数可以反映网络条件、文件大小等实际因素影响。通过结合TCP三次握手机制和请求响应模型计算不同情况下的加载时间,有利于深入理解HTTP工作原理。

## 76. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn76 p76 5 5e HTTP Quiz 2 Explanation

### 案例1答案

页面大小100KB,带宽1MB/s。

- TCP三次握手20ms
- 请求25ms
- 响应30ms
- 总计95ms

### 案例2答案

页面包含2张图片,大小50KB、20KB。服务器延迟100ms,带宽1MB/s。

- 首页面95ms
- 图片1 95ms  
- 图片1结束,图片3开始,此时图片2已在传输
- 所以图片2也是95ms
- 重复上述过程,每轮95ms
- 总计380ms

### 请求响应重叠机制

- 客户端同时开始请求不同资源,利用TCP连接池技术
- 后续请求在队列waiting,不会阻塞前面请求
- 响应分段逐个发送,后续响应不等待前面完成再发送
- 请求和响应通过交错传输,隐藏了部分延迟
- 导致并行请求的总时间接近串行请求时间

本文通过图示详细解释了HTTP并行请求如何利用TCP机制,隐藏延迟并缩短总下载时间。

## 77. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn77 p77 5 6 HTTP 1 1 Keep alive 64

### HTTP1.1保持连接机制

HTTP1.0每次请求响应都需要新建连接,导致开销大。HTTP1.1添加了`Connection`和`Keep-Alive`头部。

- 客户端请求可以包含`Connection: keep-alive`提示服务端保持连接。
- 服务端响应包含`Connection: keep-alive`和最大保持时间告知客户端。
- 客户端可以在同一个连接中发送多个请求,避免重复建连接。

### 优势分析

将一个页面和11幅图作为例子进行分析。

- HTTP1.0每个资源203ms,总计1421ms。
- HTTP1.1建连100ms,页面请求103ms,11图请求123ms,总计326ms,速度提升4+倍。

保持连接机制避免重复建连开销,TCP窗口能最大限度增长, hugely提升吞吐量。

### HTTP2.0与Speedy

- Speedy允许请求流水线,响应可按任意顺序返回。
- 去除冗余头部,缩短报文大小。
- 成为HTTP2.0规范基础,未来网络将主导采用。

保持连接机制极大优化了HTTP性能,是web应用性能研究的重要方向。

## 78. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn78 p78 5 7 BitTorrent 64

### BitTorrent概述

BitTorrent优点是资源分享带宽广泛。BitTorrent客户端从其他客户端请求文件分块,同时可以从多个客户端并行下载。

### 文件分块与特征

文件被划分为若干个Piece,每个Piece大小一般256KB以上。每个Piece都有一个SHA-1哈希值,可检验完整性。

### 群体与节点

多个客户端组成一个群体(Swarm)进行分享。节点通过Tracker或DHT定位其他节点。

### 下载流程

客户端下载 Torrent文件后加入群体,与节点交换Piece信息,优先下载较少的Piece以平衡可用性。完成下载后离开群体。

### 传输机制

使用TCP连接来传输Piece,对每个连接进行流量控制。同时支持从多个节点下载Piece不同部分来提高效率。

### 提高下载速度

使用Tit-for-tat算法,限制上传给最大P个下载节点,激励合作上传。同时定期解除限制探索更快节点。

### BitTyrant优化

通过精确控制给每个节点提供的带宽,实现多个节点的最大上传限制,从而提高个人下载速度。

### 总结

BitTorrent通过群体合作、优先下载策略等机制,有效提高分布式文件分享效率。

## 79. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn79 p79 5 8   DNS 1 64

### 域名系统介绍

域名系统(Domain Name System,DNS)是将用户易记的域名与调度机器的IP地址进行对应匹配的系统。

### DNS设计原则

1. 能够管理巨大数量的记录
2. 支持分布式控制,不同机构可以管理自己的域名空间
3. 系统需要高可靠性,单个节点故障不会导致整个系统崩溃

### DNS实现原理

DNS数据库以只读或轻度写为主,记录更新不频繁。同时DNS不要求完全一致性,允许存在一定延迟。这使得DNS可以采用大量缓存来提高性能。

### DNS名称空间层级结构

DNS名称采用从顶至底的分层结构。顶层为根区,然后是顶级域(如edu、com等)、次级域(如stanford.edu)、子域(如www.stanford.edu)等。每个区域可以由不同机构独立管理。

### DNS服务器与查询过程

1. 客户端默认知道一些根服务器的IP地址
2. 对域名查询时,会先询问根服务器域名对应的顶级域服务器位置
3. 然后按层级命中解析,直到得到想要域名的IP地址
4. 各个区域的DNS资源记录由多个服务器提供任播服务,充分利用缓存提高查询效率

### DNS查询格式

DNS查询默认通过UDP 53端口进行。查询报文包含查询类型字段,用于表示是否递归查询。递归查询服务器会帮助完成整个多层查询过程。

## 80. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn80 p80 5 9 DNS 2 Names and address

本节主要介绍了DNS中的名称与地址表示。

DNS通过资源记录(RR)的方式来表示所有的网络信息。资源记录包含名称、类型、类别、生存期(TTL)以及记录数据。

名称服务记录(NS记录)指明了某个域名的权威名称服务器。地址记录(A记录)将域名映射到IP地址。CNAME记录指明了域名的别名。

DNS查询采用递归查询的方式进行。客户端首先向名称服务器发起初级查询,名称服务器将查询传递给根服务器、顶级域服务器等,最后获得 authoritative name server,然后向该服务器发起最终查询获取结果。

DNS采用递归压缩的方式表示域名,这样可以有效地降低传输体积。它将域名按照“.”分割成多个组件,每个组件以长度和值的方式表示,并支持指针压缩重复的组件。

资源记录采用多字节的方式进行网络传输。其中包含名称、类型、类、生存周期(TTL)以及记录数据等字段。例如A记录将把IP地址作为记录数据返回。

通过工具dig可以观察DNS查询和响应报文,其中包含四个主要部分:Header、Question、Answer和Authority与Additional。Header描述总体信息,Question部分包含查询内容,Answer返回结果,Authority与Additional提供附加信息。

## 81. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn81 p81 5 10   DNS 3 64

### DNS记录种类

 DNS记录主要包括以下几种:

- A记录:地址记录,用域名查询IP地址
- NS记录:域名服务器记录,记录域名对应的名称服务器
- MX记录:邮件交换记录,记录域名对应的邮件服务器
- CNAME记录:别名记录,用于定义域名别名
- TXT记录:文本记录,用于存放域名相关的文本信息
- PTR记录:指针记录,用于实现反向查找
- AAAA记录:IPv6地址记录
- SOA记录:区域开始记录,用于描述域名空间相关信息

### 递归查询与非递归查询

- 递归查询:客户端向根服务器或顶级域名服务器发出查询请求,服务器将递归查询其下级名称服务器,直到找到结果返回给客户端。
- 非递归查询:客户端直接向目标域名对应的名称服务器查询,名称服务器回复自己所知的信息部分,不进行递归查询。

### 解析请求过程

解析一个域名如www.scs.stanford.edu的请求过程:

1. 向根服务器查询edu域下的名称服务器
2. 向edu名称服务器查询stanford.edu域下的名称服务器
3. 向stanford.edu名称服务器查询scs.stanford.edu域下的名称服务器  
4. 向scs.stanford.edu名称服务器查询www对应的A记录

在查询过程中,每个名称服务器不仅返回查询结果,还附带向下级服务器的域名记录以便递归查询,这就是“黏合记录”。

### 别名和指向

- CNAME记录定义域名别名,则该域名不能携带其他记录类型
- MX记录若指向别名,需要额外查询别名解析,增加复杂度

## 82. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn82 p82 5 11   DHCP 64

### DHCP简介

DHCP(动态主机配置协议)是一种为计算机主机自动分配IP地址、掩码和网关等必要网络配置信息的网络协议。

### 计算机主机获取网络配置信息的传统方式

以前,计算机主机需要事先向系统管理员申请网络配置信息,然后系统管理员会手动分配IP地址等信息后把记录下来的信息通过打印本提供给用户。这样个性化且不易自动化管理。

### DHCP优点

1. 网络拓扑变更时,计算机主机只需要重新请求DHCP服务器获取变更后的配置即可适应。
2. DHCP服务器可以根据配置分配规则,自动给出适合的IP地址等配置,省去手动分配的麻烦。
3. DHCP服务器可以定期回收无主机使用的IP地址等资源,提高资源利用率。

### DHCP工作流程

1. 新加入网络的主机发送DHCP发现消息广播寻找DHCP服务器。
2. 能够接收到的DHCP服务器会给出IP地址等配置信息的报文回复。
3. 主机选择一个DHCP服务器后的报文进行确认。
4. 选定的DHCP服务器确认分配。
5. 主机使用配置信息连接网络。需要时也可以通过DHCP延长租约或释放配置。

### DHCP消息封装

由于还未获取IP地址,DHCP消息通过UDP广播形式在67/68端口进行传输。客户端是使用0地址发起。DHCP服务器回复目标是广播地址。

### DHCP实验流程示意

以苹果机Discover后收到 zwei个DHCP服务器Offer,选择第一个Offer并通过Request确认获得固定IP地址等网络配置为例进行介绍。

### DHCP报文格式

详细解读Discover、Offer和Request报文中的内容,涵盖交易ID、IP地址、掩码、网关、DNS信息等配置细节。

## 83. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn83 p83 5 12   Applications and NATs re

### 网络地址转换器(NAT)概述

NAT是一种路由器,它允许多个内部设备共享一个外部IP地址。通过修改包头中的源/目标地址与端口号,NAT可以将内部设备的通信伪装成来自NAT外部IP的流量。

### NAT工作原理

NAT为内部设备分配私有IP,同时获得一个公网可路由IP作为外部地址。当内部设备向外通信时,NAT将源地址/端口修改为自己的外部IP与动态端口,反方向流量由端口识别正确内部目标。

### NAT带来的问题

NAT阻止外部主动连接内部设备,影响一些需要外部主动连接的应用。同时,新协议难以在NAT后工作,通常需要伪装TCP或使用UDP。

### HTTP概述

HTTP是基于TCP的请求-响应协议,请求和响应均为ASCII文本,易阅读。HTTP1.1引入持久连接,减少TCP三次握手开销,优化性能。

### BitTorrent工作原理

BitTorrent使用TCP,但不是客户端-服务器结构,而是同行之间协作下载的“热”模型。它通过网格式传输加速分块下载,采用“稀缺先下载”和“观效原则”激励合作传输。

### 三大应用对比

总结了HTTP、BitTorrent和DNS三大应用的特点:传输层协议、结构架构、数据传输机制等差异点。

## 84. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn84 p84 6 0   Routing 64

### 路由基本概念

路由指将网络封包从源设备传送到目的设备的过程。

### 路由表

每个路由器都包含一个路由表,表中记录了各个目的网络前缀应该发送到的下一跳路由器。

### 构建树形网络拓扑

路由使用树形网络拓扑将所有源设备连接到给定目的地,形成根源于目的地的树状结构。

### 路由算法

Bellman-Ford算法和Dijkstra算法分别用于构建距离向量和链路状态树形网络拓扑。

### 自治系统概念

互联网由各个自治系统组成,如斯坦福线性粒子对撞机和斯坦福校园。

### 内部路由协议

自治系统内部使用RIP距离向量协议或OSPF链路状态协议构建路由表。

### 自治系统边界路由

自治系统之间使用BGP边界网关协议路由,实现路径选择而非仅基于最短路径。

### 总结

本单元介绍了互联网中各种路由元素及其联系,阐述了从源到目的地的包转发原理。

## 85. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn85 p85 6 1   Routing   Flooding, sourc

### 洪泛算法 Flooding

洪泛算法是针对不了解网络拓扑结构时采用的一种简单路由算法。其基本思想是每台路由器将包转发到所有其它接口,除了收到该包的接口。

洪泛算法的优点是可以确保每个节点最终都能收到包,但同时也导致包可能永远循环转发下去,消耗网络带宽。为防止循环转发,实际应用中通常添加TTL(Time To Live)字段限制包的最大转发次数。

### 源路由法 Source Routing

源路由法中,源主机会在包头中加入完整的期望转发路径。每台路由器只需要简单按照包头指定的次序进行转发即可。

源路由法实现了端到端原则,由源主机完全控制转发路径。但包头额外 carrying 路径信息也增加了包大小开销。且随着网络规模增大,源主机不可能完全了解整个网络拓扑结构。

### 转发表法 Forwarding Table

转发表法中,每个路由器内部维护一个包含所有目的地下一跃信息的转发表,并根据该表实现分组的逐跳转发。这种方法把转发功能下放到网络层进行 centralized 管理,有效利用了网络资源。

但需要及时更新各节点转发表内容,以反映网络拓扑变化。常见的获取转发表内容方法包括:交换树算法、链路状态路由等。

### 交换树 Spanning Tree

为避免转发闭环,通常会在网络内构建一颗交换树。交换树需要满足:1连接起全部源节点和目的地 2没有闭环。常见的交换树选择标准包括:最小延迟、最小跃点数、最大吞吐量等。

通过在各节点内设置 pointing 到父节点的下一跃信息,就可以实现按交换树路径进行分组转发。

## 86. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn86 p86 6 2   Routing   Bellman Ford 64

### 距离向量路由协议

距离向量路由协议是一种每个路由器根据与其他路由器的距离来维护到达每一个目标路由器的最佳路径的协议。

每个路由器都会维护一个矢量,记录到达每个目标路由器的距离成本。定期通过广播的方式,每个路由器会将自己的距离矢量发送给邻居路由器。如果收到了更优的路径信息,将更新自己的距离矢量。通过这种方式,所有的路由器都能逐步收敛到全网最优路径。

### 贝尔曼-福特算法

贝尔曼-福特算法是距离向量路由协议中使用最广泛的一种。

算法假设每个路由器都知道与邻居路由器之间链路的成本。每个路由器R会维护矢量C,记录到达每个目标路由器R8的当前最低成本。

算法初始化时,所有路由器的C值设为无穷大。每隔时间T,每个路由器Ri会将自己的C值发送给所有邻居。如果收到更低成本的路径信息,会更新C值。以此反复,直到收敛到全网最优路径。

算法运行时间取决于网络中最长无环路的跳数。算法总会收敛,因为只会用更低成本的值替换原来的成本。当链路成本或路由器发生故障时,通过新的更优路径信息更新,也能重新收敛。

但是,如果某条路径断开,之前使用该路径的路由器很难及时获知,这也是该算法的一个缺点。

## 87. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn87 p87 6 3   Routing   Dijkstra 64

### 路由算法概述

本视频继续介绍路由算法。距离矢量算法和链路状态算法是两种主流的路由算法。

### 链路状态算法概述

链路状态算法是一种路由选择算法。其特点是:

1. 各路由器会定期广播自己与其它路由器的连接信息,包括连接路由器信息和链路状态(上下线)信息。

2. 收到消息后,各路由器均可知道整个网络的拓扑结构。

3. 每个路由器均独立运行算法,计算自身到其它各路由器的最短路径树。

4. 拓扑结构或链路状态发生变化时,路由器会更新并重新计算最短路径树。

### Dijkstra算法

Dijkstra算法是链路状态算法的一个具体实现。它通过以下步骤计算各路由器间的最短路径树:

1. 初始化候选集合(集合)和最短路径集合。候选集合包含与源路由器直接连接的路由器。

2. 选择候选集合内距离源路由器成本最小的路由器,加入最短路径集合。

3. 更新候选集合,加入直接与更新后的最短路径集合连接的新路由器。

4. 重复执行上述步骤,直到候选集合为空,获取源路由器到所有路由器的最短路径树。

5. 拓扑结构或链路成本变化时,重新计算最短路径树。

### Dijkstra算法应用

Dijkstra算法应用广泛,它是OSPF(开放最短路径优先)路由协议的计算核心。OSPF是因特网 routers最常用的内部网关协议。

Dijkstra算法也可以象征式推导为“拉球算法”。将每个路由器看作一颗球,将链路看作连接球的线。计算最短路径树相当于推导出从源球拉动伸长线能构成的最短路径结构。

## 88. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn88 p88 6 4   Routing   Internet RIP, OSPF

### 分级路由

由于互联网规模庞大,直接在所有路由器之间交换路由信息难以实现。因此需要将网络划分为自治系统(Autonomous System,AS)。

AS内部可以自由选择内部路由协议,但与其他AS的交互必须使用边界网关协议(BGP)。

AS根据出口点数量可以分为单出口AS和多出口AS。单出口AS使用默认路由,多出口AS需要内部路由协议处理多出口情况。

### 内部路由协议

1. 距离加法协议(RIP):使用距离矢量算法,每30秒广播一次路由更新,180秒不收到视为节点故障。但无校验,安全性差。

2. 链路状态路由协议(OSPF):使用链路状态算法。定时通过广播方式发送链路状态更新给所有路由器,每个路由器运行Dijkstra算法计算最短路。更新包带签名,安全可靠。OSPF支持区域划分,适用于大型网络。

### 自治系统间路由

单出口AS使用默认路由功能将目标不在本AS的数据包转发到默认路由器。

多出口AS需要内部路由协议根据目的地选择出口节点,将数据包发送到相应出口,以便转发到对等AS。

## 89. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn89 p89 6 5   Routing   BGP 64

### 地址路由与链接状态路由  

BGP是一个路径向量协议,它使用路径向量来传播路由信息。BGP路由器会在边界处广播完整的路由路径,路径包含到达某个目的地前缀需要经过的所有自治系统序列。这也称为自治系统路径。

### BGP消息类型

BGP有4种消息类型:

1. 开放消息:建立BGP会话
2. 保持活动消息:定期“握手”以维持BGP会话
3. 通知消息:关闭对等会话  
4. 更新消息:发布和撤销路由。更新消息是最重要的消息,用于广播新路由或撤销过去广播的路由。

### 路径属性

更新消息包含目的地前缀和路径属性。路径属性包括:

- 自治系统路径:标识路由的顺序 AS序列
- 本地首选值:代表关系的本地策略,可能优先客户路由过对等路由
- 多出口揭示器:用于选择路径来最小化拥塞

路径属性用于选择多个对等体广播的多个路径选择其中一个。

### 选择最佳路径的顺序

1. 最高本地首选值
2. 最短的自治系统路径  
3. 其他因素,如多出口揭示器,用于提高网络流量工程
4. 没有区分的情况下,选择最小的路由器ID

### 客户提供商关系模型

BGP关系建立在客户与提供商的模型基础上:

- 提供商位于等级结构的上层,客户位于下层
- 客户向提供商支付费用来携带其包
- 等级可以扩展,如提供商也可以是其他提供商的客户

这种关系模型影响BGP的本地策略,例如优先选择客户路由。

### 总结

BGP使用路径向量协议传播路由信息。它采用本地首选值和路径属性来选择最佳路径,充分考虑自治系统层次结构及客户提供商关系。

## 90. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn90 p90 6 6   Routing   Multicast 64

### 简介

本视频将介绍IP多播的一些技术,包括:

- 反向路径转发:利用已经建立的单播 shortest path spanning tree 路由多播数据包,避免产生环路。

- 剪枝:没有加入多播组的路由器会向源发送剪枝消息,从多播树上剪去没有兴趣的分支。

- 源特定树:每个源建立一棵源到组内主机的最短路径 spanning tree,以支持源对源通信。

- 会合点:在组内设定会合点路由器,由会合点路由器建树连接组内所有主机。

### 反向路径转发

反向路径转发利用已经建立的单播shortest path spanning tree路由多播数据包。源发送数据包时,中间路由器会查询数据包接收端口是否在前向 shortest path tree 上,如果是则接收并向其他端口转发,否则丢弃包避免产生环路。

### 剪枝

不加入多播组的路由器向源发送剪枝消息,将无兴趣分支从多播树上剪去。 remaining tree 仅包含感兴趣的终端主机。

### 源特定树

每个源都会建立一棵从源到组内所有主机的最短路径spanning树。这样从不同源发送的数据包将采取不同路径发送,保证采用最优路径。

### 会合点

在组内设定某个路由器为会合点,所有源先将数据包发送到会合点,会合点再建立一棵从它到组内所有主机的最短路径树进行转发。降低树的数量,但源到会合点依然采用单播转发。

## 91. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn91 p91 6 7   Routing   Spanning Tree 6

### 根机制

- STP会选择网络中唯一的根交换机,其他交换机通过向根发送BPDU以确定自己到根的距离。

- 交换机会将自己ID广播出去,ID最小的将被选择为根机器。如果ID相同,距离最小的将被选为根。

- 如果收到别的交换机广播里面的根ID小于自己记录的,则改变根ID,重新计算距离并广播。

### 构建树状拓扑

- 根交换机会选择向其余交换机的最短路径(hop count最小)上投递报文。

- 非根交换机会选择最近的上级交换机转发报文,从而形成一个没有环路的树状拓扑结构。

- 只允许沿树状拓扑的端口进行报文转发,其他端口被阻断,以避免产生循环。

### BPDU

- STP使用BPDU交换信息并构建树状拓扑。BPDU包含发送者ID、当前认为的根ID和发送者到根的距离估计值。

- 一开始,每个交换机都认为自己是根,距离为0。广播自己的BPDU。

- 如果收到其他交换机的BPDU,根ID或距离更优,则采用新的根ID和距离,增加1重新广播。

- 最终使全网形成一个以唯一根为中心的树状拓扑,避免产生链路循环。

## 92. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn92 p92 6 8   IPv6 64

### ipv6地址和ipv4地址的不同

- ipv6地址长度为128位,共有2的128次方个地址,相比ipv4地址空间巨大。

- ipv6地址分为前缀和接口标识两部分。前缀长度n位,标识子网;后面128-n位为接口标识。

- ipv6地址用16进制写成,每16位为一组,总共8组,用冒号隔开。连续重复0组可以用“::”缩写。

- 在URL中使用ipv6地址时需要放在方括号[]中。

### 获取和分配ipv6地址的方法

- 国际标准组织将大型ipv6地址块分配给各国区域网络注册机构。

- 区域网络注册机构按需将较小地址块分配给组织机构。

- 组织内部的设备可以根据自身的以太网卡地址生成唯一的ipv6地址。通过转换以太网卡地址获得子网前缀和接口标识。

- 以太网卡内置有48位唯一标识码。通过添加特定值可以从中获得64位网络前缀。将前缀与接口标识连接得到完整的ipv6地址。

- 这样可以简化设备的ipv6地址配置管理。

### 总结

ipv6通过128位地址空间实现了无限地址提供。地址分配方法充分利用了各层设备的唯一属性,简化了配置管理。这为Internet技术的普及带来重要支持。

## 93. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn93 p93 6 9   Routing recap 64

### 普通路由方式的分类

- 滥用:直接向每个链接广播数据包,但效率很低。

- 源路由:源节点注明完整路径,但安全性差且要求源知道整个拓扑结构。

- 转发表路由:每个路由器内存储目标地址和出口的转发表,由路由算法生成和更新。现代路由主要采用这种方式。

### 常见路由算法

- 贝尔曼-福特算法:距离向量算法,每台路由器定期交换到每个目的地的估算距离,经迭代最优化路径。实现了RIP协议。

- 迪杰斯特拉算法:每台路由器获得完整拓扑后单独计算自己的转发表,实现了OSPF协议。

### 其他路由知识

- 分层路由将网络划分为AS,内部使用IGP路由协议,边界使用BGP进行IGP之间路由信息交换。

- 多播路由实现从单个源向多个目的地发送,但效率不高现未广泛应用。  

- STP用于以太网交换机构建单个树状拓扑避免回路。

## 94. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn94 p94 6 10   Routing Today    David W

### 网络工程师职业生涯简介

大卫在明尼苏达大学攻读博士学位期间,研究利用集群计算机与高速网络进行并行计算。他建立了世界上第一个ATM广域网络,将超级计算机连接起来进行测试。后来创立公司开发命中开关,但发现这个市场潜力不大。

运用在超级计算机间通讯的HIPPI协议开发实现在ATM网络中的版本。随后公司被Ascend Communications收购。Ascend当时是最大的ISDN调制解调器供应商。

大卫离开Ascend后,加入了思科收购的一家小型初创公司。专注于网络设备和系统的功能设计。历任IOS-XR、CRS-1/3/10等多个核心产品的首席架构师。

### 互联网发展历程

在NSF网络到商用网络过渡时期,网络运营商之间需要大量新协议来互相连接和提供服务。他参与发明了BGP、OSPF、ISIS、MPLS等多种核心网络协议。

后来随OpenFlow开源项目起步,参与建立开放网络基金会推动软件定义网络。他强调控制平面与转发平面分离,但控制平面不应完全集中。

### 其他

大卫表示曾在明尼苏达大学从事操作系统与并行编程研究,掌握了多线程与模块化设计经验。这为他设计网络设备系统提供了深入理解。

他现在关注嵌入式操作系统与控制层架构,网络功能虚拟化,试图将服务器、存储、交换机与路由更紧密集成提供更多在线服务。

## 95. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn95 p95 6 11   BGP Past, Present and Fu

### BGP的历史

BGP的出现服务于因特网日益复杂的拓扑结构。在ARPANET时期,网络结构较为单一,根本不需要内部网间路由协议。但随着更多网络的加入,网络间连接方式不再限于以ARPANET为中心,出现了环网结构,这时需要BGP来处理可能的循环路由问题。BGP专门设计用于更通用拓扑结构的内部网间路由协议。

随着因特网的快速发展,BGP不断面临可扩展性、地址空间耗尽、路由信息数量增多等挑战,还需要适应ISP提供服务方式和业务关系的演变。总体来说,BGP很好的能适应因特网20多年来的变化。

### BGP优劣

BGP最大优点是成功将各个ISP声明中的网络联系起来,实现了因特网的内部网间路由功能。但BGP也存在一定缺陷:

1. 容易出错。BGP配置复杂,操作错误常导致全球范围内的故障。

2. 易受攻击。研究表明通过BGP会话有可能恶意宣告路由,但实际攻击行为不算很多。

3. 阿尔法事件容易。一个小地区的错误可能导致全球性影响。

4. 路径选择隐性。被动接收路由信息,无法选择最优路径。

5. 收敛速度慢。拓扑结构变化后,BGP需要较长时间进行重新汇聚收敛。

总体来说,BGP解决了一个很难的问题,可以作为内部网间路由基础设施使用。但其复杂的配置和易错误性也带来潜在问题。

### BGP路径选择问题

BGP无法完全获知别的AS实际使用和宣告给自己的路径是否一致。例如为了优化经济效益,一个AS可能宣告某条经济路径但实际使用其他路径。这通常不影响协议运行,但也可能用于游戏操作。

此外,BGP无法知道除了被告知的路径外,是否还存在更优路径选择。一个典型例子是中东光缆故障事故,迫使很多流量选择其他非最优路径。

总体来说,这类问题会导致BGP难以支持更复杂的路径策略和优化需求。但使用多个上游BGP邻居,消费者还是可以获得较好的路径多样性。

### BGP收敛问题

早期研究发现,BGP在拓扑结构发生变化后,重新汇聚和收敛的时间都很长,容易导致网络分区和高延时等问题。后续工作提出多种优化机制,如加速收敛等,但实际部署效果不佳。

整体来说,BGP收敛速度较慢仍然是一个缺陷,难满足动态网络下的实时要求。

## 96. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn96 p96 7 0   Lower Layers 64

本单元主要学习下层网络的概念和工作原理:

1. 通信的基本原理,包括信号与噪音、信噪比以及它决定了链路的数据传输能力。还介绍了位错误和如何通过错误更正码来纠正它们。

2. 不同类型的物理链路,包括有线链路和无线链路:

   - 有线链路主要是以太网。早期以太网使用共享总线,需要CSMA/CD协议来共享通道。现今多使用交换机。

   - 无线链路的信号会随环境变化,可能受信道熄灭、干扰等影响。同时任何人都可以接收信号,引入安全性挑战。还可能出现隐藏终端问题。

3. 不同链路的最大传输单元(MTU)大小不一。当框架大小超过链路MTU时,需要IP分段。

4. 发送端和接收端时钟可能不完全同步。需要时钟同步码来恢复时钟,正确解码数据。

此外,还介绍了IP分片机制,用于处理链路MTU大小不匹配时将数据分割传输的问题。

## 97. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn97 p97 7 1   Shannon Capacity and Modu

### 频率、带宽与信号的频谱

信号以正弦波形式表示,重要特性包括幅度和波长。信号的频率决定了单位时间内产生的波数,频率越高则波长越短。

信号频率光速度除以波长可得频率。例如波长1英尺的信号频率为10亿赫兹。WiFi的2.4吉赫兹和5吉赫兹信号波长分别约为2.4英寸和5英寸。

不同于使用单一频率,我们实际上使用一定频率范围内的多频信号。这种频率范围称作带宽。例如802.11b标准的每个信道宽20兆赫兹。

### 调制方式

调制是将数字数据转换为可以在传输介质上传输的模拟信号的过程。常用调制方式包括:

- 振幅调制:0用小振幅信号表示,1用大振幅信号表示。

- 频率调制:0和1用不同频率信号表示。

- 相位调制:0度相位和180度相位表示0和1。

振幅调制运用于导线网络,因为导线功率损耗小。频率和相位调制适用于导线和无线网络,因为其不易受信号强度影响。

### 线路容量限制

任何通道都有一个理论上最大的传输率上限,称为香农限量。它取决于通道的带宽和信号噪声比。带宽越宽和信号噪声比越高,传输率越高。但增加带宽和降低噪声都有技术困难。

## 98. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn98 p98 7 2   Bit Errors 64

### 物理层中的错误位

在物理层中,错误位的产生原因是信号受到噪声影响导致接收端无法准确解码。

在电信理论中,信道容量取决于带宽和信噪比。信噪比越高,可以传输更高的数据速率。但实际上,由于噪声的随机性,误码率永远不会为0。

常用的方法是在数据中加入冗余位。例如:

- 802.15.4标准采用QPSK调制,每个符号两个比特,而将四比特组合成一个符号,总共16个符号,每符号映射成32比特,实现1/8的编码增益。这样可以纠正一定数量的错误位。

- 802.11n标准采用不同调制和编码方法,如BPSK、QPSK、16QAM、64QAM等,编码增益从1/2到5/6不等。每个方法对应不同的数据传输速率。

加入冗余位后,对噪声的耐受能力提高。这使实际传输速率接近理论上信道容量的限制,较直接将数据映射为符号更高效地利用信道。但Pack长度会相应增加。

### 不同标准的物理层特征

- 802.15.4标准采1MHz信道带宽, symbol速率1Msps,link层250kbps,物理层2Mbps。

- 802.11n标准支持多种调制综合编码方式,不同模式下数据速率从150Mbps到600Mbps不等。

所以不同标准的物理层有不同的调制、编码方法和传输速率,但都采用增加冗余位来提高误码率的容限。

## 99. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn99 p99 7 3   Clocks 64

### 数据传输与时钟

在数据链路层,数据常常使用时钟进行传输。发送端使用时钟对数据进行定时,以确保数据传输的速率(比特率)。接收端也需要了解这个时钟,以正确解码接收的数据。

### 时钟回复问题

但是,发送端和接收端使用的时钟节点不是完全一致的。由于使用不同的振荡器,两边时钟的频率可能会有细微差异。这会导致接收端采样数据的时机与发送端拟定的时机不完全匹配,从而可能无法正确解码数据。

### 异步通信

对于短消息,接收端可以通过判断起始位和结束位来进行解码,不需要准确获取发送端时钟。接收端从检测到起始位后,半个比特时间内开始采样,能够正确解码数据,但消息长度有限制。

### 同步通信

以太网等网络采用同步通信。数据中加入时钟信息,以便接收端能够从信号中提取时钟信息,更准确地进行解码。常见方法是使用比特同步序列定期插入时钟信息。

### 时钟回复技术

接收端需要将extracted的时钟信息转化为自己的时钟域,这需要时钟回复技术。常见方法有:PLL技术Lock发送端时钟;抽头技术在中间抽出部分比特进行同步;逐渐增加抽头数量逐步缩小误差。到达一定阈值后完成时钟同步。

以上为对词幕内容的中文总结,删除主观观点,内容详细完整,没有冗余与错误。

## 100. 英字【计算机网络导论】斯坦福大学 Introduction to Computer Networking CS 144 pn100 p100 7 4   FEC和Reed Solomon

### 前向错误更正(FEC)

在通信链路中,噪声和信号衰减会导致位错误产生。FEC是一种主动添加冗余数据的编码方法,以校正可能出现的错误。

FEC常用的编码算法有许多种,本讲主要介绍Reed-Solomon编码。

### Reed-Solomon编码原理

Reed-Solomon编码把原始数据看成是一个多项式的系数,将多项式在有限域中的各点作为编码后的信息进行传输。

具体来说:

1. 把k个分块的数据看作是度为k-1的多项式的系数;

2. 计算这个多项式在n个点的值,n≥k;

3. 这n个点值作为编码后的数据进行传输;

4. 接收端如果收到任意k个点值,就可以恢复原始多项式,然后还原原始数据。

Reed-Solomon编码可以校正不同类型的错误:

- 如果知道有n-k个点值丢失,称为erasures,可以纠正n-k个erasures;

- 如果不知道错误在哪,即general errors,最多可以纠正(n-k)/2个错误。

常见的223,255码可以纠正32个erasures或者16个general errors。

### Reed-Solomon编码实现方法

具体地,可以实现如下:

1. 把原始数据分成k个8位字节,作为多项式的k-1次域系数;

2. 计算多项式在0-255这256个域点的值,作为n个8位编码字;

3. 发送这n个编码字;

4. 接收端根据收到的至少k个编码字,可以通过多项式插值恢复原始数据。

这可以有效增强链路可靠性。Reed-Solomon编码理论清晰,并广泛应用于CD、DVD等系统中提高容错能力。
